{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3TT96EuDv1rpC+qXveaDW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IraDionisio/CSCI-166-DQN-Final-Project/blob/main/BaselineBeamRider.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJHcqDf82zOI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test 3 --- Final Test for 06.11.2025"
      ],
      "metadata": {
        "id": "XtOuIKifmmyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium[atari,accept-rom-license]\n",
        "!pip install autorom\n",
        "!pip install stable-baselines3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqL9333gml9l",
        "outputId": "55edc06d-3519-48a3-d9fe-ca0584ed1437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium[accept-rom-license,atari] in /usr/local/lib/python3.12/dist-packages (1.2.2)\n",
            "\u001b[33mWARNING: gymnasium 1.2.2 does not provide the extra 'accept-rom-license'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (0.0.4)\n",
            "Requirement already satisfied: ale_py>=0.9 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari]) (0.11.2)\n",
            "Requirement already satisfied: autorom in /usr/local/lib/python3.12/dist-packages (0.6.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from autorom) (8.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from autorom) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->autorom) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->autorom) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->autorom) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->autorom) (2025.11.12)\n",
            "Requirement already satisfied: stable-baselines3 in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (1.2.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.9.0+cu126)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (3.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!AutoROM --accept-license"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oi2qmVoVmxve",
        "outputId": "772efe5f-84af-4a73-dbb1-586533cc59a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoROM will download the Atari 2600 ROMs.\n",
            "They will be installed to:\n",
            "\t/usr/local/lib/python3.12/dist-packages/AutoROM/roms\n",
            "\n",
            "Existing ROMs will be overwritten.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install the Gym"
      ],
      "metadata": {
        "id": "RQyqgMFzT-qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ale_py\n",
        "import gymnasium as gym"
      ],
      "metadata": {
        "id": "_W_afhrzUAnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configure the model save drive"
      ],
      "metadata": {
        "id": "E0n7zQrALq7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "v8hSrWrrLibc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "889c247d-6f3f-4c25-aacf-d1e2f6ad7a6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "save_dir = \"/content/drive/MyDrive/PUBLIC/Models\"\n",
        "os.makedirs(save_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "vlWPUjKfLv9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now Model"
      ],
      "metadata": {
        "id": "SAEvyoukL1T3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "import argparse\n",
        "import time\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import collections\n",
        "import typing as tt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.tensorboard.writer import SummaryWriter"
      ],
      "metadata": {
        "id": "VCbjkLLSxCUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dqn_model\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, input_shape, n_actions):\n",
        "        super(DQN, self).__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "        size = self.conv(torch.zeros(1, *input_shape)).size()[-1]\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, n_actions)\n",
        "        )\n",
        "    def forward(self, x: torch.ByteTensor):\n",
        "        x = x.float() / 255.0\n",
        "        return self.fc(self.conv(x))"
      ],
      "metadata": {
        "id": "dIJ32Rs6xJsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#wrappers\n",
        "\n",
        "from gymnasium import spaces\n",
        "from stable_baselines3.common import atari_wrappers\n",
        "\n",
        "\n",
        "class ImageToPyTorch(gym.ObservationWrapper):\n",
        "    \"\"\"\n",
        "    ImageToPyTorch: Reorders image dimensions from (H, W, C) to (C, H, W)\n",
        "    for compatibility with PyTorch convolutional layers.\n",
        "    \"\"\"\n",
        "    def __init__(self, env):\n",
        "        super(ImageToPyTorch, self).__init__(env)\n",
        "        obs = self.observation_space\n",
        "        assert isinstance(obs, gym.spaces.Box)\n",
        "        assert len(obs.shape) == 3\n",
        "        new_shape = (obs.shape[-1], obs.shape[0], obs.shape[1])\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            low=obs.low.min(), high=obs.high.max(),\n",
        "            shape=new_shape, dtype=obs.dtype)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.moveaxis(observation, 2, 0)\n",
        "\n",
        "\n",
        "class BufferWrapper(gym.ObservationWrapper):\n",
        "    \"\"\"\n",
        "    BufferWrapper: Maintains a rolling window of the last `n_steps` frames\n",
        "    to give the agent a sense of temporal context.\n",
        "    \"\"\"\n",
        "    def __init__(self, env, n_steps):\n",
        "        super(BufferWrapper, self).__init__(env)\n",
        "        obs = env.observation_space\n",
        "        assert isinstance(obs, spaces.Box)\n",
        "        new_obs = gym.spaces.Box(\n",
        "            obs.low.repeat(n_steps, axis=0), obs.high.repeat(n_steps, axis=0),\n",
        "            dtype=obs.dtype)\n",
        "        self.observation_space = new_obs\n",
        "        self.buffer = collections.deque(maxlen=n_steps)\n",
        "\n",
        "    def reset(self, *, seed: tt.Optional[int] = None, options: tt.Optional[dict[str, tt.Any]] = None):\n",
        "        for _ in range(self.buffer.maxlen):\n",
        "            self.buffer.append(np.zeros_like(self.env.observation_space.low))\n",
        "        obs, extra = self.env.reset()\n",
        "        return self.observation(obs), extra\n",
        "\n",
        "    def observation(self, observation: np.ndarray) -> np.ndarray:\n",
        "        self.buffer.append(observation)\n",
        "        return np.concatenate(self.buffer)\n",
        "\n",
        "\n",
        "def make_env(env_name: str, render_mode=None, **kwargs):\n",
        "    print(f\"Creating environment {env_name}\")\n",
        "    env = gym.make(env_name, render_mode=render_mode, **kwargs)\n",
        "    env = atari_wrappers.AtariWrapper(env, clip_reward=False, noop_max=0)\n",
        "    env = ImageToPyTorch(env)\n",
        "    env = BufferWrapper(env, n_steps=N_STEPS)\n",
        "    return env"
      ],
      "metadata": {
        "id": "Vk2CtGcOBcQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEFAULT_ENV_NAME = \"ALE/BeamRider-v5\"\n",
        "MEAN_REWARD_BOUND = 500 # Default value, will be overridden by fast training config\n",
        "\n",
        "GAMMA = 0.99\n",
        "BATCH_SIZE = 32\n",
        "REPLAY_SIZE = 10000\n",
        "LEARNING_RATE = 1e-4\n",
        "SYNC_TARGET_FRAMES = 1000\n",
        "REPLAY_START_SIZE = 10000\n",
        "N_STEPS = 4 # for frame-stacking\n",
        "\n",
        "SAVE_EPSILON = 0.5  # Only save if at least this much better\n",
        "EPSILON_DECAY_LAST_FRAME = 150000\n",
        "EPSILON_START = 1.0\n",
        "EPSILON_FINAL = 0.01\n",
        "\n",
        "# Tuple of tensors returned from a sampled minibatch in replay buffer\n",
        "State = np.ndarray\n",
        "Action = int\n",
        "BatchTensors = tt.Tuple[\n",
        "    torch.ByteTensor,           # current state\n",
        "    torch.LongTensor,           # actions\n",
        "    torch.Tensor,               # rewards\n",
        "    torch.BoolTensor,           # done || trunc\n",
        "    torch.ByteTensor            # next state\n",
        "]"
      ],
      "metadata": {
        "id": "GvXPdjPCBxOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âš™ï¸ Fast Training Config for Quick Test Run\n",
        "MEAN_REWARD_BOUND = 500 # Changed to allow for more meaningful training\n",
        "REPLAY_START_SIZE = 1000\n",
        "EPSILON_DECAY_LAST_FRAME = 10_000\n",
        "SYNC_TARGET_FRAMES = 500\n",
        "\n",
        "# REPLAY_SIZE = 5000  # optional\n",
        "# BATCH_SIZE = 16     # optional"
      ],
      "metadata": {
        "id": "3FHvHNMrR9Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Define directories\n",
        "save_dir_drive = \"/content/drive/MyDrive/PUBLIC/Models\"\n",
        "save_dir_local = \"saved_models\"\n",
        "\n",
        "# Create both directories if they don't exist\n",
        "os.makedirs(save_dir_drive, exist_ok=True)\n",
        "os.makedirs(save_dir_local, exist_ok=True)\n",
        "\n",
        "# Safe model filename\n",
        "env_name = DEFAULT_ENV_NAME\n",
        "safe_env_name = env_name.replace(\"/\", \"_\")"
      ],
      "metadata": {
        "id": "MkILCuT2OhBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Experience:\n",
        "    state: State\n",
        "    action: Action\n",
        "    reward: float\n",
        "    done_trunc: bool\n",
        "    new_state: State\n",
        "\n",
        "\n",
        "class ExperienceBuffer:\n",
        "    def __init__(self, capacity: int):\n",
        "        self.buffer = collections.deque(maxlen=capacity)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "    def append(self, experience: Experience):\n",
        "        self.buffer.append(experience)\n",
        "\n",
        "    def sample(self, batch_size: int) -> tt.List[Experience]:\n",
        "        indices = np.random.choice(len(self), batch_size, replace=False)\n",
        "        return [self.buffer[idx] for idx in indices]"
      ],
      "metadata": {
        "id": "uW4Bo-mcB6rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "    def __init__(self, env: gym.Env, exp_buffer: ExperienceBuffer):\n",
        "        self.env = env\n",
        "        self.exp_buffer = exp_buffer\n",
        "        self.state: tt.Optional[np.ndarray] = None\n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self):\n",
        "        self.state, _ = self.env.reset()\n",
        "        self.total_reward = 0.0\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def play_step(self, net: DQN, device: torch.device,\n",
        "                  epsilon: float = 0.0) -> tt.Optional[float]:\n",
        "        done_reward = None\n",
        "\n",
        "        if np.random.random() < epsilon:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            state_v = torch.as_tensor(self.state).to(device)\n",
        "            state_v.unsqueeze_(0)\n",
        "            q_vals_v = net(state_v)\n",
        "            _, act_v = torch.max(q_vals_v, dim=1)\n",
        "            action = int(act_v.item())\n",
        "\n",
        "        # do step in the environment\n",
        "        new_state, reward, is_done, is_tr, _ = self.env.step(action)\n",
        "        self.total_reward += reward\n",
        "\n",
        "        exp = Experience(\n",
        "            state=self.state, action=action, reward=float(reward),\n",
        "            done_trunc=is_done or is_tr, new_state=new_state\n",
        "        )\n",
        "        self.exp_buffer.append(exp)\n",
        "        self.state = new_state\n",
        "        if is_done or is_tr:\n",
        "            done_reward = self.total_reward\n",
        "            self._reset()\n",
        "        return done_reward"
      ],
      "metadata": {
        "id": "irJb4V32B-R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_to_tensors(batch: tt.List[Experience], device: torch.device) -> BatchTensors:\n",
        "    states, actions, rewards, dones, new_state = [], [], [], [], []\n",
        "    for e in batch:\n",
        "        states.append(e.state)\n",
        "        actions.append(e.action)\n",
        "        rewards.append(e.reward)\n",
        "        dones.append(e.done_trunc)\n",
        "        new_state.append(e.new_state)\n",
        "    states_t = torch.as_tensor(np.asarray(states))\n",
        "    actions_t = torch.LongTensor(actions)\n",
        "    rewards_t = torch.FloatTensor(rewards)\n",
        "    dones_t = torch.BoolTensor(dones)\n",
        "    new_states_t = torch.as_tensor(np.asarray(new_state))\n",
        "    return states_t.to(device), actions_t.to(device), rewards_t.to(device), \\\n",
        "           dones_t.to(device),  new_states_t.to(device)"
      ],
      "metadata": {
        "id": "vHXmNr_wCBJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss(batch: tt.List[Experience], net: DQN, tgt_net: DQN,\n",
        "              device: torch.device) -> torch.Tensor:\n",
        "    states_t, actions_t, rewards_t, dones_t, new_states_t = batch_to_tensors(batch, device)\n",
        "\n",
        "    state_action_values = net(states_t).gather(\n",
        "        1, actions_t.unsqueeze(-1)\n",
        "    ).squeeze(-1)\n",
        "    with torch.no_grad():\n",
        "        next_state_values = tgt_net(new_states_t).max(1)[0]\n",
        "        next_state_values[dones_t] = 0.0\n",
        "        next_state_values = next_state_values.detach()\n",
        "\n",
        "    expected_state_action_values = next_state_values * GAMMA + rewards_t\n",
        "    return nn.MSELoss()(state_action_values, expected_state_action_values)"
      ],
      "metadata": {
        "id": "-dbh0431CEXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_comment = f\"lr{LEARNING_RATE}_gamma{GAMMA}_epsdec{EPSILON_DECAY_LAST_FRAME}_rs{REPLAY_START_SIZE}_bs{BATCH_SIZE}_sync{SYNC_TARGET_FRAMES}_fs{N_STEPS}\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "env = make_env(env_name)\n",
        "net = DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
        "tgt_net = DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
        "writer = SummaryWriter(comment=f\"-{env_name}-{model_comment}\")\n",
        "print(net)\n",
        "\n",
        "buffer = ExperienceBuffer(REPLAY_SIZE)\n",
        "agent = Agent(env, buffer)\n",
        "epsilon = EPSILON_START\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
        "total_rewards = []\n",
        "frame_idx = 0\n",
        "ts_frame = 0\n",
        "ts = time.time()\n",
        "best_m_reward = None\n",
        "\n",
        "hparams = {\n",
        "    'learning_rate': LEARNING_RATE,\n",
        "    'gamma': GAMMA,\n",
        "    'epsilon_start': EPSILON_START,\n",
        "    'epsilon_final': EPSILON_FINAL,\n",
        "    'epsilon_decay_last_frame': EPSILON_DECAY_LAST_FRAME,\n",
        "    'replay_size': REPLAY_SIZE,\n",
        "    'replay_start_size': REPLAY_START_SIZE,\n",
        "    'batch_size': BATCH_SIZE,\n",
        "    'sync_target_frames': SYNC_TARGET_FRAMES,\n",
        "    'frame_stack': N_STEPS,\n",
        "    'optimizer': 'Adam',\n",
        "    'mean_reward_bound': MEAN_REWARD_BOUND\n",
        "}\n",
        "\n",
        "start_time = time.time()\n",
        "while True:\n",
        "    frame_idx += 1\n",
        "    epsilon = max(EPSILON_FINAL, EPSILON_START - frame_idx / EPSILON_DECAY_LAST_FRAME)\n",
        "\n",
        "    reward = agent.play_step(net, device, epsilon)\n",
        "    if reward is not None:\n",
        "        total_rewards.append(reward)\n",
        "        speed = (frame_idx - ts_frame) / (time.time() - ts)\n",
        "        elapsed = time.time() - start_time  # in seconds\n",
        "        ts_frame = frame_idx\n",
        "        ts = time.time()\n",
        "        m_reward = np.mean(total_rewards[-100:])\n",
        "        print(f\"{frame_idx}: done {len(total_rewards)} games, reward {m_reward:.3f}, \"\n",
        "             f\"eps {epsilon:.2f}, speed {speed:.2f} f/s, time {elapsed/60:.1f} min\")\n",
        "        writer.add_scalar(\"epsilon\", epsilon, frame_idx)\n",
        "        writer.add_scalar(\"speed\", speed, frame_idx)\n",
        "        writer.add_scalar(\"reward_100\", m_reward, frame_idx)\n",
        "        writer.add_scalar(\"reward\", reward, frame_idx)\n",
        "        if best_m_reward is None or m_reward > best_m_reward + SAVE_EPSILON:\n",
        "            # print(f\"{frame_idx}: done {len(total_rewards)} games, reward {m_reward:.3f}, \"\n",
        "            #    f\"eps {epsilon:.2f}, speed {speed:.2f} f/s, time {elapsed/60:.1f} min\")\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
        "            model_filename = f\"{safe_env_name}-best_{int(m_reward)}-{timestamp}-{model_comment}.dat\"\n",
        "\n",
        "            # Save to both paths\n",
        "            model_path_drive = os.path.join(save_dir_drive, model_filename)\n",
        "            model_path_local = os.path.join(save_dir_local, model_filename)\n",
        "\n",
        "            torch.save(net.state_dict(), model_path_drive)\n",
        "            torch.save(net.state_dict(), model_path_local)\n",
        "\n",
        "            print(f\"ðŸ’¾ Model saved to:\\n - Google Drive: {model_path_drive}\\n - Local:        {model_path_local}\")\n",
        "            if best_m_reward is not None:\n",
        "                print(f\"Best reward updated {best_m_reward:.3f} -> {m_reward:.3f}\")\n",
        "            best_m_reward = m_reward\n",
        "\n",
        "            writer.add_hparams(hparams, {'metric/mean_reward': m_reward}, global_step=frame_idx)\n",
        "\n",
        "        if m_reward > MEAN_REWARD_BOUND:\n",
        "            print(\"Solved in %d frames!\" % frame_idx)\n",
        "            break\n",
        "    if len(buffer) < REPLAY_START_SIZE:\n",
        "        continue\n",
        "    if frame_idx % SYNC_TARGET_FRAMES == 0:\n",
        "        tgt_net.load_state_dict(net.state_dict())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    batch = buffer.sample(BATCH_SIZE)\n",
        "    loss_t = calc_loss(batch, net, tgt_net, device)\n",
        "    loss_t.backward()\n",
        "    optimizer.step()\n",
        "env.close()\n",
        "writer.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8gj-5woCXEB",
        "outputId": "6bd73a4a-a37f-435f-c310-5bec820b4445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating environment ALE/BeamRider-v5\n",
            "DQN(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (5): ReLU()\n",
            "    (6): Flatten(start_dim=1, end_dim=-1)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=3136, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n",
            "193: done 1 games, reward 132.000, eps 0.98, speed 354.42 f/s, time 0.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_132-20251201-0058-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_132-20251201-0058-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "240: done 2 games, reward 88.000, eps 0.98, speed 298.35 f/s, time 0.0 min\n",
            "299: done 3 games, reward 73.333, eps 0.97, speed 369.10 f/s, time 0.0 min\n",
            "390: done 4 games, reward 110.000, eps 0.96, speed 345.48 f/s, time 0.0 min\n",
            "472: done 5 games, reward 96.800, eps 0.95, speed 363.45 f/s, time 0.0 min\n",
            "521: done 6 games, reward 80.667, eps 0.95, speed 347.92 f/s, time 0.0 min\n",
            "710: done 7 games, reward 94.286, eps 0.93, speed 355.92 f/s, time 0.0 min\n",
            "819: done 8 games, reward 93.500, eps 0.92, speed 344.92 f/s, time 0.0 min\n",
            "870: done 9 games, reward 83.111, eps 0.91, speed 355.67 f/s, time 0.0 min\n",
            "1001: done 10 games, reward 83.600, eps 0.90, speed 112.72 f/s, time 0.1 min\n",
            "1103: done 11 games, reward 80.000, eps 0.89, speed 73.01 f/s, time 0.1 min\n",
            "1212: done 12 games, reward 80.667, eps 0.88, speed 70.88 f/s, time 0.1 min\n",
            "1333: done 13 games, reward 84.615, eps 0.87, speed 42.78 f/s, time 0.2 min\n",
            "1410: done 14 games, reward 84.857, eps 0.86, speed 47.42 f/s, time 0.2 min\n",
            "1482: done 15 games, reward 85.067, eps 0.85, speed 62.99 f/s, time 0.2 min\n",
            "1578: done 16 games, reward 88.000, eps 0.84, speed 51.30 f/s, time 0.2 min\n",
            "1660: done 17 games, reward 88.000, eps 0.83, speed 149.91 f/s, time 0.2 min\n",
            "1768: done 18 games, reward 88.000, eps 0.82, speed 143.61 f/s, time 0.3 min\n",
            "1903: done 19 games, reward 88.000, eps 0.81, speed 144.01 f/s, time 0.3 min\n",
            "2021: done 20 games, reward 88.000, eps 0.80, speed 144.21 f/s, time 0.3 min\n",
            "2183: done 21 games, reward 96.381, eps 0.78, speed 145.73 f/s, time 0.3 min\n",
            "2318: done 22 games, reward 100.000, eps 0.77, speed 144.10 f/s, time 0.3 min\n",
            "2380: done 23 games, reward 97.565, eps 0.76, speed 149.13 f/s, time 0.3 min\n",
            "2432: done 24 games, reward 97.167, eps 0.76, speed 145.27 f/s, time 0.3 min\n",
            "2566: done 25 games, reward 100.320, eps 0.74, speed 121.77 f/s, time 0.4 min\n",
            "2620: done 26 games, reward 96.462, eps 0.74, speed 104.10 f/s, time 0.4 min\n",
            "2736: done 27 games, reward 97.778, eps 0.73, speed 104.17 f/s, time 0.4 min\n",
            "2911: done 28 games, reward 105.286, eps 0.71, speed 119.55 f/s, time 0.4 min\n",
            "2974: done 29 games, reward 103.172, eps 0.70, speed 141.95 f/s, time 0.4 min\n",
            "3061: done 30 games, reward 99.733, eps 0.69, speed 145.69 f/s, time 0.4 min\n",
            "3182: done 31 games, reward 99.355, eps 0.68, speed 142.59 f/s, time 0.4 min\n",
            "3256: done 32 games, reward 99.000, eps 0.67, speed 143.26 f/s, time 0.4 min\n",
            "3311: done 33 games, reward 97.333, eps 0.67, speed 141.31 f/s, time 0.4 min\n",
            "3432: done 34 games, reward 98.353, eps 0.66, speed 134.78 f/s, time 0.5 min\n",
            "3486: done 35 games, reward 99.314, eps 0.65, speed 147.39 f/s, time 0.5 min\n",
            "3680: done 36 games, reward 102.667, eps 0.63, speed 139.24 f/s, time 0.5 min\n",
            "3839: done 37 games, reward 105.838, eps 0.62, speed 142.72 f/s, time 0.5 min\n",
            "3897: done 38 games, reward 103.053, eps 0.61, speed 146.31 f/s, time 0.5 min\n",
            "3947: done 39 games, reward 100.410, eps 0.61, speed 137.55 f/s, time 0.5 min\n",
            "4192: done 40 games, reward 102.300, eps 0.58, speed 139.76 f/s, time 0.6 min\n",
            "4287: done 41 games, reward 99.805, eps 0.57, speed 113.69 f/s, time 0.6 min\n",
            "4393: done 42 games, reward 101.619, eps 0.56, speed 103.35 f/s, time 0.6 min\n",
            "4517: done 43 games, reward 100.279, eps 0.55, speed 101.40 f/s, time 0.6 min\n",
            "4781: done 44 games, reward 109.000, eps 0.52, speed 134.56 f/s, time 0.6 min\n",
            "4835: done 45 games, reward 108.533, eps 0.52, speed 141.32 f/s, time 0.6 min\n",
            "4944: done 46 games, reward 106.174, eps 0.51, speed 121.66 f/s, time 0.7 min\n",
            "5082: done 47 games, reward 106.723, eps 0.49, speed 101.99 f/s, time 0.7 min\n",
            "5163: done 48 games, reward 107.250, eps 0.48, speed 101.97 f/s, time 0.7 min\n",
            "5230: done 49 games, reward 105.061, eps 0.48, speed 102.89 f/s, time 0.7 min\n",
            "5391: done 50 games, reward 109.120, eps 0.46, speed 132.84 f/s, time 0.7 min\n",
            "5462: done 51 games, reward 106.980, eps 0.45, speed 138.71 f/s, time 0.7 min\n",
            "5550: done 52 games, reward 105.769, eps 0.44, speed 138.39 f/s, time 0.7 min\n",
            "5694: done 53 games, reward 106.264, eps 0.43, speed 134.95 f/s, time 0.8 min\n",
            "5746: done 54 games, reward 104.296, eps 0.43, speed 142.76 f/s, time 0.8 min\n",
            "5844: done 55 games, reward 103.200, eps 0.42, speed 116.30 f/s, time 0.8 min\n",
            "5995: done 56 games, reward 105.286, eps 0.40, speed 102.15 f/s, time 0.8 min\n",
            "6063: done 57 games, reward 104.982, eps 0.39, speed 102.20 f/s, time 0.8 min\n",
            "6411: done 58 games, reward 109.241, eps 0.36, speed 130.80 f/s, time 0.9 min\n",
            "6660: done 59 games, reward 114.847, eps 0.33, speed 135.85 f/s, time 0.9 min\n",
            "6775: done 60 games, reward 115.867, eps 0.32, speed 137.58 f/s, time 0.9 min\n",
            "6977: done 61 games, reward 114.689, eps 0.30, speed 136.93 f/s, time 0.9 min\n",
            "7078: done 62 games, reward 115.677, eps 0.29, speed 134.97 f/s, time 0.9 min\n",
            "7132: done 63 games, reward 114.540, eps 0.29, speed 138.25 f/s, time 1.0 min\n",
            "7182: done 64 games, reward 112.750, eps 0.28, speed 131.11 f/s, time 1.0 min\n",
            "7307: done 65 games, reward 113.723, eps 0.27, speed 135.54 f/s, time 1.0 min\n",
            "7358: done 66 games, reward 112.000, eps 0.26, speed 132.39 f/s, time 1.0 min\n",
            "7466: done 67 games, reward 110.985, eps 0.25, speed 135.88 f/s, time 1.0 min\n",
            "7557: done 68 games, reward 111.294, eps 0.24, speed 98.69 f/s, time 1.0 min\n",
            "7634: done 69 games, reward 111.594, eps 0.24, speed 98.49 f/s, time 1.0 min\n",
            "7703: done 70 games, reward 111.257, eps 0.23, speed 97.89 f/s, time 1.0 min\n",
            "8033: done 71 games, reward 114.648, eps 0.20, speed 121.74 f/s, time 1.1 min\n",
            "8089: done 72 games, reward 113.667, eps 0.19, speed 131.90 f/s, time 1.1 min\n",
            "8163: done 73 games, reward 113.315, eps 0.18, speed 133.37 f/s, time 1.1 min\n",
            "8498: done 74 games, reward 118.324, eps 0.15, speed 132.88 f/s, time 1.1 min\n",
            "8548: done 75 games, reward 116.747, eps 0.15, speed 132.00 f/s, time 1.1 min\n",
            "8656: done 76 games, reward 116.368, eps 0.13, speed 130.53 f/s, time 1.2 min\n",
            "8837: done 77 games, reward 116.000, eps 0.12, speed 132.20 f/s, time 1.2 min\n",
            "8938: done 78 games, reward 116.769, eps 0.11, speed 130.88 f/s, time 1.2 min\n",
            "8986: done 79 games, reward 115.291, eps 0.10, speed 132.44 f/s, time 1.2 min\n",
            "9077: done 80 games, reward 116.050, eps 0.09, speed 130.71 f/s, time 1.2 min\n",
            "9174: done 81 games, reward 116.247, eps 0.08, speed 96.83 f/s, time 1.2 min\n",
            "9410: done 82 games, reward 120.195, eps 0.06, speed 97.73 f/s, time 1.3 min\n",
            "9533: done 83 games, reward 119.807, eps 0.05, speed 129.88 f/s, time 1.3 min\n",
            "9627: done 84 games, reward 119.952, eps 0.04, speed 130.93 f/s, time 1.3 min\n",
            "9765: done 85 games, reward 119.576, eps 0.02, speed 131.00 f/s, time 1.3 min\n",
            "9819: done 86 games, reward 118.186, eps 0.02, speed 132.40 f/s, time 1.3 min\n",
            "10075: done 87 games, reward 119.356, eps 0.01, speed 130.38 f/s, time 1.4 min\n",
            "10186: done 88 games, reward 121.000, eps 0.01, speed 129.99 f/s, time 1.4 min\n",
            "10233: done 89 games, reward 119.640, eps 0.01, speed 130.73 f/s, time 1.4 min\n",
            "10361: done 90 games, reward 120.756, eps 0.01, speed 129.21 f/s, time 1.4 min\n",
            "10423: done 91 games, reward 120.879, eps 0.01, speed 127.86 f/s, time 1.4 min\n",
            "10553: done 92 games, reward 122.913, eps 0.01, speed 128.84 f/s, time 1.4 min\n",
            "10697: done 93 games, reward 122.538, eps 0.01, speed 120.11 f/s, time 1.4 min\n",
            "10769: done 94 games, reward 121.702, eps 0.01, speed 98.50 f/s, time 1.4 min\n",
            "10823: done 95 games, reward 120.884, eps 0.01, speed 90.82 f/s, time 1.5 min\n",
            "10933: done 96 games, reward 121.458, eps 0.01, speed 94.06 f/s, time 1.5 min\n",
            "11037: done 97 games, reward 122.474, eps 0.01, speed 116.45 f/s, time 1.5 min\n",
            "11151: done 98 games, reward 123.918, eps 0.01, speed 128.58 f/s, time 1.5 min\n",
            "11320: done 99 games, reward 125.333, eps 0.01, speed 130.09 f/s, time 1.5 min\n",
            "11444: done 100 games, reward 124.960, eps 0.01, speed 129.80 f/s, time 1.5 min\n",
            "11532: done 101 games, reward 124.520, eps 0.01, speed 128.74 f/s, time 1.6 min\n",
            "11680: done 102 games, reward 125.840, eps 0.01, speed 127.33 f/s, time 1.6 min\n",
            "11759: done 103 games, reward 125.840, eps 0.01, speed 129.75 f/s, time 1.6 min\n",
            "11806: done 104 games, reward 123.640, eps 0.01, speed 65.07 f/s, time 1.6 min\n",
            "11944: done 105 games, reward 125.840, eps 0.01, speed 95.79 f/s, time 1.6 min\n",
            "12093: done 106 games, reward 127.160, eps 0.01, speed 104.26 f/s, time 1.6 min\n",
            "12146: done 107 games, reward 125.400, eps 0.01, speed 101.09 f/s, time 1.7 min\n",
            "12266: done 108 games, reward 126.720, eps 0.01, speed 96.72 f/s, time 1.7 min\n",
            "12320: done 109 games, reward 126.720, eps 0.01, speed 94.98 f/s, time 1.7 min\n",
            "12377: done 110 games, reward 126.280, eps 0.01, speed 90.51 f/s, time 1.7 min\n",
            "12552: done 111 games, reward 128.040, eps 0.01, speed 121.74 f/s, time 1.7 min\n",
            "12817: done 112 games, reward 131.560, eps 0.01, speed 126.69 f/s, time 1.8 min\n",
            "12988: done 113 games, reward 132.640, eps 0.01, speed 129.70 f/s, time 1.8 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_132-20251201-0100-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_132-20251201-0100-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 132.000 -> 132.640\n",
            "13085: done 114 games, reward 133.520, eps 0.01, speed 124.37 f/s, time 1.8 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_133-20251201-0100-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_133-20251201-0100-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 132.640 -> 133.520\n",
            "13143: done 115 games, reward 133.080, eps 0.01, speed 123.72 f/s, time 1.8 min\n",
            "13200: done 116 games, reward 132.640, eps 0.01, speed 127.66 f/s, time 1.8 min\n",
            "13376: done 117 games, reward 133.960, eps 0.01, speed 129.37 f/s, time 1.8 min\n",
            "13434: done 118 games, reward 133.960, eps 0.01, speed 128.85 f/s, time 1.8 min\n",
            "13553: done 119 games, reward 133.520, eps 0.01, speed 131.95 f/s, time 1.8 min\n",
            "13668: done 120 games, reward 133.520, eps 0.01, speed 130.47 f/s, time 1.9 min\n",
            "13719: done 121 games, reward 130.880, eps 0.01, speed 98.49 f/s, time 1.9 min\n",
            "14123: done 122 games, reward 134.400, eps 0.01, speed 106.34 f/s, time 1.9 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_134-20251201-0100-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_134-20251201-0100-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 133.520 -> 134.400\n",
            "14239: done 123 games, reward 135.720, eps 0.01, speed 118.03 f/s, time 1.9 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_135-20251201-0100-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_135-20251201-0100-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 134.400 -> 135.720\n",
            "14391: done 124 games, reward 137.480, eps 0.01, speed 123.50 f/s, time 2.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_137-20251201-0100-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_137-20251201-0100-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 135.720 -> 137.480\n",
            "14452: done 125 games, reward 136.160, eps 0.01, speed 117.24 f/s, time 2.0 min\n",
            "14745: done 126 games, reward 141.000, eps 0.01, speed 126.04 f/s, time 2.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_141-20251201-0100-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_141-20251201-0100-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 137.480 -> 141.000\n",
            "14815: done 127 games, reward 140.560, eps 0.01, speed 114.81 f/s, time 2.0 min\n",
            "14862: done 128 games, reward 137.480, eps 0.01, speed 128.10 f/s, time 2.0 min\n",
            "15021: done 129 games, reward 139.240, eps 0.01, speed 127.41 f/s, time 2.1 min\n",
            "15071: done 130 games, reward 140.120, eps 0.01, speed 126.44 f/s, time 2.1 min\n",
            "15183: done 131 games, reward 139.680, eps 0.01, speed 128.01 f/s, time 2.1 min\n",
            "15337: done 132 games, reward 141.000, eps 0.01, speed 99.12 f/s, time 2.1 min\n",
            "15391: done 133 games, reward 141.000, eps 0.01, speed 91.15 f/s, time 2.1 min\n",
            "15441: done 134 games, reward 139.680, eps 0.01, speed 95.11 f/s, time 2.1 min\n",
            "15586: done 135 games, reward 140.560, eps 0.01, speed 106.02 f/s, time 2.1 min\n",
            "15738: done 136 games, reward 140.120, eps 0.01, speed 126.45 f/s, time 2.2 min\n",
            "15812: done 137 games, reward 138.800, eps 0.01, speed 130.55 f/s, time 2.2 min\n",
            "16041: done 138 games, reward 144.080, eps 0.01, speed 130.00 f/s, time 2.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_144-20251201-0100-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_144-20251201-0100-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 141.000 -> 144.080\n",
            "16092: done 139 games, reward 144.080, eps 0.01, speed 119.55 f/s, time 2.2 min\n",
            "16357: done 140 games, reward 145.560, eps 0.01, speed 129.95 f/s, time 2.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_145-20251201-0101-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_145-20251201-0101-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 144.080 -> 145.560\n",
            "16647: done 141 games, reward 150.840, eps 0.01, speed 128.89 f/s, time 2.3 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_150-20251201-0101-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_150-20251201-0101-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 145.560 -> 150.840\n",
            "16741: done 142 games, reward 149.520, eps 0.01, speed 123.70 f/s, time 2.3 min\n",
            "16891: done 143 games, reward 149.960, eps 0.01, speed 104.20 f/s, time 2.3 min\n",
            "17001: done 144 games, reward 149.080, eps 0.01, speed 97.88 f/s, time 2.3 min\n",
            "17051: done 145 games, reward 148.640, eps 0.01, speed 90.89 f/s, time 2.3 min\n",
            "17404: done 146 games, reward 153.240, eps 0.01, speed 124.50 f/s, time 2.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_153-20251201-0101-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_153-20251201-0101-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 150.840 -> 153.240\n",
            "17589: done 147 games, reward 155.440, eps 0.01, speed 126.51 f/s, time 2.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_155-20251201-0101-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_155-20251201-0101-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 153.240 -> 155.440\n",
            "17640: done 148 games, reward 154.560, eps 0.01, speed 118.27 f/s, time 2.4 min\n",
            "17743: done 149 games, reward 156.320, eps 0.01, speed 127.86 f/s, time 2.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_156-20251201-0101-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_156-20251201-0101-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 155.440 -> 156.320\n",
            "17926: done 150 games, reward 154.120, eps 0.01, speed 126.44 f/s, time 2.5 min\n",
            "18269: done 151 games, reward 159.400, eps 0.01, speed 128.90 f/s, time 2.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_159-20251201-0101-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_159-20251201-0101-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 156.320 -> 159.400\n",
            "18326: done 152 games, reward 158.960, eps 0.01, speed 122.52 f/s, time 2.5 min\n",
            "18373: done 153 games, reward 157.640, eps 0.01, speed 100.40 f/s, time 2.5 min\n",
            "18494: done 154 games, reward 160.280, eps 0.01, speed 95.57 f/s, time 2.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_160-20251201-0101-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_160-20251201-0101-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 159.400 -> 160.280\n",
            "18618: done 155 games, reward 161.600, eps 0.01, speed 86.55 f/s, time 2.6 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_161-20251201-0101-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_161-20251201-0101-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 160.280 -> 161.600\n",
            "18680: done 156 games, reward 159.840, eps 0.01, speed 116.31 f/s, time 2.6 min\n",
            "18797: done 157 games, reward 162.040, eps 0.01, speed 127.48 f/s, time 2.6 min\n",
            "18864: done 158 games, reward 159.840, eps 0.01, speed 122.00 f/s, time 2.6 min\n",
            "19076: done 159 games, reward 157.200, eps 0.01, speed 131.38 f/s, time 2.6 min\n",
            "19220: done 160 games, reward 155.880, eps 0.01, speed 126.09 f/s, time 2.6 min\n",
            "19291: done 161 games, reward 156.320, eps 0.01, speed 129.13 f/s, time 2.7 min\n",
            "19486: done 162 games, reward 158.520, eps 0.01, speed 128.08 f/s, time 2.7 min\n",
            "19594: done 163 games, reward 159.400, eps 0.01, speed 128.08 f/s, time 2.7 min\n",
            "19696: done 164 games, reward 161.160, eps 0.01, speed 126.03 f/s, time 2.7 min\n",
            "19746: done 165 games, reward 159.400, eps 0.01, speed 128.48 f/s, time 2.7 min\n",
            "19863: done 166 games, reward 160.720, eps 0.01, speed 129.27 f/s, time 2.7 min\n",
            "19915: done 167 games, reward 160.280, eps 0.01, speed 102.02 f/s, time 2.7 min\n",
            "19967: done 168 games, reward 158.960, eps 0.01, speed 97.44 f/s, time 2.7 min\n",
            "20134: done 169 games, reward 160.280, eps 0.01, speed 92.85 f/s, time 2.8 min\n",
            "20265: done 170 games, reward 161.160, eps 0.01, speed 112.28 f/s, time 2.8 min\n",
            "20347: done 171 games, reward 158.080, eps 0.01, speed 129.23 f/s, time 2.8 min\n",
            "20509: done 172 games, reward 161.160, eps 0.01, speed 129.67 f/s, time 2.8 min\n",
            "20625: done 173 games, reward 162.040, eps 0.01, speed 129.63 f/s, time 2.8 min\n",
            "20764: done 174 games, reward 158.080, eps 0.01, speed 130.30 f/s, time 2.9 min\n",
            "20895: done 175 games, reward 159.400, eps 0.01, speed 128.98 f/s, time 2.9 min\n",
            "20965: done 176 games, reward 159.400, eps 0.01, speed 130.88 f/s, time 2.9 min\n",
            "21077: done 177 games, reward 160.280, eps 0.01, speed 129.56 f/s, time 2.9 min\n",
            "21194: done 178 games, reward 161.600, eps 0.01, speed 130.01 f/s, time 2.9 min\n",
            "21244: done 179 games, reward 162.040, eps 0.01, speed 133.46 f/s, time 2.9 min\n",
            "21401: done 180 games, reward 162.480, eps 0.01, speed 128.14 f/s, time 2.9 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_162-20251201-0101-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_162-20251201-0101-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 161.600 -> 162.480\n",
            "21546: done 181 games, reward 164.240, eps 0.01, speed 104.40 f/s, time 3.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_164-20251201-0101-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_164-20251201-0101-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 162.480 -> 164.240\n",
            "21596: done 182 games, reward 159.840, eps 0.01, speed 88.65 f/s, time 3.0 min\n",
            "21690: done 183 games, reward 160.280, eps 0.01, speed 92.79 f/s, time 3.0 min\n",
            "21786: done 184 games, reward 162.040, eps 0.01, speed 104.14 f/s, time 3.0 min\n",
            "21835: done 185 games, reward 161.600, eps 0.01, speed 119.99 f/s, time 3.0 min\n",
            "21939: done 186 games, reward 162.480, eps 0.01, speed 130.39 f/s, time 3.0 min\n",
            "22063: done 187 games, reward 161.600, eps 0.01, speed 129.73 f/s, time 3.0 min\n",
            "22230: done 188 games, reward 161.160, eps 0.01, speed 128.88 f/s, time 3.1 min\n",
            "22314: done 189 games, reward 162.040, eps 0.01, speed 130.25 f/s, time 3.1 min\n",
            "22448: done 190 games, reward 162.040, eps 0.01, speed 129.93 f/s, time 3.1 min\n",
            "22503: done 191 games, reward 162.040, eps 0.01, speed 127.76 f/s, time 3.1 min\n",
            "22565: done 192 games, reward 158.960, eps 0.01, speed 129.61 f/s, time 3.1 min\n",
            "22669: done 193 games, reward 160.280, eps 0.01, speed 122.45 f/s, time 3.1 min\n",
            "22874: done 194 games, reward 162.480, eps 0.01, speed 130.42 f/s, time 3.1 min\n",
            "22926: done 195 games, reward 162.040, eps 0.01, speed 127.65 f/s, time 3.2 min\n",
            "23067: done 196 games, reward 162.040, eps 0.01, speed 115.99 f/s, time 3.2 min\n",
            "23118: done 197 games, reward 160.280, eps 0.01, speed 99.36 f/s, time 3.2 min\n",
            "23177: done 198 games, reward 158.520, eps 0.01, speed 93.45 f/s, time 3.2 min\n",
            "23301: done 199 games, reward 157.640, eps 0.01, speed 94.60 f/s, time 3.2 min\n",
            "23351: done 200 games, reward 156.760, eps 0.01, speed 116.92 f/s, time 3.2 min\n",
            "23476: done 201 games, reward 157.640, eps 0.01, speed 126.76 f/s, time 3.2 min\n",
            "23586: done 202 games, reward 157.640, eps 0.01, speed 129.75 f/s, time 3.3 min\n",
            "23724: done 203 games, reward 159.840, eps 0.01, speed 129.07 f/s, time 3.3 min\n",
            "23786: done 204 games, reward 160.280, eps 0.01, speed 129.12 f/s, time 3.3 min\n",
            "23896: done 205 games, reward 159.840, eps 0.01, speed 127.39 f/s, time 3.3 min\n",
            "23948: done 206 games, reward 158.960, eps 0.01, speed 131.78 f/s, time 3.3 min\n",
            "24069: done 207 games, reward 159.840, eps 0.01, speed 129.65 f/s, time 3.3 min\n",
            "24289: done 208 games, reward 160.720, eps 0.01, speed 129.63 f/s, time 3.3 min\n",
            "24339: done 209 games, reward 160.720, eps 0.01, speed 130.98 f/s, time 3.3 min\n",
            "24409: done 210 games, reward 160.720, eps 0.01, speed 128.11 f/s, time 3.4 min\n",
            "24542: done 211 games, reward 160.280, eps 0.01, speed 130.01 f/s, time 3.4 min\n",
            "24616: done 212 games, reward 156.320, eps 0.01, speed 116.97 f/s, time 3.4 min\n",
            "24684: done 213 games, reward 155.240, eps 0.01, speed 97.02 f/s, time 3.4 min\n",
            "24865: done 214 games, reward 157.000, eps 0.01, speed 93.53 f/s, time 3.4 min\n",
            "24983: done 215 games, reward 157.880, eps 0.01, speed 115.67 f/s, time 3.4 min\n",
            "25040: done 216 games, reward 157.000, eps 0.01, speed 125.03 f/s, time 3.5 min\n",
            "25278: done 217 games, reward 160.080, eps 0.01, speed 127.91 f/s, time 3.5 min\n",
            "25339: done 218 games, reward 159.640, eps 0.01, speed 130.04 f/s, time 3.5 min\n",
            "25391: done 219 games, reward 159.640, eps 0.01, speed 126.48 f/s, time 3.5 min\n",
            "25477: done 220 games, reward 160.080, eps 0.01, speed 130.71 f/s, time 3.5 min\n",
            "25542: done 221 games, reward 160.960, eps 0.01, speed 130.35 f/s, time 3.5 min\n",
            "25603: done 222 games, reward 156.560, eps 0.01, speed 128.86 f/s, time 3.5 min\n",
            "25763: done 223 games, reward 158.320, eps 0.01, speed 129.18 f/s, time 3.5 min\n",
            "25847: done 224 games, reward 156.120, eps 0.01, speed 131.19 f/s, time 3.6 min\n",
            "26149: done 225 games, reward 158.320, eps 0.01, speed 130.69 f/s, time 3.6 min\n",
            "26395: done 226 games, reward 157.880, eps 0.01, speed 98.13 f/s, time 3.6 min\n",
            "26459: done 227 games, reward 157.440, eps 0.01, speed 90.41 f/s, time 3.7 min\n",
            "26526: done 228 games, reward 157.440, eps 0.01, speed 123.59 f/s, time 3.7 min\n",
            "26717: done 229 games, reward 157.440, eps 0.01, speed 130.16 f/s, time 3.7 min\n",
            "26804: done 230 games, reward 157.880, eps 0.01, speed 128.13 f/s, time 3.7 min\n",
            "26878: done 231 games, reward 158.320, eps 0.01, speed 127.96 f/s, time 3.7 min\n",
            "26962: done 232 games, reward 157.440, eps 0.01, speed 132.76 f/s, time 3.7 min\n",
            "27016: done 233 games, reward 157.000, eps 0.01, speed 129.69 f/s, time 3.7 min\n",
            "27068: done 234 games, reward 157.000, eps 0.01, speed 130.89 f/s, time 3.7 min\n",
            "27185: done 235 games, reward 156.120, eps 0.01, speed 127.31 f/s, time 3.7 min\n",
            "27248: done 236 games, reward 154.800, eps 0.01, speed 126.51 f/s, time 3.8 min\n",
            "27315: done 237 games, reward 154.800, eps 0.01, speed 125.97 f/s, time 3.8 min\n",
            "27439: done 238 games, reward 150.840, eps 0.01, speed 126.61 f/s, time 3.8 min\n",
            "27491: done 239 games, reward 150.840, eps 0.01, speed 130.21 f/s, time 3.8 min\n",
            "27627: done 240 games, reward 149.800, eps 0.01, speed 127.11 f/s, time 3.8 min\n",
            "27731: done 241 games, reward 146.720, eps 0.01, speed 128.44 f/s, time 3.8 min\n",
            "27791: done 242 games, reward 147.600, eps 0.01, speed 98.18 f/s, time 3.8 min\n",
            "27875: done 243 games, reward 147.160, eps 0.01, speed 97.68 f/s, time 3.8 min\n",
            "27987: done 244 games, reward 143.640, eps 0.01, speed 92.74 f/s, time 3.9 min\n",
            "28222: done 245 games, reward 146.720, eps 0.01, speed 118.64 f/s, time 3.9 min\n",
            "28440: done 246 games, reward 144.760, eps 0.01, speed 129.17 f/s, time 3.9 min\n",
            "28529: done 247 games, reward 141.680, eps 0.01, speed 129.09 f/s, time 3.9 min\n",
            "28703: done 248 games, reward 143.880, eps 0.01, speed 129.06 f/s, time 4.0 min\n",
            "29040: done 249 games, reward 145.640, eps 0.01, speed 129.88 f/s, time 4.0 min\n",
            "29219: done 250 games, reward 145.200, eps 0.01, speed 130.32 f/s, time 4.0 min\n",
            "29299: done 251 games, reward 141.680, eps 0.01, speed 129.97 f/s, time 4.0 min\n",
            "29396: done 252 games, reward 141.680, eps 0.01, speed 99.89 f/s, time 4.0 min\n",
            "29677: done 253 games, reward 143.880, eps 0.01, speed 101.60 f/s, time 4.1 min\n",
            "29785: done 254 games, reward 143.000, eps 0.01, speed 127.70 f/s, time 4.1 min\n",
            "29878: done 255 games, reward 142.560, eps 0.01, speed 128.82 f/s, time 4.1 min\n",
            "30018: done 256 games, reward 143.000, eps 0.01, speed 130.09 f/s, time 4.1 min\n",
            "30163: done 257 games, reward 143.000, eps 0.01, speed 129.74 f/s, time 4.2 min\n",
            "30227: done 258 games, reward 143.000, eps 0.01, speed 129.28 f/s, time 4.2 min\n",
            "30423: done 259 games, reward 143.440, eps 0.01, speed 130.69 f/s, time 4.2 min\n",
            "30510: done 260 games, reward 144.320, eps 0.01, speed 131.29 f/s, time 4.2 min\n",
            "30728: done 261 games, reward 147.400, eps 0.01, speed 129.29 f/s, time 4.2 min\n",
            "30782: done 262 games, reward 143.440, eps 0.01, speed 130.29 f/s, time 4.2 min\n",
            "31404: done 263 games, reward 149.680, eps 0.01, speed 110.21 f/s, time 4.3 min\n",
            "31498: done 264 games, reward 148.400, eps 0.01, speed 131.84 f/s, time 4.3 min\n",
            "31556: done 265 games, reward 148.400, eps 0.01, speed 127.81 f/s, time 4.4 min\n",
            "31705: done 266 games, reward 151.040, eps 0.01, speed 131.24 f/s, time 4.4 min\n",
            "32038: done 267 games, reward 153.240, eps 0.01, speed 130.92 f/s, time 4.4 min\n",
            "32096: done 268 games, reward 153.680, eps 0.01, speed 126.81 f/s, time 4.4 min\n",
            "32210: done 269 games, reward 151.920, eps 0.01, speed 129.36 f/s, time 4.4 min\n",
            "32270: done 270 games, reward 150.600, eps 0.01, speed 131.92 f/s, time 4.4 min\n",
            "32477: done 271 games, reward 153.680, eps 0.01, speed 127.91 f/s, time 4.5 min\n",
            "32557: done 272 games, reward 151.920, eps 0.01, speed 88.85 f/s, time 4.5 min\n",
            "32608: done 273 games, reward 150.160, eps 0.01, speed 86.95 f/s, time 4.5 min\n",
            "32691: done 274 games, reward 149.720, eps 0.01, speed 85.52 f/s, time 4.5 min\n",
            "32855: done 275 games, reward 149.720, eps 0.01, speed 84.51 f/s, time 4.5 min\n",
            "32959: done 276 games, reward 149.720, eps 0.01, speed 83.28 f/s, time 4.6 min\n",
            "33257: done 277 games, reward 151.920, eps 0.01, speed 128.48 f/s, time 4.6 min\n",
            "33437: done 278 games, reward 150.160, eps 0.01, speed 129.69 f/s, time 4.6 min\n",
            "33735: done 279 games, reward 154.560, eps 0.01, speed 130.75 f/s, time 4.7 min\n",
            "33949: done 280 games, reward 152.360, eps 0.01, speed 131.72 f/s, time 4.7 min\n",
            "34067: done 281 games, reward 150.600, eps 0.01, speed 131.29 f/s, time 4.7 min\n",
            "34140: done 282 games, reward 151.040, eps 0.01, speed 126.91 f/s, time 4.7 min\n",
            "34349: done 283 games, reward 153.680, eps 0.01, speed 104.69 f/s, time 4.7 min\n",
            "34560: done 284 games, reward 152.800, eps 0.01, speed 98.76 f/s, time 4.8 min\n",
            "34612: done 285 games, reward 152.360, eps 0.01, speed 130.05 f/s, time 4.8 min\n",
            "34813: done 286 games, reward 155.000, eps 0.01, speed 128.60 f/s, time 4.8 min\n",
            "34965: done 287 games, reward 155.000, eps 0.01, speed 128.78 f/s, time 4.8 min\n",
            "35060: done 288 games, reward 154.560, eps 0.01, speed 130.58 f/s, time 4.8 min\n",
            "35134: done 289 games, reward 154.560, eps 0.01, speed 126.48 f/s, time 4.9 min\n",
            "35302: done 290 games, reward 154.560, eps 0.01, speed 128.97 f/s, time 4.9 min\n",
            "35457: done 291 games, reward 155.000, eps 0.01, speed 129.61 f/s, time 4.9 min\n",
            "35534: done 292 games, reward 155.440, eps 0.01, speed 127.79 f/s, time 4.9 min\n",
            "35706: done 293 games, reward 155.000, eps 0.01, speed 129.90 f/s, time 4.9 min\n",
            "35755: done 294 games, reward 152.800, eps 0.01, speed 127.74 f/s, time 4.9 min\n",
            "35915: done 295 games, reward 155.000, eps 0.01, speed 100.47 f/s, time 5.0 min\n",
            "36053: done 296 games, reward 154.120, eps 0.01, speed 94.94 f/s, time 5.0 min\n",
            "36158: done 297 games, reward 154.120, eps 0.01, speed 113.37 f/s, time 5.0 min\n",
            "36318: done 298 games, reward 155.000, eps 0.01, speed 127.86 f/s, time 5.0 min\n",
            "36621: done 299 games, reward 156.320, eps 0.01, speed 128.95 f/s, time 5.1 min\n",
            "36707: done 300 games, reward 156.760, eps 0.01, speed 131.09 f/s, time 5.1 min\n",
            "36825: done 301 games, reward 157.200, eps 0.01, speed 129.57 f/s, time 5.1 min\n",
            "36929: done 302 games, reward 156.760, eps 0.01, speed 130.26 f/s, time 5.1 min\n",
            "37017: done 303 games, reward 154.120, eps 0.01, speed 128.20 f/s, time 5.1 min\n",
            "37107: done 304 games, reward 155.880, eps 0.01, speed 128.66 f/s, time 5.1 min\n",
            "37297: done 305 games, reward 155.880, eps 0.01, speed 129.15 f/s, time 5.2 min\n",
            "37348: done 306 games, reward 155.880, eps 0.01, speed 130.38 f/s, time 5.2 min\n",
            "37496: done 307 games, reward 157.200, eps 0.01, speed 98.27 f/s, time 5.2 min\n",
            "37583: done 308 games, reward 155.880, eps 0.01, speed 96.98 f/s, time 5.2 min\n",
            "37778: done 309 games, reward 157.640, eps 0.01, speed 110.95 f/s, time 5.2 min\n",
            "38169: done 310 games, reward 160.280, eps 0.01, speed 130.61 f/s, time 5.3 min\n",
            "38326: done 311 games, reward 160.720, eps 0.01, speed 130.66 f/s, time 5.3 min\n",
            "38387: done 312 games, reward 161.160, eps 0.01, speed 130.13 f/s, time 5.3 min\n",
            "38837: done 313 games, reward 162.920, eps 0.01, speed 131.40 f/s, time 5.4 min\n",
            "38972: done 314 games, reward 161.600, eps 0.01, speed 121.87 f/s, time 5.4 min\n",
            "39038: done 315 games, reward 160.720, eps 0.01, speed 95.41 f/s, time 5.4 min\n",
            "39574: done 316 games, reward 164.680, eps 0.01, speed 114.04 f/s, time 5.5 min\n",
            "39768: done 317 games, reward 162.040, eps 0.01, speed 127.44 f/s, time 5.5 min\n",
            "39852: done 318 games, reward 162.480, eps 0.01, speed 130.15 f/s, time 5.5 min\n",
            "39956: done 319 games, reward 164.680, eps 0.01, speed 129.53 f/s, time 5.5 min\n",
            "40070: done 320 games, reward 165.120, eps 0.01, speed 128.90 f/s, time 5.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_165-20251201-0104-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_165-20251201-0104-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 164.240 -> 165.120\n",
            "40184: done 321 games, reward 165.560, eps 0.01, speed 123.09 f/s, time 5.5 min\n",
            "40254: done 322 games, reward 165.560, eps 0.01, speed 129.01 f/s, time 5.6 min\n",
            "40456: done 323 games, reward 166.880, eps 0.01, speed 127.46 f/s, time 5.6 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_166-20251201-0104-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_166-20251201-0104-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 165.120 -> 166.880\n",
            "40535: done 324 games, reward 167.320, eps 0.01, speed 111.72 f/s, time 5.6 min\n",
            "40913: done 325 games, reward 165.120, eps 0.01, speed 101.60 f/s, time 5.7 min\n",
            "41004: done 326 games, reward 161.160, eps 0.01, speed 129.52 f/s, time 5.7 min\n",
            "41182: done 327 games, reward 163.360, eps 0.01, speed 129.80 f/s, time 5.7 min\n",
            "41628: done 328 games, reward 167.320, eps 0.01, speed 126.97 f/s, time 5.8 min\n",
            "41665: done 329 games, reward 165.120, eps 0.01, speed 123.05 f/s, time 5.8 min\n",
            "41853: done 330 games, reward 167.320, eps 0.01, speed 128.32 f/s, time 5.8 min\n",
            "42167: done 331 games, reward 169.520, eps 0.01, speed 119.87 f/s, time 5.8 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_169-20251201-0104-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_169-20251201-0104-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 166.880 -> 169.520\n",
            "42300: done 332 games, reward 169.160, eps 0.01, speed 91.09 f/s, time 5.8 min\n",
            "42623: done 333 games, reward 174.440, eps 0.01, speed 117.78 f/s, time 5.9 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_174-20251201-0104-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_174-20251201-0104-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 169.520 -> 174.440\n",
            "42670: done 334 games, reward 174.880, eps 0.01, speed 121.98 f/s, time 5.9 min\n",
            "42982: done 335 games, reward 174.440, eps 0.01, speed 132.25 f/s, time 5.9 min\n",
            "43115: done 336 games, reward 176.640, eps 0.01, speed 127.44 f/s, time 6.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_176-20251201-0104-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_176-20251201-0104-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 174.440 -> 176.640\n",
            "43193: done 337 games, reward 176.200, eps 0.01, speed 121.61 f/s, time 6.0 min\n",
            "43528: done 338 games, reward 178.400, eps 0.01, speed 128.43 f/s, time 6.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_178-20251201-0104-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_178-20251201-0104-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 176.640 -> 178.400\n",
            "43754: done 339 games, reward 180.160, eps 0.01, speed 107.46 f/s, time 6.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_180-20251201-0104-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_180-20251201-0104-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 178.400 -> 180.160\n",
            "43859: done 340 games, reward 178.840, eps 0.01, speed 93.10 f/s, time 6.1 min\n",
            "43939: done 341 games, reward 177.520, eps 0.01, speed 89.89 f/s, time 6.1 min\n",
            "44036: done 342 games, reward 178.400, eps 0.01, speed 124.99 f/s, time 6.1 min\n",
            "44135: done 343 games, reward 178.840, eps 0.01, speed 125.16 f/s, time 6.1 min\n",
            "44307: done 344 games, reward 181.920, eps 0.01, speed 130.23 f/s, time 6.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_181-20251201-0104-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_181-20251201-0104-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 180.160 -> 181.920\n",
            "44435: done 345 games, reward 181.040, eps 0.01, speed 125.14 f/s, time 6.1 min\n",
            "44512: done 346 games, reward 180.160, eps 0.01, speed 126.88 f/s, time 6.2 min\n",
            "44609: done 347 games, reward 180.600, eps 0.01, speed 126.67 f/s, time 6.2 min\n",
            "44737: done 348 games, reward 179.280, eps 0.01, speed 127.67 f/s, time 6.2 min\n",
            "44963: done 349 games, reward 178.400, eps 0.01, speed 128.47 f/s, time 6.2 min\n",
            "45165: done 350 games, reward 179.720, eps 0.01, speed 128.54 f/s, time 6.2 min\n",
            "45553: done 351 games, reward 183.240, eps 0.01, speed 100.67 f/s, time 6.3 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_183-20251201-0105-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_183-20251201-0105-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 181.920 -> 183.240\n",
            "45608: done 352 games, reward 184.120, eps 0.01, speed 114.01 f/s, time 6.3 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_184-20251201-0105-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_184-20251201-0105-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 183.240 -> 184.120\n",
            "45712: done 353 games, reward 182.360, eps 0.01, speed 124.53 f/s, time 6.3 min\n",
            "45859: done 354 games, reward 182.520, eps 0.01, speed 126.86 f/s, time 6.3 min\n",
            "46010: done 355 games, reward 184.280, eps 0.01, speed 128.51 f/s, time 6.4 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46388: done 356 games, reward 186.480, eps 0.01, speed 118.91 f/s, time 6.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_186-20251201-0105-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_186-20251201-0105-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 184.120 -> 186.480\n",
            "46544: done 357 games, reward 183.840, eps 0.01, speed 127.32 f/s, time 6.4 min\n",
            "46846: done 358 games, reward 188.240, eps 0.01, speed 109.42 f/s, time 6.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_188-20251201-0105-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_188-20251201-0105-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 186.480 -> 188.240\n",
            "47135: done 359 games, reward 186.480, eps 0.01, speed 102.36 f/s, time 6.5 min\n",
            "47286: done 360 games, reward 185.600, eps 0.01, speed 130.78 f/s, time 6.6 min\n",
            "47352: done 361 games, reward 182.120, eps 0.01, speed 127.09 f/s, time 6.6 min\n",
            "47809: done 362 games, reward 189.200, eps 0.01, speed 130.29 f/s, time 6.6 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_189-20251201-0105-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_189-20251201-0105-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 188.240 -> 189.200\n",
            "47850: done 363 games, reward 181.640, eps 0.01, speed 115.53 f/s, time 6.6 min\n",
            "47896: done 364 games, reward 181.160, eps 0.01, speed 128.62 f/s, time 6.6 min\n",
            "48044: done 365 games, reward 182.480, eps 0.01, speed 128.44 f/s, time 6.7 min\n",
            "48094: done 366 games, reward 178.520, eps 0.01, speed 130.92 f/s, time 6.7 min\n",
            "48176: done 367 games, reward 177.640, eps 0.01, speed 129.19 f/s, time 6.7 min\n",
            "48458: done 368 games, reward 182.920, eps 0.01, speed 106.34 f/s, time 6.7 min\n",
            "48555: done 369 games, reward 182.040, eps 0.01, speed 91.21 f/s, time 6.7 min\n",
            "49129: done 370 games, reward 185.840, eps 0.01, speed 126.95 f/s, time 6.8 min\n",
            "49243: done 371 games, reward 183.640, eps 0.01, speed 130.08 f/s, time 6.8 min\n",
            "49421: done 372 games, reward 184.520, eps 0.01, speed 129.40 f/s, time 6.8 min\n",
            "49502: done 373 games, reward 184.960, eps 0.01, speed 126.18 f/s, time 6.9 min\n",
            "49979: done 374 games, reward 191.120, eps 0.01, speed 118.69 f/s, time 6.9 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_191-20251201-0105-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_191-20251201-0105-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 189.200 -> 191.120\n",
            "50063: done 375 games, reward 190.760, eps 0.01, speed 90.43 f/s, time 6.9 min\n",
            "50103: done 376 games, reward 189.880, eps 0.01, speed 89.00 f/s, time 6.9 min\n",
            "50281: done 377 games, reward 189.880, eps 0.01, speed 114.81 f/s, time 7.0 min\n",
            "50382: done 378 games, reward 191.200, eps 0.01, speed 128.98 f/s, time 7.0 min\n",
            "50487: done 379 games, reward 187.800, eps 0.01, speed 128.05 f/s, time 7.0 min\n",
            "50601: done 380 games, reward 189.120, eps 0.01, speed 130.02 f/s, time 7.0 min\n",
            "51135: done 381 games, reward 193.080, eps 0.01, speed 129.04 f/s, time 7.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_193-20251201-0105-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_193-20251201-0105-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 191.120 -> 193.080\n",
            "51197: done 382 games, reward 193.120, eps 0.01, speed 116.13 f/s, time 7.1 min\n",
            "51325: done 383 games, reward 189.600, eps 0.01, speed 127.84 f/s, time 7.1 min\n",
            "51450: done 384 games, reward 189.600, eps 0.01, speed 117.53 f/s, time 7.1 min\n",
            "51589: done 385 games, reward 191.360, eps 0.01, speed 95.45 f/s, time 7.1 min\n",
            "51713: done 386 games, reward 189.600, eps 0.01, speed 94.05 f/s, time 7.2 min\n",
            "51779: done 387 games, reward 190.040, eps 0.01, speed 122.40 f/s, time 7.2 min\n",
            "51831: done 388 games, reward 188.720, eps 0.01, speed 125.47 f/s, time 7.2 min\n",
            "51986: done 389 games, reward 190.040, eps 0.01, speed 127.45 f/s, time 7.2 min\n",
            "52064: done 390 games, reward 188.720, eps 0.01, speed 128.38 f/s, time 7.2 min\n",
            "52122: done 391 games, reward 187.400, eps 0.01, speed 131.08 f/s, time 7.2 min\n",
            "52300: done 392 games, reward 190.920, eps 0.01, speed 129.86 f/s, time 7.2 min\n",
            "52365: done 393 games, reward 189.600, eps 0.01, speed 123.46 f/s, time 7.3 min\n",
            "52442: done 394 games, reward 190.040, eps 0.01, speed 129.73 f/s, time 7.3 min\n",
            "52563: done 395 games, reward 188.720, eps 0.01, speed 128.99 f/s, time 7.3 min\n",
            "52675: done 396 games, reward 188.280, eps 0.01, speed 128.54 f/s, time 7.3 min\n",
            "52727: done 397 games, reward 187.840, eps 0.01, speed 126.44 f/s, time 7.3 min\n",
            "52881: done 398 games, reward 188.280, eps 0.01, speed 130.31 f/s, time 7.3 min\n",
            "52960: done 399 games, reward 186.080, eps 0.01, speed 131.53 f/s, time 7.3 min\n",
            "53034: done 400 games, reward 186.520, eps 0.01, speed 105.73 f/s, time 7.3 min\n",
            "53159: done 401 games, reward 186.080, eps 0.01, speed 97.65 f/s, time 7.4 min\n",
            "53217: done 402 games, reward 185.640, eps 0.01, speed 96.33 f/s, time 7.4 min\n",
            "53321: done 403 games, reward 186.960, eps 0.01, speed 100.93 f/s, time 7.4 min\n",
            "53419: done 404 games, reward 186.080, eps 0.01, speed 129.64 f/s, time 7.4 min\n",
            "53473: done 405 games, reward 184.320, eps 0.01, speed 127.82 f/s, time 7.4 min\n",
            "53680: done 406 games, reward 187.840, eps 0.01, speed 131.08 f/s, time 7.4 min\n",
            "53905: done 407 games, reward 190.480, eps 0.01, speed 128.96 f/s, time 7.5 min\n",
            "54006: done 408 games, reward 189.600, eps 0.01, speed 127.90 f/s, time 7.5 min\n",
            "54198: done 409 games, reward 188.720, eps 0.01, speed 130.43 f/s, time 7.5 min\n",
            "54350: done 410 games, reward 187.400, eps 0.01, speed 128.86 f/s, time 7.5 min\n",
            "54409: done 411 games, reward 185.640, eps 0.01, speed 126.23 f/s, time 7.5 min\n",
            "54548: done 412 games, reward 186.080, eps 0.01, speed 127.27 f/s, time 7.5 min\n",
            "54669: done 413 games, reward 184.760, eps 0.01, speed 99.28 f/s, time 7.6 min\n",
            "54842: done 414 games, reward 185.200, eps 0.01, speed 93.36 f/s, time 7.6 min\n",
            "54923: done 415 games, reward 185.640, eps 0.01, speed 119.43 f/s, time 7.6 min\n",
            "55049: done 416 games, reward 183.880, eps 0.01, speed 126.50 f/s, time 7.6 min\n",
            "55141: done 417 games, reward 181.680, eps 0.01, speed 128.70 f/s, time 7.6 min\n",
            "55329: done 418 games, reward 183.440, eps 0.01, speed 131.44 f/s, time 7.7 min\n",
            "55605: done 419 games, reward 184.760, eps 0.01, speed 128.39 f/s, time 7.7 min\n",
            "55713: done 420 games, reward 183.880, eps 0.01, speed 130.24 f/s, time 7.7 min\n",
            "55761: done 421 games, reward 182.560, eps 0.01, speed 122.15 f/s, time 7.7 min\n",
            "56010: done 422 games, reward 186.960, eps 0.01, speed 125.23 f/s, time 7.8 min\n",
            "56440: done 423 games, reward 183.440, eps 0.01, speed 104.16 f/s, time 7.8 min\n",
            "56528: done 424 games, reward 183.040, eps 0.01, speed 126.86 f/s, time 7.8 min\n",
            "56669: done 425 games, reward 183.920, eps 0.01, speed 128.65 f/s, time 7.9 min\n",
            "56932: done 426 games, reward 188.320, eps 0.01, speed 127.81 f/s, time 7.9 min\n",
            "57185: done 427 games, reward 186.120, eps 0.01, speed 129.83 f/s, time 7.9 min\n",
            "57308: done 428 games, reward 184.800, eps 0.01, speed 129.42 f/s, time 7.9 min\n",
            "57578: done 429 games, reward 187.880, eps 0.01, speed 130.07 f/s, time 8.0 min\n",
            "58138: done 430 games, reward 185.720, eps 0.01, speed 110.18 f/s, time 8.1 min\n",
            "58246: done 431 games, reward 184.840, eps 0.01, speed 128.75 f/s, time 8.1 min\n",
            "58635: done 432 games, reward 187.840, eps 0.01, speed 130.63 f/s, time 8.1 min\n",
            "58708: done 433 games, reward 182.560, eps 0.01, speed 129.84 f/s, time 8.1 min\n",
            "58819: done 434 games, reward 183.000, eps 0.01, speed 129.17 f/s, time 8.1 min\n",
            "58876: done 435 games, reward 182.120, eps 0.01, speed 130.29 f/s, time 8.1 min\n",
            "58975: done 436 games, reward 181.680, eps 0.01, speed 127.12 f/s, time 8.2 min\n",
            "59136: done 437 games, reward 185.640, eps 0.01, speed 129.52 f/s, time 8.2 min\n",
            "59537: done 438 games, reward 185.280, eps 0.01, speed 106.04 f/s, time 8.2 min\n",
            "59676: done 439 games, reward 185.920, eps 0.01, speed 111.80 f/s, time 8.3 min\n",
            "59780: done 440 games, reward 187.680, eps 0.01, speed 127.68 f/s, time 8.3 min\n",
            "59959: done 441 games, reward 189.440, eps 0.01, speed 129.46 f/s, time 8.3 min\n",
            "60033: done 442 games, reward 187.680, eps 0.01, speed 126.88 f/s, time 8.3 min\n",
            "60137: done 443 games, reward 188.120, eps 0.01, speed 118.16 f/s, time 8.3 min\n",
            "60191: done 444 games, reward 184.600, eps 0.01, speed 97.53 f/s, time 8.3 min\n",
            "60336: done 445 games, reward 184.600, eps 0.01, speed 96.88 f/s, time 8.4 min\n",
            "60465: done 446 games, reward 184.600, eps 0.01, speed 104.96 f/s, time 8.4 min\n",
            "60760: done 447 games, reward 186.800, eps 0.01, speed 127.36 f/s, time 8.4 min\n",
            "60879: done 448 games, reward 187.680, eps 0.01, speed 96.07 f/s, time 8.4 min\n",
            "60935: done 449 games, reward 185.040, eps 0.01, speed 94.83 f/s, time 8.5 min\n",
            "61093: done 450 games, reward 185.920, eps 0.01, speed 102.53 f/s, time 8.5 min\n",
            "61144: done 451 games, reward 181.080, eps 0.01, speed 125.76 f/s, time 8.5 min\n",
            "61275: done 452 games, reward 182.840, eps 0.01, speed 129.16 f/s, time 8.5 min\n",
            "61389: done 453 games, reward 183.720, eps 0.01, speed 131.26 f/s, time 8.5 min\n",
            "61490: done 454 games, reward 183.120, eps 0.01, speed 130.13 f/s, time 8.5 min\n",
            "61597: done 455 games, reward 181.360, eps 0.01, speed 129.27 f/s, time 8.5 min\n",
            "61795: done 456 games, reward 180.480, eps 0.01, speed 130.24 f/s, time 8.6 min\n",
            "62239: done 457 games, reward 184.440, eps 0.01, speed 130.40 f/s, time 8.6 min\n",
            "62467: done 458 games, reward 182.080, eps 0.01, speed 107.85 f/s, time 8.7 min\n",
            "62594: done 459 games, reward 184.720, eps 0.01, speed 93.86 f/s, time 8.7 min\n",
            "62974: done 460 games, reward 187.800, eps 0.01, speed 126.71 f/s, time 8.7 min\n",
            "63014: done 461 games, reward 187.320, eps 0.01, speed 129.22 f/s, time 8.7 min\n",
            "63107: done 462 games, reward 181.560, eps 0.01, speed 125.51 f/s, time 8.7 min\n",
            "63301: done 463 games, reward 184.640, eps 0.01, speed 126.78 f/s, time 8.8 min\n",
            "63696: done 464 games, reward 186.840, eps 0.01, speed 130.77 f/s, time 8.8 min\n",
            "63925: done 465 games, reward 189.040, eps 0.01, speed 124.28 f/s, time 8.9 min\n",
            "64273: done 466 games, reward 192.120, eps 0.01, speed 101.63 f/s, time 8.9 min\n",
            "64553: done 467 games, reward 194.160, eps 0.01, speed 128.39 f/s, time 8.9 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_194-20251201-0107-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_194-20251201-0107-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 193.080 -> 194.160\n",
            "64647: done 468 games, reward 190.200, eps 0.01, speed 121.91 f/s, time 9.0 min\n",
            "64754: done 469 games, reward 190.200, eps 0.01, speed 129.99 f/s, time 9.0 min\n",
            "64840: done 470 games, reward 186.840, eps 0.01, speed 128.77 f/s, time 9.0 min\n",
            "65130: done 471 games, reward 191.240, eps 0.01, speed 127.96 f/s, time 9.0 min\n",
            "65522: done 472 games, reward 189.040, eps 0.01, speed 125.98 f/s, time 9.1 min\n",
            "65593: done 473 games, reward 189.040, eps 0.01, speed 95.03 f/s, time 9.1 min\n",
            "65731: done 474 games, reward 185.080, eps 0.01, speed 93.86 f/s, time 9.1 min\n",
            "66257: done 475 games, reward 188.080, eps 0.01, speed 125.34 f/s, time 9.2 min\n",
            "66397: done 476 games, reward 188.080, eps 0.01, speed 130.06 f/s, time 9.2 min\n",
            "66576: done 477 games, reward 187.640, eps 0.01, speed 127.84 f/s, time 9.2 min\n",
            "66729: done 478 games, reward 187.200, eps 0.01, speed 129.83 f/s, time 9.2 min\n",
            "67081: done 479 games, reward 186.640, eps 0.01, speed 125.17 f/s, time 9.3 min\n",
            "67393: done 480 games, reward 190.600, eps 0.01, speed 99.77 f/s, time 9.3 min\n",
            "67722: done 481 games, reward 186.640, eps 0.01, speed 130.46 f/s, time 9.4 min\n",
            "67862: done 482 games, reward 186.640, eps 0.01, speed 129.45 f/s, time 9.4 min\n",
            "68195: done 483 games, reward 190.600, eps 0.01, speed 130.50 f/s, time 9.4 min\n",
            "68506: done 484 games, reward 191.560, eps 0.01, speed 130.04 f/s, time 9.5 min\n",
            "68571: done 485 games, reward 190.280, eps 0.01, speed 128.10 f/s, time 9.5 min\n",
            "68762: done 486 games, reward 191.600, eps 0.01, speed 105.69 f/s, time 9.5 min\n",
            "68959: done 487 games, reward 192.480, eps 0.01, speed 99.02 f/s, time 9.6 min\n",
            "69357: done 488 games, reward 192.480, eps 0.01, speed 130.27 f/s, time 9.6 min\n",
            "69522: done 489 games, reward 194.240, eps 0.01, speed 127.76 f/s, time 9.6 min\n",
            "70389: done 490 games, reward 196.000, eps 0.01, speed 122.57 f/s, time 9.7 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_196-20251201-0108-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_196-20251201-0108-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 194.160 -> 196.000\n",
            "70758: done 491 games, reward 199.880, eps 0.01, speed 109.37 f/s, time 9.8 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_199-20251201-0108-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_199-20251201-0108-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 196.000 -> 199.880\n",
            "70950: done 492 games, reward 199.000, eps 0.01, speed 125.00 f/s, time 9.8 min\n",
            "71291: done 493 games, reward 202.080, eps 0.01, speed 129.97 f/s, time 9.9 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_202-20251201-0108-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_202-20251201-0108-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 199.880 -> 202.080\n",
            "71335: done 494 games, reward 201.200, eps 0.01, speed 116.02 f/s, time 9.9 min\n",
            "71726: done 495 games, reward 206.040, eps 0.01, speed 126.90 f/s, time 9.9 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_206-20251201-0108-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_206-20251201-0108-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 202.080 -> 206.040\n",
            "71979: done 496 games, reward 206.480, eps 0.01, speed 99.10 f/s, time 10.0 min\n",
            "72116: done 497 games, reward 208.880, eps 0.01, speed 99.80 f/s, time 10.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_208-20251201-0108-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_208-20251201-0108-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 206.040 -> 208.880\n",
            "72403: done 498 games, reward 211.080, eps 0.01, speed 123.72 f/s, time 10.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_211-20251201-0108-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_211-20251201-0108-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 208.880 -> 211.080\n",
            "72477: done 499 games, reward 211.080, eps 0.01, speed 120.97 f/s, time 10.0 min\n",
            "72806: done 500 games, reward 212.480, eps 0.01, speed 128.41 f/s, time 10.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_212-20251201-0108-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_212-20251201-0108-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 211.080 -> 212.480\n",
            "73006: done 501 games, reward 214.240, eps 0.01, speed 126.13 f/s, time 10.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_214-20251201-0108-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_214-20251201-0108-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 212.480 -> 214.240\n",
            "73117: done 502 games, reward 214.240, eps 0.01, speed 124.75 f/s, time 10.1 min\n",
            "73218: done 503 games, reward 213.800, eps 0.01, speed 129.16 f/s, time 10.1 min\n",
            "73512: done 504 games, reward 216.000, eps 0.01, speed 103.49 f/s, time 10.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_216-20251201-0108-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_216-20251201-0108-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 214.240 -> 216.000\n",
            "73753: done 505 games, reward 218.640, eps 0.01, speed 107.04 f/s, time 10.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_218-20251201-0109-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_218-20251201-0109-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 216.000 -> 218.640\n",
            "73863: done 506 games, reward 216.600, eps 0.01, speed 122.07 f/s, time 10.2 min\n",
            "74027: done 507 games, reward 213.520, eps 0.01, speed 124.26 f/s, time 10.3 min\n",
            "74138: done 508 games, reward 213.520, eps 0.01, speed 128.77 f/s, time 10.3 min\n",
            "74402: done 509 games, reward 216.600, eps 0.01, speed 129.33 f/s, time 10.3 min\n",
            "74749: done 510 games, reward 220.120, eps 0.01, speed 124.56 f/s, time 10.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_220-20251201-0109-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_220-20251201-0109-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 218.640 -> 220.120\n",
            "75077: done 511 games, reward 221.000, eps 0.01, speed 104.91 f/s, time 10.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_221-20251201-0109-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_221-20251201-0109-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 220.120 -> 221.000\n",
            "75193: done 512 games, reward 220.160, eps 0.01, speed 97.36 f/s, time 10.4 min\n",
            "75333: done 513 games, reward 221.040, eps 0.01, speed 127.63 f/s, time 10.4 min\n",
            "75847: done 514 games, reward 222.360, eps 0.01, speed 130.50 f/s, time 10.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_222-20251201-0109-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_222-20251201-0109-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 221.000 -> 222.360\n",
            "75887: done 515 games, reward 221.480, eps 0.01, speed 115.43 f/s, time 10.5 min\n",
            "76072: done 516 games, reward 221.920, eps 0.01, speed 126.53 f/s, time 10.5 min\n",
            "76207: done 517 games, reward 223.680, eps 0.01, speed 129.81 f/s, time 10.6 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_223-20251201-0109-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_223-20251201-0109-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 222.360 -> 223.680\n",
            "76298: done 518 games, reward 222.800, eps 0.01, speed 121.50 f/s, time 10.6 min\n",
            "76496: done 519 games, reward 221.040, eps 0.01, speed 110.17 f/s, time 10.6 min\n",
            "76672: done 520 games, reward 222.360, eps 0.01, speed 93.02 f/s, time 10.6 min\n",
            "76938: done 521 games, reward 224.560, eps 0.01, speed 123.11 f/s, time 10.7 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_224-20251201-0109-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_224-20251201-0109-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 223.680 -> 224.560\n",
            "77133: done 522 games, reward 221.040, eps 0.01, speed 123.45 f/s, time 10.7 min\n",
            "77329: done 523 games, reward 222.360, eps 0.01, speed 128.81 f/s, time 10.7 min\n",
            "77384: done 524 games, reward 221.880, eps 0.01, speed 128.01 f/s, time 10.7 min\n",
            "78031: done 525 games, reward 226.720, eps 0.01, speed 123.47 f/s, time 10.8 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_226-20251201-0109-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_226-20251201-0109-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 224.560 -> 226.720\n",
            "78115: done 526 games, reward 222.320, eps 0.01, speed 92.37 f/s, time 10.8 min\n",
            "78161: done 527 games, reward 221.880, eps 0.01, speed 94.09 f/s, time 10.8 min\n",
            "78312: done 528 games, reward 221.880, eps 0.01, speed 102.52 f/s, time 10.9 min\n",
            "78413: done 529 games, reward 220.120, eps 0.01, speed 126.62 f/s, time 10.9 min\n",
            "78514: done 530 games, reward 220.520, eps 0.01, speed 127.91 f/s, time 10.9 min\n",
            "78695: done 531 games, reward 219.640, eps 0.01, speed 128.43 f/s, time 10.9 min\n",
            "78934: done 532 games, reward 220.520, eps 0.01, speed 130.01 f/s, time 10.9 min\n",
            "78983: done 533 games, reward 220.520, eps 0.01, speed 124.02 f/s, time 11.0 min\n",
            "79181: done 534 games, reward 221.840, eps 0.01, speed 130.32 f/s, time 11.0 min\n",
            "79230: done 535 games, reward 221.840, eps 0.01, speed 128.29 f/s, time 11.0 min\n",
            "79317: done 536 games, reward 220.080, eps 0.01, speed 126.28 f/s, time 11.0 min\n",
            "79586: done 537 games, reward 217.880, eps 0.01, speed 119.91 f/s, time 11.0 min\n",
            "79705: done 538 games, reward 216.040, eps 0.01, speed 95.17 f/s, time 11.1 min\n",
            "79761: done 539 games, reward 214.080, eps 0.01, speed 96.62 f/s, time 11.1 min\n",
            "79956: done 540 games, reward 213.200, eps 0.01, speed 113.71 f/s, time 11.1 min\n",
            "80195: done 541 games, reward 215.400, eps 0.01, speed 130.11 f/s, time 11.1 min\n",
            "80363: done 542 games, reward 219.280, eps 0.01, speed 129.79 f/s, time 11.1 min\n",
            "80457: done 543 games, reward 219.280, eps 0.01, speed 128.21 f/s, time 11.2 min\n",
            "80626: done 544 games, reward 221.040, eps 0.01, speed 129.94 f/s, time 11.2 min\n",
            "80735: done 545 games, reward 219.720, eps 0.01, speed 130.21 f/s, time 11.2 min\n",
            "80986: done 546 games, reward 222.800, eps 0.01, speed 130.95 f/s, time 11.2 min\n",
            "81041: done 547 games, reward 219.720, eps 0.01, speed 127.60 f/s, time 11.2 min\n",
            "81200: done 548 games, reward 219.280, eps 0.01, speed 109.28 f/s, time 11.3 min\n",
            "81583: done 549 games, reward 223.240, eps 0.01, speed 107.02 f/s, time 11.3 min\n",
            "81631: done 550 games, reward 221.040, eps 0.01, speed 130.60 f/s, time 11.3 min\n",
            "81779: done 551 games, reward 222.360, eps 0.01, speed 130.79 f/s, time 11.3 min\n",
            "81956: done 552 games, reward 221.920, eps 0.01, speed 130.72 f/s, time 11.4 min\n",
            "82195: done 553 games, reward 223.680, eps 0.01, speed 130.45 f/s, time 11.4 min\n",
            "82253: done 554 games, reward 222.800, eps 0.01, speed 128.24 f/s, time 11.4 min\n",
            "82427: done 555 games, reward 224.120, eps 0.01, speed 129.02 f/s, time 11.4 min\n",
            "82573: done 556 games, reward 223.240, eps 0.01, speed 129.89 f/s, time 11.4 min\n",
            "82792: done 557 games, reward 221.040, eps 0.01, speed 112.72 f/s, time 11.5 min\n",
            "83098: done 558 games, reward 222.080, eps 0.01, speed 104.64 f/s, time 11.5 min\n",
            "83183: done 559 games, reward 219.880, eps 0.01, speed 131.35 f/s, time 11.5 min\n",
            "83274: done 560 games, reward 216.800, eps 0.01, speed 128.09 f/s, time 11.5 min\n",
            "83546: done 561 games, reward 218.560, eps 0.01, speed 129.20 f/s, time 11.6 min\n",
            "83669: done 562 games, reward 219.000, eps 0.01, speed 130.66 f/s, time 11.6 min\n",
            "83748: done 563 games, reward 216.800, eps 0.01, speed 130.14 f/s, time 11.6 min\n",
            "84125: done 564 games, reward 218.560, eps 0.01, speed 129.12 f/s, time 11.7 min\n",
            "84177: done 565 games, reward 215.040, eps 0.01, speed 124.55 f/s, time 11.7 min\n",
            "84271: done 566 games, reward 214.600, eps 0.01, speed 130.54 f/s, time 11.7 min\n",
            "84469: done 567 games, reward 213.000, eps 0.01, speed 95.59 f/s, time 11.7 min\n",
            "84528: done 568 games, reward 211.680, eps 0.01, speed 91.47 f/s, time 11.7 min\n",
            "84784: done 569 games, reward 216.080, eps 0.01, speed 122.93 f/s, time 11.8 min\n",
            "84896: done 570 games, reward 215.680, eps 0.01, speed 125.17 f/s, time 11.8 min\n",
            "85134: done 571 games, reward 213.480, eps 0.01, speed 128.58 f/s, time 11.8 min\n",
            "85189: done 572 games, reward 213.040, eps 0.01, speed 130.56 f/s, time 11.8 min\n",
            "85268: done 573 games, reward 213.480, eps 0.01, speed 126.22 f/s, time 11.8 min\n",
            "85570: done 574 games, reward 217.000, eps 0.01, speed 129.21 f/s, time 11.9 min\n",
            "85763: done 575 games, reward 215.400, eps 0.01, speed 130.85 f/s, time 11.9 min\n",
            "85807: done 576 games, reward 215.400, eps 0.01, speed 126.80 f/s, time 11.9 min\n",
            "85931: done 577 games, reward 213.200, eps 0.01, speed 103.40 f/s, time 11.9 min\n",
            "86098: done 578 games, reward 214.960, eps 0.01, speed 95.40 f/s, time 11.9 min\n",
            "86261: done 579 games, reward 214.960, eps 0.01, speed 118.65 f/s, time 12.0 min\n",
            "86343: done 580 games, reward 211.440, eps 0.01, speed 131.04 f/s, time 12.0 min\n",
            "86397: done 581 games, reward 210.120, eps 0.01, speed 125.82 f/s, time 12.0 min\n",
            "86466: done 582 games, reward 210.080, eps 0.01, speed 131.32 f/s, time 12.0 min\n",
            "86736: done 583 games, reward 209.200, eps 0.01, speed 128.12 f/s, time 12.0 min\n",
            "86813: done 584 games, reward 206.920, eps 0.01, speed 125.08 f/s, time 12.0 min\n",
            "86899: done 585 games, reward 207.760, eps 0.01, speed 128.72 f/s, time 12.0 min\n",
            "87067: done 586 games, reward 206.000, eps 0.01, speed 129.18 f/s, time 12.1 min\n",
            "87239: done 587 games, reward 206.000, eps 0.01, speed 130.49 f/s, time 12.1 min\n",
            "87385: done 588 games, reward 208.200, eps 0.01, speed 129.70 f/s, time 12.1 min\n",
            "87789: done 589 games, reward 209.960, eps 0.01, speed 102.27 f/s, time 12.2 min\n",
            "88022: done 590 games, reward 209.160, eps 0.01, speed 129.63 f/s, time 12.2 min\n",
            "88142: done 591 games, reward 206.280, eps 0.01, speed 106.20 f/s, time 12.2 min\n",
            "88525: done 592 games, reward 208.040, eps 0.01, speed 104.34 f/s, time 12.3 min\n",
            "88596: done 593 games, reward 204.960, eps 0.01, speed 127.62 f/s, time 12.3 min\n",
            "88795: done 594 games, reward 205.840, eps 0.01, speed 130.83 f/s, time 12.3 min\n",
            "88942: done 595 games, reward 201.880, eps 0.01, speed 110.54 f/s, time 12.3 min\n",
            "89048: done 596 games, reward 203.640, eps 0.01, speed 95.37 f/s, time 12.4 min\n",
            "89157: done 597 games, reward 202.560, eps 0.01, speed 92.60 f/s, time 12.4 min\n",
            "89355: done 598 games, reward 200.800, eps 0.01, speed 127.67 f/s, time 12.4 min\n",
            "89492: done 599 games, reward 202.120, eps 0.01, speed 128.46 f/s, time 12.4 min\n",
            "89782: done 600 games, reward 205.920, eps 0.01, speed 131.11 f/s, time 12.5 min\n",
            "90122: done 601 games, reward 207.680, eps 0.01, speed 129.16 f/s, time 12.5 min\n",
            "90203: done 602 games, reward 208.120, eps 0.01, speed 131.44 f/s, time 12.5 min\n",
            "90293: done 603 games, reward 207.240, eps 0.01, speed 128.30 f/s, time 12.5 min\n",
            "90418: done 604 games, reward 205.480, eps 0.01, speed 127.79 f/s, time 12.5 min\n",
            "90469: done 605 games, reward 202.400, eps 0.01, speed 105.58 f/s, time 12.5 min\n",
            "90794: done 606 games, reward 206.280, eps 0.01, speed 100.33 f/s, time 12.6 min\n",
            "91286: done 607 games, reward 212.560, eps 0.01, speed 129.24 f/s, time 12.7 min\n",
            "91343: done 608 games, reward 212.640, eps 0.01, speed 126.27 f/s, time 12.7 min\n",
            "91466: done 609 games, reward 210.600, eps 0.01, speed 128.41 f/s, time 12.7 min\n",
            "91924: done 610 games, reward 211.920, eps 0.01, speed 130.69 f/s, time 12.7 min\n",
            "92069: done 611 games, reward 212.040, eps 0.01, speed 112.19 f/s, time 12.8 min\n",
            "92175: done 612 games, reward 213.000, eps 0.01, speed 92.53 f/s, time 12.8 min\n",
            "92525: done 613 games, reward 216.080, eps 0.01, speed 112.20 f/s, time 12.8 min\n",
            "92626: done 614 games, reward 212.560, eps 0.01, speed 124.32 f/s, time 12.9 min\n",
            "93112: done 615 games, reward 220.200, eps 0.01, speed 128.90 f/s, time 12.9 min\n",
            "93692: done 616 games, reward 227.040, eps 0.01, speed 122.35 f/s, time 13.0 min\n",
            "93774: done 617 games, reward 226.280, eps 0.01, speed 94.60 f/s, time 13.0 min\n",
            "93920: done 618 games, reward 225.960, eps 0.01, speed 99.31 f/s, time 13.0 min\n",
            "94085: done 619 games, reward 225.960, eps 0.01, speed 127.96 f/s, time 13.1 min\n",
            "94278: done 620 games, reward 226.840, eps 0.01, speed 128.80 f/s, time 13.1 min\n",
            "94577: done 621 games, reward 230.280, eps 0.01, speed 129.72 f/s, time 13.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_230-20251201-0111-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_230-20251201-0111-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 226.720 -> 230.280\n",
            "94772: done 622 games, reward 230.280, eps 0.01, speed 125.98 f/s, time 13.1 min\n",
            "94968: done 623 games, reward 230.280, eps 0.01, speed 129.73 f/s, time 13.2 min\n",
            "95146: done 624 games, reward 232.480, eps 0.01, speed 128.76 f/s, time 13.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_232-20251201-0111-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_232-20251201-0111-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 230.280 -> 232.480\n",
            "95291: done 625 games, reward 230.280, eps 0.01, speed 93.29 f/s, time 13.2 min\n",
            "95841: done 626 games, reward 237.760, eps 0.01, speed 114.72 f/s, time 13.3 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_237-20251201-0112-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_237-20251201-0112-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 232.480 -> 237.760\n",
            "95892: done 627 games, reward 237.760, eps 0.01, speed 118.05 f/s, time 13.3 min\n",
            "96431: done 628 games, reward 241.280, eps 0.01, speed 128.39 f/s, time 13.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_241-20251201-0112-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_241-20251201-0112-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 237.760 -> 241.280\n",
            "96538: done 629 games, reward 240.400, eps 0.01, speed 123.23 f/s, time 13.4 min\n",
            "96659: done 630 games, reward 240.080, eps 0.01, speed 128.93 f/s, time 13.4 min\n",
            "96843: done 631 games, reward 241.400, eps 0.01, speed 100.08 f/s, time 13.4 min\n",
            "97063: done 632 games, reward 239.200, eps 0.01, speed 101.52 f/s, time 13.5 min\n",
            "97122: done 633 games, reward 240.080, eps 0.01, speed 126.93 f/s, time 13.5 min\n",
            "97458: done 634 games, reward 244.480, eps 0.01, speed 128.57 f/s, time 13.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_244-20251201-0112-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_244-20251201-0112-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 241.280 -> 244.480\n",
            "97532: done 635 games, reward 245.440, eps 0.01, speed 121.50 f/s, time 13.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_245-20251201-0112-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_245-20251201-0112-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 244.480 -> 245.440\n",
            "97578: done 636 games, reward 245.480, eps 0.01, speed 113.37 f/s, time 13.5 min\n",
            "97800: done 637 games, reward 247.680, eps 0.01, speed 128.58 f/s, time 13.6 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_247-20251201-0112-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_247-20251201-0112-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 245.440 -> 247.680\n",
            "98114: done 638 games, reward 249.520, eps 0.01, speed 129.05 f/s, time 13.6 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_249-20251201-0112-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_249-20251201-0112-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 247.680 -> 249.520\n",
            "98321: done 639 games, reward 253.400, eps 0.01, speed 108.30 f/s, time 13.6 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_253-20251201-0112-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_253-20251201-0112-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 249.520 -> 253.400\n",
            "98772: done 640 games, reward 258.240, eps 0.01, speed 106.44 f/s, time 13.7 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_258-20251201-0112-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_258-20251201-0112-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 253.400 -> 258.240\n",
            "99052: done 641 games, reward 257.720, eps 0.01, speed 124.70 f/s, time 13.7 min\n",
            "99121: done 642 games, reward 254.840, eps 0.01, speed 126.75 f/s, time 13.8 min\n",
            "99339: done 643 games, reward 255.280, eps 0.01, speed 125.59 f/s, time 13.8 min\n",
            "99656: done 644 games, reward 257.040, eps 0.01, speed 127.90 f/s, time 13.8 min\n",
            "99715: done 645 games, reward 256.600, eps 0.01, speed 125.86 f/s, time 13.8 min\n",
            "99920: done 646 games, reward 254.840, eps 0.01, speed 102.07 f/s, time 13.9 min\n",
            "100093: done 647 games, reward 257.480, eps 0.01, speed 99.42 f/s, time 13.9 min\n",
            "100282: done 648 games, reward 257.080, eps 0.01, speed 129.68 f/s, time 13.9 min\n",
            "100416: done 649 games, reward 254.880, eps 0.01, speed 129.76 f/s, time 13.9 min\n",
            "100588: done 650 games, reward 256.640, eps 0.01, speed 129.83 f/s, time 14.0 min\n",
            "100691: done 651 games, reward 256.200, eps 0.01, speed 128.55 f/s, time 14.0 min\n",
            "101151: done 652 games, reward 261.080, eps 0.01, speed 129.67 f/s, time 14.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_261-20251201-0112-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_261-20251201-0112-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 258.240 -> 261.080\n",
            "101196: done 653 games, reward 258.000, eps 0.01, speed 115.56 f/s, time 14.0 min\n",
            "101237: done 654 games, reward 257.560, eps 0.01, speed 126.84 f/s, time 14.0 min\n",
            "101391: done 655 games, reward 258.000, eps 0.01, speed 113.44 f/s, time 14.1 min\n",
            "101445: done 656 games, reward 256.680, eps 0.01, speed 95.85 f/s, time 14.1 min\n",
            "101579: done 657 games, reward 257.120, eps 0.01, speed 95.63 f/s, time 14.1 min\n",
            "101663: done 658 games, reward 254.480, eps 0.01, speed 104.49 f/s, time 14.1 min\n",
            "101730: done 659 games, reward 253.600, eps 0.01, speed 129.56 f/s, time 14.1 min\n",
            "101807: done 660 games, reward 253.160, eps 0.01, speed 125.15 f/s, time 14.1 min\n",
            "102053: done 661 games, reward 256.240, eps 0.01, speed 128.28 f/s, time 14.2 min\n",
            "102360: done 662 games, reward 261.040, eps 0.01, speed 126.40 f/s, time 14.2 min\n",
            "102427: done 663 games, reward 260.640, eps 0.01, speed 125.97 f/s, time 14.2 min\n",
            "102700: done 664 games, reward 261.960, eps 0.01, speed 128.41 f/s, time 14.3 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_261-20251201-0113-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_261-20251201-0113-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 261.080 -> 261.960\n",
            "102747: done 665 games, reward 261.960, eps 0.01, speed 118.08 f/s, time 14.3 min\n",
            "102814: done 666 games, reward 259.760, eps 0.01, speed 124.24 f/s, time 14.3 min\n",
            "102902: done 667 games, reward 260.200, eps 0.01, speed 120.82 f/s, time 14.3 min\n",
            "103057: done 668 games, reward 261.520, eps 0.01, speed 94.41 f/s, time 14.3 min\n",
            "103236: done 669 games, reward 259.760, eps 0.01, speed 102.33 f/s, time 14.3 min\n",
            "103386: done 670 games, reward 261.040, eps 0.01, speed 128.11 f/s, time 14.4 min\n",
            "103607: done 671 games, reward 262.360, eps 0.01, speed 131.21 f/s, time 14.4 min\n",
            "103746: done 672 games, reward 263.800, eps 0.01, speed 127.91 f/s, time 14.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_263-20251201-0113-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_263-20251201-0113-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 261.960 -> 263.800\n",
            "104514: done 673 games, reward 269.080, eps 0.01, speed 124.97 f/s, time 14.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_269-20251201-0113-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_269-20251201-0113-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 263.800 -> 269.080\n",
            "104851: done 674 games, reward 263.840, eps 0.01, speed 101.04 f/s, time 14.6 min\n",
            "105068: done 675 games, reward 264.840, eps 0.01, speed 127.51 f/s, time 14.6 min\n",
            "105410: done 676 games, reward 269.680, eps 0.01, speed 128.75 f/s, time 14.6 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_269-20251201-0113-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_269-20251201-0113-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 269.080 -> 269.680\n",
            "105703: done 677 games, reward 270.120, eps 0.01, speed 126.07 f/s, time 14.7 min\n",
            "105764: done 678 games, reward 266.160, eps 0.01, speed 129.34 f/s, time 14.7 min\n",
            "105956: done 679 games, reward 267.480, eps 0.01, speed 128.63 f/s, time 14.7 min\n",
            "106027: done 680 games, reward 266.600, eps 0.01, speed 124.19 f/s, time 14.7 min\n",
            "106126: done 681 games, reward 266.600, eps 0.01, speed 94.91 f/s, time 14.7 min\n",
            "106297: done 682 games, reward 269.680, eps 0.01, speed 89.95 f/s, time 14.8 min\n",
            "106803: done 683 games, reward 273.080, eps 0.01, speed 127.30 f/s, time 14.8 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_273-20251201-0113-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_273-20251201-0113-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 269.680 -> 273.080\n",
            "106856: done 684 games, reward 272.680, eps 0.01, speed 118.45 f/s, time 14.8 min\n",
            "107038: done 685 games, reward 275.320, eps 0.01, speed 129.36 f/s, time 14.9 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_275-20251201-0113-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_275-20251201-0113-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 273.080 -> 275.320\n",
            "107123: done 686 games, reward 275.320, eps 0.01, speed 124.34 f/s, time 14.9 min\n",
            "107199: done 687 games, reward 273.560, eps 0.01, speed 126.81 f/s, time 14.9 min\n",
            "107289: done 688 games, reward 272.680, eps 0.01, speed 127.67 f/s, time 14.9 min\n",
            "107396: done 689 games, reward 268.720, eps 0.01, speed 129.67 f/s, time 14.9 min\n",
            "107645: done 690 games, reward 269.960, eps 0.01, speed 118.81 f/s, time 14.9 min\n",
            "107866: done 691 games, reward 273.800, eps 0.01, speed 92.60 f/s, time 15.0 min\n",
            "108223: done 692 games, reward 274.680, eps 0.01, speed 126.00 f/s, time 15.0 min\n",
            "108299: done 693 games, reward 275.120, eps 0.01, speed 124.92 f/s, time 15.0 min\n",
            "108400: done 694 games, reward 275.680, eps 0.01, speed 127.54 f/s, time 15.1 min\n",
            "108518: done 695 games, reward 275.240, eps 0.01, speed 127.82 f/s, time 15.1 min\n",
            "108741: done 696 games, reward 276.120, eps 0.01, speed 129.14 f/s, time 15.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_276-20251201-0113-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_276-20251201-0113-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 275.320 -> 276.120\n",
            "108797: done 697 games, reward 274.800, eps 0.01, speed 118.33 f/s, time 15.1 min\n",
            "109036: done 698 games, reward 275.680, eps 0.01, speed 128.64 f/s, time 15.1 min\n",
            "109119: done 699 games, reward 274.360, eps 0.01, speed 129.96 f/s, time 15.1 min\n",
            "109175: done 700 games, reward 268.280, eps 0.01, speed 101.47 f/s, time 15.2 min\n",
            "109414: done 701 games, reward 266.520, eps 0.01, speed 94.20 f/s, time 15.2 min\n",
            "109638: done 702 games, reward 268.280, eps 0.01, speed 122.94 f/s, time 15.2 min\n",
            "109692: done 703 games, reward 268.280, eps 0.01, speed 127.56 f/s, time 15.2 min\n",
            "109809: done 704 games, reward 268.280, eps 0.01, speed 127.53 f/s, time 15.2 min\n",
            "109917: done 705 games, reward 269.600, eps 0.01, speed 128.86 f/s, time 15.3 min\n",
            "110249: done 706 games, reward 267.800, eps 0.01, speed 129.36 f/s, time 15.3 min\n",
            "110484: done 707 games, reward 264.160, eps 0.01, speed 128.87 f/s, time 15.3 min\n",
            "110624: done 708 games, reward 264.520, eps 0.01, speed 129.40 f/s, time 15.4 min\n",
            "110825: done 709 games, reward 264.920, eps 0.01, speed 107.38 f/s, time 15.4 min\n",
            "110993: done 710 games, reward 259.640, eps 0.01, speed 92.63 f/s, time 15.4 min\n",
            "111052: done 711 games, reward 258.640, eps 0.01, speed 128.43 f/s, time 15.4 min\n",
            "111106: done 712 games, reward 257.200, eps 0.01, speed 125.98 f/s, time 15.4 min\n",
            "111214: done 713 games, reward 252.800, eps 0.01, speed 130.14 f/s, time 15.4 min\n",
            "111436: done 714 games, reward 255.440, eps 0.01, speed 128.62 f/s, time 15.5 min\n",
            "111701: done 715 games, reward 251.440, eps 0.01, speed 130.10 f/s, time 15.5 min\n",
            "111876: done 716 games, reward 244.600, eps 0.01, speed 129.97 f/s, time 15.5 min\n",
            "112160: done 717 games, reward 247.120, eps 0.01, speed 130.09 f/s, time 15.6 min\n",
            "112204: done 718 games, reward 245.680, eps 0.01, speed 124.42 f/s, time 15.6 min\n",
            "112527: done 719 games, reward 248.760, eps 0.01, speed 102.73 f/s, time 15.6 min\n",
            "112579: done 720 games, reward 246.560, eps 0.01, speed 94.06 f/s, time 15.6 min\n",
            "112976: done 721 games, reward 246.160, eps 0.01, speed 128.95 f/s, time 15.7 min\n",
            "113165: done 722 games, reward 247.480, eps 0.01, speed 129.12 f/s, time 15.7 min\n",
            "113310: done 723 games, reward 247.040, eps 0.01, speed 128.38 f/s, time 15.7 min\n",
            "113499: done 724 games, reward 247.120, eps 0.01, speed 129.88 f/s, time 15.8 min\n",
            "113815: done 725 games, reward 249.320, eps 0.01, speed 127.52 f/s, time 15.8 min\n",
            "113862: done 726 games, reward 241.400, eps 0.01, speed 125.04 f/s, time 15.8 min\n",
            "114018: done 727 games, reward 242.800, eps 0.01, speed 94.46 f/s, time 15.8 min\n",
            "114122: done 728 games, reward 237.960, eps 0.01, speed 89.88 f/s, time 15.8 min\n",
            "114231: done 729 games, reward 239.720, eps 0.01, speed 115.65 f/s, time 15.9 min\n",
            "114422: done 730 games, reward 241.360, eps 0.01, speed 126.82 f/s, time 15.9 min\n",
            "114698: done 731 games, reward 244.000, eps 0.01, speed 127.44 f/s, time 15.9 min\n",
            "114902: done 732 games, reward 242.680, eps 0.01, speed 130.02 f/s, time 15.9 min\n",
            "115137: done 733 games, reward 245.160, eps 0.01, speed 127.07 f/s, time 16.0 min\n",
            "115268: done 734 games, reward 240.320, eps 0.01, speed 123.83 f/s, time 16.0 min\n",
            "115573: done 735 games, reward 244.200, eps 0.01, speed 107.61 f/s, time 16.0 min\n",
            "115905: done 736 games, reward 249.960, eps 0.01, speed 110.52 f/s, time 16.1 min\n",
            "116323: done 737 games, reward 252.160, eps 0.01, speed 129.34 f/s, time 16.1 min\n",
            "116363: done 738 games, reward 249.000, eps 0.01, speed 108.18 f/s, time 16.2 min\n",
            "116554: done 739 games, reward 249.480, eps 0.01, speed 95.08 f/s, time 16.2 min\n",
            "117162: done 740 games, reward 249.480, eps 0.01, speed 104.18 f/s, time 16.3 min\n",
            "117314: done 741 games, reward 246.600, eps 0.01, speed 124.35 f/s, time 16.3 min\n",
            "117356: done 742 games, reward 245.160, eps 0.01, speed 127.84 f/s, time 16.3 min\n",
            "117848: done 743 games, reward 250.000, eps 0.01, speed 129.71 f/s, time 16.4 min\n",
            "117991: done 744 games, reward 247.440, eps 0.01, speed 130.42 f/s, time 16.4 min\n",
            "118068: done 745 games, reward 248.000, eps 0.01, speed 127.12 f/s, time 16.4 min\n",
            "118272: done 746 games, reward 248.440, eps 0.01, speed 127.61 f/s, time 16.4 min\n",
            "118502: done 747 games, reward 248.880, eps 0.01, speed 115.90 f/s, time 16.5 min\n",
            "118576: done 748 games, reward 248.960, eps 0.01, speed 92.64 f/s, time 16.5 min\n",
            "118973: done 749 games, reward 252.480, eps 0.01, speed 112.98 f/s, time 16.5 min\n",
            "119045: done 750 games, reward 250.720, eps 0.01, speed 128.16 f/s, time 16.5 min\n",
            "119290: done 751 games, reward 251.240, eps 0.01, speed 130.84 f/s, time 16.6 min\n",
            "119435: done 752 games, reward 245.480, eps 0.01, speed 130.14 f/s, time 16.6 min\n",
            "119530: done 753 games, reward 246.360, eps 0.01, speed 128.60 f/s, time 16.6 min\n",
            "120095: done 754 games, reward 254.120, eps 0.01, speed 123.76 f/s, time 16.7 min\n",
            "120546: done 755 games, reward 257.200, eps 0.01, speed 109.48 f/s, time 16.8 min\n",
            "120862: done 756 games, reward 262.920, eps 0.01, speed 127.76 f/s, time 16.8 min\n",
            "120988: done 757 games, reward 262.200, eps 0.01, speed 125.94 f/s, time 16.8 min\n",
            "121254: done 758 games, reward 263.080, eps 0.01, speed 128.78 f/s, time 16.8 min\n",
            "121431: done 759 games, reward 265.280, eps 0.01, speed 129.13 f/s, time 16.9 min\n",
            "121513: done 760 games, reward 266.160, eps 0.01, speed 127.47 f/s, time 16.9 min\n",
            "121670: done 761 games, reward 264.400, eps 0.01, speed 107.24 f/s, time 16.9 min\n",
            "121951: done 762 games, reward 261.360, eps 0.01, speed 101.89 f/s, time 16.9 min\n",
            "122232: done 763 games, reward 268.080, eps 0.01, speed 128.09 f/s, time 17.0 min\n",
            "122731: done 764 games, reward 268.520, eps 0.01, speed 128.51 f/s, time 17.0 min\n",
            "123093: done 765 games, reward 271.320, eps 0.01, speed 130.20 f/s, time 17.1 min\n",
            "123286: done 766 games, reward 276.160, eps 0.01, speed 103.59 f/s, time 17.1 min\n",
            "123369: done 767 games, reward 275.280, eps 0.01, speed 96.45 f/s, time 17.1 min\n",
            "123706: done 768 games, reward 278.800, eps 0.01, speed 116.33 f/s, time 17.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_278-20251201-0115-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_278-20251201-0115-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 276.120 -> 278.800\n",
            "123886: done 769 games, reward 280.000, eps 0.01, speed 125.84 f/s, time 17.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_280-20251201-0116-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_280-20251201-0116-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 278.800 -> 280.000\n",
            "124043: done 770 games, reward 279.560, eps 0.01, speed 126.74 f/s, time 17.2 min\n",
            "124571: done 771 games, reward 280.000, eps 0.01, speed 128.49 f/s, time 17.3 min\n",
            "124671: done 772 games, reward 278.560, eps 0.01, speed 127.81 f/s, time 17.3 min\n",
            "124877: done 773 games, reward 276.360, eps 0.01, speed 101.98 f/s, time 17.3 min\n",
            "125346: done 774 games, reward 278.080, eps 0.01, speed 114.82 f/s, time 17.4 min\n",
            "125396: done 775 games, reward 274.720, eps 0.01, speed 130.54 f/s, time 17.4 min\n",
            "125865: done 776 games, reward 276.480, eps 0.01, speed 128.32 f/s, time 17.5 min\n",
            "126182: done 777 games, reward 280.960, eps 0.01, speed 128.31 f/s, time 17.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_280-20251201-0116-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_280-20251201-0116-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 280.000 -> 280.960\n",
            "126258: done 778 games, reward 281.920, eps 0.01, speed 118.18 f/s, time 17.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_281-20251201-0116-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_281-20251201-0116-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 280.960 -> 281.920\n",
            "126384: done 779 games, reward 281.040, eps 0.01, speed 96.35 f/s, time 17.6 min\n",
            "126463: done 780 games, reward 280.600, eps 0.01, speed 95.10 f/s, time 17.6 min\n",
            "126589: done 781 games, reward 281.040, eps 0.01, speed 97.49 f/s, time 17.6 min\n",
            "126713: done 782 games, reward 279.280, eps 0.01, speed 126.96 f/s, time 17.6 min\n",
            "127011: done 783 games, reward 277.200, eps 0.01, speed 129.73 f/s, time 17.6 min\n",
            "127104: done 784 games, reward 277.680, eps 0.01, speed 127.16 f/s, time 17.7 min\n",
            "127289: done 785 games, reward 275.040, eps 0.01, speed 129.05 f/s, time 17.7 min\n",
            "127446: done 786 games, reward 276.360, eps 0.01, speed 126.69 f/s, time 17.7 min\n",
            "127579: done 787 games, reward 276.800, eps 0.01, speed 128.48 f/s, time 17.7 min\n",
            "127860: done 788 games, reward 279.240, eps 0.01, speed 125.69 f/s, time 17.8 min\n",
            "128418: done 789 games, reward 283.640, eps 0.01, speed 108.30 f/s, time 17.8 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_283-20251201-0116-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_283-20251201-0116-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 281.920 -> 283.640\n",
            "128471: done 790 games, reward 281.000, eps 0.01, speed 120.80 f/s, time 17.9 min\n",
            "128967: done 791 games, reward 282.920, eps 0.01, speed 128.85 f/s, time 17.9 min\n",
            "129068: done 792 games, reward 278.520, eps 0.01, speed 130.55 f/s, time 17.9 min\n",
            "129773: done 793 games, reward 286.760, eps 0.01, speed 111.61 f/s, time 18.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_286-20251201-0116-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_286-20251201-0116-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 283.640 -> 286.760\n",
            "129911: done 794 games, reward 288.200, eps 0.01, speed 121.13 f/s, time 18.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_288-20251201-0116-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_288-20251201-0116-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 286.760 -> 288.200\n",
            "130325: done 795 games, reward 293.040, eps 0.01, speed 128.47 f/s, time 18.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_293-20251201-0116-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_293-20251201-0116-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 288.200 -> 293.040\n",
            "130532: done 796 games, reward 290.440, eps 0.01, speed 126.87 f/s, time 18.1 min\n",
            "130606: done 797 games, reward 290.920, eps 0.01, speed 123.44 f/s, time 18.1 min\n",
            "131563: done 798 games, reward 301.200, eps 0.01, speed 114.70 f/s, time 18.3 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_301-20251201-0117-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_301-20251201-0117-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 293.040 -> 301.200\n",
            "131613: done 799 games, reward 300.840, eps 0.01, speed 118.23 f/s, time 18.3 min\n",
            "131768: done 800 games, reward 301.880, eps 0.01, speed 124.63 f/s, time 18.3 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_301-20251201-0117-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_301-20251201-0117-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 301.200 -> 301.880\n",
            "131960: done 801 games, reward 301.000, eps 0.01, speed 124.69 f/s, time 18.3 min\n",
            "132228: done 802 games, reward 301.440, eps 0.01, speed 128.53 f/s, time 18.4 min\n",
            "132509: done 803 games, reward 302.840, eps 0.01, speed 129.87 f/s, time 18.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_302-20251201-0117-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_302-20251201-0117-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 301.880 -> 302.840\n",
            "133401: done 804 games, reward 310.080, eps 0.01, speed 113.63 f/s, time 18.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_310-20251201-0117-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_310-20251201-0117-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 302.840 -> 310.080\n",
            "133469: done 805 games, reward 309.240, eps 0.01, speed 117.20 f/s, time 18.5 min\n",
            "133590: done 806 games, reward 307.160, eps 0.01, speed 127.89 f/s, time 18.6 min\n",
            "133745: done 807 games, reward 304.520, eps 0.01, speed 127.84 f/s, time 18.6 min\n",
            "133796: done 808 games, reward 303.640, eps 0.01, speed 124.18 f/s, time 18.6 min\n",
            "134005: done 809 games, reward 303.520, eps 0.01, speed 130.69 f/s, time 18.6 min\n",
            "134206: done 810 games, reward 304.840, eps 0.01, speed 106.43 f/s, time 18.6 min\n",
            "134942: done 811 games, reward 315.560, eps 0.01, speed 117.71 f/s, time 18.8 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_315-20251201-0117-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_315-20251201-0117-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 310.080 -> 315.560\n",
            "135277: done 812 games, reward 321.280, eps 0.01, speed 127.00 f/s, time 18.8 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_321-20251201-0117-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_321-20251201-0117-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 315.560 -> 321.280\n",
            "135407: done 813 games, reward 322.600, eps 0.01, speed 120.32 f/s, time 18.8 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_322-20251201-0117-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_322-20251201-0117-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 321.280 -> 322.600\n",
            "135456: done 814 games, reward 319.960, eps 0.01, speed 116.06 f/s, time 18.8 min\n",
            "135509: done 815 games, reward 316.320, eps 0.01, speed 127.33 f/s, time 18.8 min\n",
            "135762: done 816 games, reward 318.520, eps 0.01, speed 107.39 f/s, time 18.9 min\n",
            "136055: done 817 games, reward 316.320, eps 0.01, speed 106.31 f/s, time 18.9 min\n",
            "136167: done 818 games, reward 317.280, eps 0.01, speed 119.45 f/s, time 18.9 min\n",
            "136494: done 819 games, reward 318.160, eps 0.01, speed 130.00 f/s, time 19.0 min\n",
            "136577: done 820 games, reward 317.720, eps 0.01, speed 129.38 f/s, time 19.0 min\n",
            "136679: done 821 games, reward 314.880, eps 0.01, speed 128.93 f/s, time 19.0 min\n",
            "137124: done 822 games, reward 318.400, eps 0.01, speed 129.25 f/s, time 19.1 min\n",
            "137220: done 823 games, reward 316.200, eps 0.01, speed 113.85 f/s, time 19.1 min\n",
            "137434: done 824 games, reward 316.800, eps 0.01, speed 94.00 f/s, time 19.1 min\n",
            "137801: done 825 games, reward 316.800, eps 0.01, speed 121.99 f/s, time 19.2 min\n",
            "137887: done 826 games, reward 317.240, eps 0.01, speed 128.67 f/s, time 19.2 min\n",
            "138023: done 827 games, reward 317.280, eps 0.01, speed 129.59 f/s, time 19.2 min\n",
            "138534: done 828 games, reward 322.560, eps 0.01, speed 129.41 f/s, time 19.2 min\n",
            "138834: done 829 games, reward 323.720, eps 0.01, speed 117.67 f/s, time 19.3 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_323-20251201-0118-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_323-20251201-0118-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 322.600 -> 323.720\n",
            "139043: done 830 games, reward 324.000, eps 0.01, speed 90.63 f/s, time 19.3 min\n",
            "139363: done 831 games, reward 324.880, eps 0.01, speed 128.28 f/s, time 19.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_324-20251201-0118-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_324-20251201-0118-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 323.720 -> 324.880\n",
            "139422: done 832 games, reward 324.000, eps 0.01, speed 117.03 f/s, time 19.4 min\n",
            "139556: done 833 games, reward 323.520, eps 0.01, speed 128.36 f/s, time 19.4 min\n",
            "139660: done 834 games, reward 323.520, eps 0.01, speed 126.76 f/s, time 19.4 min\n",
            "139730: done 835 games, reward 320.000, eps 0.01, speed 130.20 f/s, time 19.4 min\n",
            "140106: done 836 games, reward 318.240, eps 0.01, speed 127.00 f/s, time 19.5 min\n",
            "140217: done 837 games, reward 312.600, eps 0.01, speed 125.69 f/s, time 19.5 min\n",
            "140479: done 838 games, reward 317.440, eps 0.01, speed 104.84 f/s, time 19.5 min\n",
            "140840: done 839 games, reward 317.280, eps 0.01, speed 114.23 f/s, time 19.6 min\n",
            "140929: done 840 games, reward 312.120, eps 0.01, speed 120.95 f/s, time 19.6 min\n",
            "141367: done 841 games, reward 317.280, eps 0.01, speed 128.58 f/s, time 19.6 min\n",
            "141407: done 842 games, reward 317.280, eps 0.01, speed 124.59 f/s, time 19.7 min\n",
            "141632: done 843 games, reward 314.520, eps 0.01, speed 130.08 f/s, time 19.7 min\n",
            "141737: done 844 games, reward 315.000, eps 0.01, speed 128.43 f/s, time 19.7 min\n",
            "141936: done 845 games, reward 314.440, eps 0.01, speed 115.89 f/s, time 19.7 min\n",
            "141983: done 846 games, reward 310.920, eps 0.01, speed 96.00 f/s, time 19.7 min\n",
            "142475: done 847 games, reward 314.040, eps 0.01, speed 111.61 f/s, time 19.8 min\n",
            "142790: done 848 games, reward 317.880, eps 0.01, speed 128.81 f/s, time 19.8 min\n",
            "143090: done 849 games, reward 317.760, eps 0.01, speed 128.97 f/s, time 19.9 min\n",
            "143161: done 850 games, reward 318.280, eps 0.01, speed 127.12 f/s, time 19.9 min\n",
            "143359: done 851 games, reward 319.520, eps 0.01, speed 129.45 f/s, time 19.9 min\n",
            "143794: done 852 games, reward 323.160, eps 0.01, speed 102.82 f/s, time 20.0 min\n",
            "143837: done 853 games, reward 322.280, eps 0.01, speed 124.86 f/s, time 20.0 min\n",
            "143985: done 854 games, reward 317.160, eps 0.01, speed 126.87 f/s, time 20.0 min\n",
            "144039: done 855 games, reward 311.440, eps 0.01, speed 128.00 f/s, time 20.0 min\n",
            "144534: done 856 games, reward 310.680, eps 0.01, speed 128.97 f/s, time 20.1 min\n",
            "144888: done 857 games, reward 313.600, eps 0.01, speed 128.90 f/s, time 20.1 min\n",
            "145131: done 858 games, reward 312.720, eps 0.01, speed 97.06 f/s, time 20.2 min\n",
            "145491: done 859 games, reward 317.240, eps 0.01, speed 87.07 f/s, time 20.2 min\n",
            "146278: done 860 games, reward 327.280, eps 0.01, speed 128.54 f/s, time 20.3 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_327-20251201-0119-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_327-20251201-0119-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 324.880 -> 327.280\n",
            "146522: done 861 games, reward 327.080, eps 0.01, speed 127.68 f/s, time 20.4 min\n",
            "146581: done 862 games, reward 324.080, eps 0.01, speed 125.36 f/s, time 20.4 min\n",
            "146830: done 863 games, reward 321.280, eps 0.01, speed 111.39 f/s, time 20.4 min\n",
            "146901: done 864 games, reward 316.440, eps 0.01, speed 95.70 f/s, time 20.4 min\n",
            "147007: done 865 games, reward 314.520, eps 0.01, speed 91.20 f/s, time 20.5 min\n",
            "147681: done 866 games, reward 316.320, eps 0.01, speed 128.14 f/s, time 20.5 min\n",
            "147738: done 867 games, reward 315.960, eps 0.01, speed 130.15 f/s, time 20.5 min\n",
            "147957: done 868 games, reward 314.040, eps 0.01, speed 129.51 f/s, time 20.6 min\n",
            "148118: done 869 games, reward 311.960, eps 0.01, speed 128.42 f/s, time 20.6 min\n",
            "148730: done 870 games, reward 317.400, eps 0.01, speed 110.86 f/s, time 20.7 min\n",
            "148891: done 871 games, reward 317.400, eps 0.01, speed 127.78 f/s, time 20.7 min\n",
            "149471: done 872 games, reward 324.480, eps 0.01, speed 128.18 f/s, time 20.8 min\n",
            "149526: done 873 games, reward 321.960, eps 0.01, speed 129.57 f/s, time 20.8 min\n",
            "149568: done 874 games, reward 319.320, eps 0.01, speed 125.85 f/s, time 20.8 min\n",
            "149960: done 875 games, reward 325.480, eps 0.01, speed 119.78 f/s, time 20.9 min\n",
            "150246: done 876 games, reward 322.200, eps 0.01, speed 102.89 f/s, time 20.9 min\n",
            "150314: done 877 games, reward 316.440, eps 0.01, speed 127.36 f/s, time 20.9 min\n",
            "150881: done 878 games, reward 325.440, eps 0.01, speed 126.96 f/s, time 21.0 min\n",
            "150921: done 879 games, reward 324.120, eps 0.01, speed 128.48 f/s, time 21.0 min\n",
            "150988: done 880 games, reward 324.160, eps 0.01, speed 125.04 f/s, time 21.0 min\n",
            "151468: done 881 games, reward 331.280, eps 0.01, speed 125.69 f/s, time 21.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_331-20251201-0119-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_331-20251201-0119-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 327.280 -> 331.280\n",
            "151613: done 882 games, reward 333.840, eps 0.01, speed 94.21 f/s, time 21.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_333-20251201-0119-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_333-20251201-0119-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 331.280 -> 333.840\n",
            "151796: done 883 games, reward 330.440, eps 0.01, speed 102.32 f/s, time 21.1 min\n",
            "152146: done 884 games, reward 335.200, eps 0.01, speed 126.84 f/s, time 21.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_335-20251201-0119-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_335-20251201-0119-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 333.840 -> 335.200\n",
            "152407: done 885 games, reward 338.600, eps 0.01, speed 125.30 f/s, time 21.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_338-20251201-0119-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_338-20251201-0119-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 335.200 -> 338.600\n",
            "152462: done 886 games, reward 336.440, eps 0.01, speed 107.98 f/s, time 21.2 min\n",
            "152592: done 887 games, reward 337.760, eps 0.01, speed 129.37 f/s, time 21.2 min\n",
            "152842: done 888 games, reward 337.080, eps 0.01, speed 127.38 f/s, time 21.3 min\n",
            "153053: done 889 games, reward 332.800, eps 0.01, speed 113.14 f/s, time 21.3 min\n",
            "153184: done 890 games, reward 334.120, eps 0.01, speed 94.75 f/s, time 21.3 min\n",
            "153802: done 891 games, reward 332.240, eps 0.01, speed 121.93 f/s, time 21.4 min\n",
            "153889: done 892 games, reward 331.880, eps 0.01, speed 128.73 f/s, time 21.4 min\n",
            "154313: done 893 games, reward 329.360, eps 0.01, speed 129.08 f/s, time 21.5 min\n",
            "154496: done 894 games, reward 327.920, eps 0.01, speed 128.54 f/s, time 21.5 min\n",
            "155098: done 895 games, reward 330.640, eps 0.01, speed 110.08 f/s, time 21.6 min\n",
            "155554: done 896 games, reward 336.800, eps 0.01, speed 129.32 f/s, time 21.6 min\n",
            "155660: done 897 games, reward 336.320, eps 0.01, speed 129.75 f/s, time 21.6 min\n",
            "155880: done 898 games, reward 324.920, eps 0.01, speed 129.53 f/s, time 21.7 min\n",
            "156372: done 899 games, reward 331.480, eps 0.01, speed 110.40 f/s, time 21.7 min\n",
            "156449: done 900 games, reward 331.880, eps 0.01, speed 100.49 f/s, time 21.8 min\n",
            "156616: done 901 games, reward 331.640, eps 0.01, speed 128.70 f/s, time 21.8 min\n",
            "157254: done 902 games, reward 335.200, eps 0.01, speed 129.05 f/s, time 21.9 min\n",
            "157440: done 903 games, reward 338.120, eps 0.01, speed 129.19 f/s, time 21.9 min\n",
            "157614: done 904 games, reward 331.520, eps 0.01, speed 127.14 f/s, time 21.9 min\n",
            "158294: done 905 games, reward 339.560, eps 0.01, speed 111.81 f/s, time 22.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_339-20251201-0120-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_339-20251201-0120-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 338.600 -> 339.560\n",
            "158380: done 906 games, reward 339.560, eps 0.01, speed 125.65 f/s, time 22.0 min\n",
            "158470: done 907 games, reward 338.760, eps 0.01, speed 128.18 f/s, time 22.0 min\n",
            "158642: done 908 games, reward 340.960, eps 0.01, speed 129.23 f/s, time 22.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_340-20251201-0120-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_340-20251201-0120-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 339.560 -> 340.960\n",
            "158751: done 909 games, reward 340.960, eps 0.01, speed 124.45 f/s, time 22.1 min\n",
            "158852: done 910 games, reward 339.640, eps 0.01, speed 128.81 f/s, time 22.1 min\n",
            "159077: done 911 games, reward 333.320, eps 0.01, speed 129.91 f/s, time 22.1 min\n",
            "159302: done 912 games, reward 331.760, eps 0.01, speed 122.55 f/s, time 22.1 min\n",
            "159437: done 913 games, reward 331.520, eps 0.01, speed 95.54 f/s, time 22.2 min\n",
            "159528: done 914 games, reward 332.840, eps 0.01, speed 88.94 f/s, time 22.2 min\n",
            "159666: done 915 games, reward 333.280, eps 0.01, speed 117.11 f/s, time 22.2 min\n",
            "159882: done 916 games, reward 332.400, eps 0.01, speed 130.53 f/s, time 22.2 min\n",
            "160326: done 917 games, reward 335.920, eps 0.01, speed 129.30 f/s, time 22.3 min\n",
            "160399: done 918 games, reward 335.400, eps 0.01, speed 131.13 f/s, time 22.3 min\n",
            "160632: done 919 games, reward 330.120, eps 0.01, speed 128.08 f/s, time 22.3 min\n",
            "161116: done 920 games, reward 336.280, eps 0.01, speed 107.89 f/s, time 22.4 min\n",
            "161222: done 921 games, reward 335.800, eps 0.01, speed 120.60 f/s, time 22.4 min\n",
            "161410: done 922 games, reward 332.080, eps 0.01, speed 129.49 f/s, time 22.4 min\n",
            "161683: done 923 games, reward 337.360, eps 0.01, speed 130.32 f/s, time 22.5 min\n",
            "161913: done 924 games, reward 336.280, eps 0.01, speed 132.01 f/s, time 22.5 min\n",
            "162050: done 925 games, reward 330.600, eps 0.01, speed 130.03 f/s, time 22.5 min\n",
            "162712: done 926 games, reward 340.600, eps 0.01, speed 111.72 f/s, time 22.6 min\n",
            "162976: done 927 games, reward 342.520, eps 0.01, speed 127.19 f/s, time 22.7 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_342-20251201-0121-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_342-20251201-0121-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 340.960 -> 342.520\n",
            "163072: done 928 games, reward 338.000, eps 0.01, speed 123.05 f/s, time 22.7 min\n",
            "163213: done 929 games, reward 336.840, eps 0.01, speed 126.33 f/s, time 22.7 min\n",
            "163571: done 930 games, reward 337.880, eps 0.01, speed 130.32 f/s, time 22.7 min\n",
            "163808: done 931 games, reward 336.040, eps 0.01, speed 128.99 f/s, time 22.8 min\n",
            "163909: done 932 games, reward 336.920, eps 0.01, speed 130.17 f/s, time 22.8 min\n",
            "164142: done 933 games, reward 338.440, eps 0.01, speed 105.73 f/s, time 22.8 min\n",
            "164214: done 934 games, reward 337.120, eps 0.01, speed 89.05 f/s, time 22.8 min\n",
            "164561: done 935 games, reward 341.960, eps 0.01, speed 118.92 f/s, time 22.9 min\n",
            "164727: done 936 games, reward 337.920, eps 0.01, speed 130.12 f/s, time 22.9 min\n",
            "164868: done 937 games, reward 339.840, eps 0.01, speed 129.27 f/s, time 22.9 min\n",
            "165065: done 938 games, reward 341.160, eps 0.01, speed 128.41 f/s, time 22.9 min\n",
            "165380: done 939 games, reward 339.840, eps 0.01, speed 130.15 f/s, time 23.0 min\n",
            "165445: done 940 games, reward 338.880, eps 0.01, speed 128.90 f/s, time 23.0 min\n",
            "165602: done 941 games, reward 334.920, eps 0.01, speed 120.78 f/s, time 23.0 min\n",
            "165774: done 942 games, reward 336.680, eps 0.01, speed 96.89 f/s, time 23.0 min\n",
            "166019: done 943 games, reward 335.040, eps 0.01, speed 111.60 f/s, time 23.1 min\n",
            "166152: done 944 games, reward 336.680, eps 0.01, speed 129.59 f/s, time 23.1 min\n",
            "167215: done 945 games, reward 353.800, eps 0.01, speed 127.52 f/s, time 23.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_353-20251201-0122-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_353-20251201-0122-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 342.520 -> 353.800\n",
            "167262: done 946 games, reward 353.800, eps 0.01, speed 83.99 f/s, time 23.2 min\n",
            "167377: done 947 games, reward 348.920, eps 0.01, speed 95.81 f/s, time 23.3 min\n",
            "167842: done 948 games, reward 350.360, eps 0.01, speed 121.97 f/s, time 23.3 min\n",
            "168051: done 949 games, reward 350.480, eps 0.01, speed 129.78 f/s, time 23.4 min\n",
            "168233: done 950 games, reward 352.160, eps 0.01, speed 130.62 f/s, time 23.4 min\n",
            "168574: done 951 games, reward 353.520, eps 0.01, speed 129.05 f/s, time 23.4 min\n",
            "168693: done 952 games, reward 350.000, eps 0.01, speed 128.18 f/s, time 23.4 min\n",
            "169402: done 953 games, reward 360.920, eps 0.01, speed 111.80 f/s, time 23.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_360-20251201-0122-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_360-20251201-0122-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 353.800 -> 360.920\n",
            "169544: done 954 games, reward 361.160, eps 0.01, speed 125.15 f/s, time 23.6 min\n",
            "169894: done 955 games, reward 365.400, eps 0.01, speed 130.64 f/s, time 23.6 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_365-20251201-0122-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_365-20251201-0122-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 360.920 -> 365.400\n",
            "169999: done 956 games, reward 362.200, eps 0.01, speed 122.93 f/s, time 23.6 min\n",
            "170077: done 957 games, reward 358.680, eps 0.01, speed 124.14 f/s, time 23.6 min\n",
            "170317: done 958 games, reward 360.440, eps 0.01, speed 123.82 f/s, time 23.7 min\n",
            "170496: done 959 games, reward 357.680, eps 0.01, speed 97.32 f/s, time 23.7 min\n",
            "170610: done 960 games, reward 347.200, eps 0.01, speed 93.66 f/s, time 23.7 min\n",
            "170836: done 961 games, reward 346.520, eps 0.01, speed 130.28 f/s, time 23.7 min\n",
            "171005: done 962 games, reward 348.200, eps 0.01, speed 128.70 f/s, time 23.8 min\n",
            "171116: done 963 games, reward 345.120, eps 0.01, speed 131.87 f/s, time 23.8 min\n",
            "171209: done 964 games, reward 345.120, eps 0.01, speed 128.22 f/s, time 23.8 min\n",
            "171427: done 965 games, reward 347.320, eps 0.01, speed 127.16 f/s, time 23.8 min\n",
            "171519: done 966 games, reward 342.000, eps 0.01, speed 131.49 f/s, time 23.8 min\n",
            "171822: done 967 games, reward 342.800, eps 0.01, speed 130.30 f/s, time 23.9 min\n",
            "171924: done 968 games, reward 340.760, eps 0.01, speed 105.98 f/s, time 23.9 min\n",
            "172020: done 969 games, reward 339.880, eps 0.01, speed 97.03 f/s, time 23.9 min\n",
            "172202: done 970 games, reward 334.880, eps 0.01, speed 102.18 f/s, time 23.9 min\n",
            "172399: done 971 games, reward 333.560, eps 0.01, speed 127.59 f/s, time 24.0 min\n",
            "172681: done 972 games, reward 329.600, eps 0.01, speed 129.73 f/s, time 24.0 min\n",
            "172725: done 973 games, reward 328.160, eps 0.01, speed 129.59 f/s, time 24.0 min\n",
            "172852: done 974 games, reward 330.800, eps 0.01, speed 129.80 f/s, time 24.0 min\n",
            "173054: done 975 games, reward 327.280, eps 0.01, speed 128.72 f/s, time 24.0 min\n",
            "173265: done 976 games, reward 324.840, eps 0.01, speed 128.87 f/s, time 24.1 min\n",
            "173571: done 977 games, reward 330.520, eps 0.01, speed 111.64 f/s, time 24.1 min\n",
            "173752: done 978 games, reward 322.440, eps 0.01, speed 98.49 f/s, time 24.1 min\n",
            "173813: done 979 games, reward 323.400, eps 0.01, speed 92.34 f/s, time 24.2 min\n",
            "173978: done 980 games, reward 326.000, eps 0.01, speed 94.04 f/s, time 24.2 min\n",
            "175480: done 981 games, reward 334.360, eps 0.01, speed 119.01 f/s, time 24.4 min\n",
            "175649: done 982 games, reward 332.120, eps 0.01, speed 130.49 f/s, time 24.4 min\n",
            "176128: done 983 games, reward 337.760, eps 0.01, speed 130.02 f/s, time 24.5 min\n",
            "176405: done 984 games, reward 336.840, eps 0.01, speed 129.92 f/s, time 24.5 min\n",
            "176547: done 985 games, reward 333.080, eps 0.01, speed 112.36 f/s, time 24.5 min\n",
            "177198: done 986 games, reward 341.600, eps 0.01, speed 114.73 f/s, time 24.6 min\n",
            "177465: done 987 games, reward 342.800, eps 0.01, speed 129.35 f/s, time 24.7 min\n",
            "177864: done 988 games, reward 344.400, eps 0.01, speed 130.26 f/s, time 24.7 min\n",
            "178039: done 989 games, reward 343.400, eps 0.01, speed 129.08 f/s, time 24.7 min\n",
            "178235: done 990 games, reward 346.040, eps 0.01, speed 96.68 f/s, time 24.8 min\n",
            "178741: done 991 games, reward 342.040, eps 0.01, speed 119.36 f/s, time 24.8 min\n",
            "179265: done 992 games, reward 347.680, eps 0.01, speed 130.54 f/s, time 24.9 min\n",
            "179412: done 993 games, reward 343.960, eps 0.01, speed 129.70 f/s, time 24.9 min\n",
            "179489: done 994 games, reward 343.000, eps 0.01, speed 131.09 f/s, time 24.9 min\n",
            "179606: done 995 games, reward 336.760, eps 0.01, speed 128.72 f/s, time 25.0 min\n",
            "179785: done 996 games, reward 333.200, eps 0.01, speed 100.46 f/s, time 25.0 min\n",
            "180036: done 997 games, reward 336.040, eps 0.01, speed 104.81 f/s, time 25.0 min\n",
            "180164: done 998 games, reward 335.840, eps 0.01, speed 128.50 f/s, time 25.0 min\n",
            "180752: done 999 games, reward 334.120, eps 0.01, speed 129.89 f/s, time 25.1 min\n",
            "180815: done 1000 games, reward 332.680, eps 0.01, speed 124.85 f/s, time 25.1 min\n",
            "181085: done 1001 games, reward 335.560, eps 0.01, speed 128.38 f/s, time 25.2 min\n",
            "181524: done 1002 games, reward 333.160, eps 0.01, speed 104.76 f/s, time 25.2 min\n",
            "181702: done 1003 games, reward 330.280, eps 0.01, speed 128.79 f/s, time 25.3 min\n",
            "182584: done 1004 games, reward 343.240, eps 0.01, speed 129.22 f/s, time 25.4 min\n",
            "182974: done 1005 games, reward 340.960, eps 0.01, speed 113.18 f/s, time 25.4 min\n",
            "183312: done 1006 games, reward 352.480, eps 0.01, speed 111.66 f/s, time 25.5 min\n",
            "183713: done 1007 games, reward 356.360, eps 0.01, speed 129.68 f/s, time 25.5 min\n",
            "183788: done 1008 games, reward 354.600, eps 0.01, speed 129.53 f/s, time 25.5 min\n",
            "184568: done 1009 games, reward 359.520, eps 0.01, speed 120.86 f/s, time 25.6 min\n",
            "184999: done 1010 games, reward 363.920, eps 0.01, speed 117.72 f/s, time 25.7 min\n",
            "185344: done 1011 games, reward 359.960, eps 0.01, speed 130.49 f/s, time 25.7 min\n",
            "185735: done 1012 games, reward 360.120, eps 0.01, speed 129.62 f/s, time 25.8 min\n",
            "186371: done 1013 games, reward 364.800, eps 0.01, speed 110.77 f/s, time 25.9 min\n",
            "186419: done 1014 games, reward 363.520, eps 0.01, speed 126.01 f/s, time 25.9 min\n",
            "186659: done 1015 games, reward 366.920, eps 0.01, speed 129.14 f/s, time 25.9 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_366-20251201-0124-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_366-20251201-0124-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 365.400 -> 366.920\n",
            "186807: done 1016 games, reward 365.160, eps 0.01, speed 124.83 f/s, time 26.0 min\n",
            "187344: done 1017 games, reward 364.280, eps 0.01, speed 131.70 f/s, time 26.0 min\n",
            "187571: done 1018 games, reward 364.800, eps 0.01, speed 124.32 f/s, time 26.1 min\n",
            "187786: done 1019 games, reward 367.440, eps 0.01, speed 95.33 f/s, time 26.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_367-20251201-0124-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_367-20251201-0124-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 366.920 -> 367.440\n",
            "188433: done 1020 games, reward 370.640, eps 0.01, speed 124.13 f/s, time 26.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_370-20251201-0124-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_370-20251201-0124-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 367.440 -> 370.640\n",
            "189233: done 1021 games, reward 379.240, eps 0.01, speed 121.38 f/s, time 26.3 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_379-20251201-0125-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_379-20251201-0125-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 370.640 -> 379.240\n",
            "189546: done 1022 games, reward 382.080, eps 0.01, speed 102.97 f/s, time 26.3 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_382-20251201-0125-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_382-20251201-0125-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 379.240 -> 382.080\n",
            "189857: done 1023 games, reward 381.040, eps 0.01, speed 125.77 f/s, time 26.4 min\n",
            "189901: done 1024 games, reward 379.240, eps 0.01, speed 129.96 f/s, time 26.4 min\n",
            "190624: done 1025 games, reward 385.360, eps 0.01, speed 129.21 f/s, time 26.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_385-20251201-0125-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_385-20251201-0125-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 382.080 -> 385.360\n",
            "190901: done 1026 games, reward 378.760, eps 0.01, speed 96.73 f/s, time 26.5 min\n",
            "191462: done 1027 games, reward 383.960, eps 0.01, speed 124.87 f/s, time 26.6 min\n",
            "191560: done 1028 games, reward 383.440, eps 0.01, speed 127.55 f/s, time 26.6 min\n",
            "192189: done 1029 games, reward 390.240, eps 0.01, speed 129.36 f/s, time 26.7 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_390-20251201-0125-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_390-20251201-0125-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 385.360 -> 390.240\n",
            "192323: done 1030 games, reward 388.720, eps 0.01, speed 98.88 f/s, time 26.7 min\n",
            "192381: done 1031 games, reward 384.880, eps 0.01, speed 92.77 f/s, time 26.7 min\n",
            "192782: done 1032 games, reward 389.280, eps 0.01, speed 113.88 f/s, time 26.8 min\n",
            "192972: done 1033 games, reward 386.240, eps 0.01, speed 129.96 f/s, time 26.8 min\n",
            "193316: done 1034 games, reward 390.600, eps 0.01, speed 129.30 f/s, time 26.9 min\n",
            "193982: done 1035 games, reward 396.320, eps 0.01, speed 117.44 f/s, time 26.9 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_396-20251201-0125-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_396-20251201-0125-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 390.240 -> 396.320\n",
            "194092: done 1036 games, reward 397.800, eps 0.01, speed 91.12 f/s, time 27.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_397-20251201-0125-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_397-20251201-0125-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 396.320 -> 397.800\n",
            "194452: done 1037 games, reward 401.680, eps 0.01, speed 126.49 f/s, time 27.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_401-20251201-0125-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_401-20251201-0125-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 397.800 -> 401.680\n",
            "194772: done 1038 games, reward 402.120, eps 0.01, speed 126.49 f/s, time 27.1 min\n",
            "195027: done 1039 games, reward 402.160, eps 0.01, speed 128.65 f/s, time 27.1 min\n",
            "195320: done 1040 games, reward 407.080, eps 0.01, speed 125.80 f/s, time 27.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_407-20251201-0125-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_407-20251201-0125-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 401.680 -> 407.080\n",
            "195617: done 1041 games, reward 407.080, eps 0.01, speed 94.21 f/s, time 27.2 min\n",
            "195986: done 1042 games, reward 410.720, eps 0.01, speed 129.68 f/s, time 27.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_410-20251201-0126-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_410-20251201-0126-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 407.080 -> 410.720\n",
            "196087: done 1043 games, reward 410.440, eps 0.01, speed 121.67 f/s, time 27.2 min\n",
            "196767: done 1044 games, reward 418.760, eps 0.01, speed 128.57 f/s, time 27.3 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_418-20251201-0126-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_418-20251201-0126-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 410.720 -> 418.760\n",
            "196866: done 1045 games, reward 402.680, eps 0.01, speed 120.58 f/s, time 27.3 min\n",
            "197184: done 1046 games, reward 406.280, eps 0.01, speed 98.63 f/s, time 27.4 min\n",
            "197998: done 1047 games, reward 418.280, eps 0.01, speed 128.91 f/s, time 27.5 min\n",
            "198072: done 1048 games, reward 412.040, eps 0.01, speed 128.44 f/s, time 27.5 min\n",
            "198143: done 1049 games, reward 407.800, eps 0.01, speed 128.28 f/s, time 27.5 min\n",
            "198268: done 1050 games, reward 407.800, eps 0.01, speed 130.56 f/s, time 27.5 min\n",
            "198747: done 1051 games, reward 407.800, eps 0.01, speed 109.32 f/s, time 27.6 min\n",
            "198788: done 1052 games, reward 406.360, eps 0.01, speed 108.71 f/s, time 27.6 min\n",
            "199083: done 1053 games, reward 400.720, eps 0.01, speed 130.34 f/s, time 27.7 min\n",
            "199232: done 1054 games, reward 398.280, eps 0.01, speed 130.54 f/s, time 27.7 min\n",
            "199524: done 1055 games, reward 398.320, eps 0.01, speed 131.30 f/s, time 27.7 min\n",
            "199796: done 1056 games, reward 401.840, eps 0.01, speed 130.75 f/s, time 27.7 min\n",
            "200083: done 1057 games, reward 403.280, eps 0.01, speed 124.64 f/s, time 27.8 min\n",
            "200345: done 1058 games, reward 405.040, eps 0.01, speed 95.08 f/s, time 27.8 min\n",
            "200918: done 1059 games, reward 411.040, eps 0.01, speed 128.77 f/s, time 27.9 min\n",
            "201015: done 1060 games, reward 411.560, eps 0.01, speed 127.84 f/s, time 27.9 min\n",
            "201225: done 1061 games, reward 412.240, eps 0.01, speed 129.01 f/s, time 27.9 min\n",
            "201321: done 1062 games, reward 412.240, eps 0.01, speed 128.19 f/s, time 28.0 min\n",
            "201380: done 1063 games, reward 411.800, eps 0.01, speed 128.00 f/s, time 28.0 min\n",
            "201674: done 1064 games, reward 414.440, eps 0.01, speed 123.79 f/s, time 28.0 min\n",
            "202014: done 1065 games, reward 417.520, eps 0.01, speed 101.44 f/s, time 28.1 min\n",
            "202087: done 1066 games, reward 416.200, eps 0.01, speed 129.15 f/s, time 28.1 min\n",
            "202541: done 1067 games, reward 421.640, eps 0.01, speed 129.24 f/s, time 28.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_421-20251201-0126-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_421-20251201-0126-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 418.760 -> 421.640\n",
            "202672: done 1068 games, reward 422.520, eps 0.01, speed 125.52 f/s, time 28.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_422-20251201-0126-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_422-20251201-0126-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 421.640 -> 422.520\n",
            "203150: done 1069 games, reward 427.000, eps 0.01, speed 128.83 f/s, time 28.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_427-20251201-0127-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_427-20251201-0127-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 422.520 -> 427.000\n",
            "203480: done 1070 games, reward 431.000, eps 0.01, speed 89.87 f/s, time 28.3 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_431-20251201-0127-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_431-20251201-0127-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 427.000 -> 431.000\n",
            "203637: done 1071 games, reward 429.680, eps 0.01, speed 73.40 f/s, time 28.3 min\n",
            "203966: done 1072 games, reward 430.520, eps 0.01, speed 125.65 f/s, time 28.3 min\n",
            "204135: done 1073 games, reward 432.920, eps 0.01, speed 128.79 f/s, time 28.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_432-20251201-0127-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_432-20251201-0127-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 431.000 -> 432.920\n",
            "204403: done 1074 games, reward 436.000, eps 0.01, speed 124.77 f/s, time 28.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_436-20251201-0127-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_436-20251201-0127-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 432.920 -> 436.000\n",
            "204771: done 1075 games, reward 439.520, eps 0.01, speed 127.94 f/s, time 28.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_439-20251201-0127-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_439-20251201-0127-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 436.000 -> 439.520\n",
            "205283: done 1076 games, reward 446.800, eps 0.01, speed 105.14 f/s, time 28.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_446-20251201-0127-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_446-20251201-0127-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 439.520 -> 446.800\n",
            "205634: done 1077 games, reward 445.000, eps 0.01, speed 126.82 f/s, time 28.6 min\n",
            "206050: done 1078 games, reward 449.720, eps 0.01, speed 130.41 f/s, time 28.6 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_449-20251201-0127-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_449-20251201-0127-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 446.800 -> 449.720\n",
            "206121: done 1079 games, reward 450.680, eps 0.01, speed 120.06 f/s, time 28.6 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_450-20251201-0127-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_450-20251201-0127-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 449.720 -> 450.680\n",
            "206356: done 1080 games, reward 452.400, eps 0.01, speed 128.06 f/s, time 28.7 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_452-20251201-0127-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_452-20251201-0127-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 450.680 -> 452.400\n",
            "206487: done 1081 games, reward 438.240, eps 0.01, speed 96.66 f/s, time 28.7 min\n",
            "206676: done 1082 games, reward 439.680, eps 0.01, speed 94.56 f/s, time 28.7 min\n",
            "207327: done 1083 games, reward 441.120, eps 0.01, speed 127.68 f/s, time 28.8 min\n",
            "207800: done 1084 games, reward 443.400, eps 0.01, speed 129.21 f/s, time 28.9 min\n",
            "207991: done 1085 games, reward 445.800, eps 0.01, speed 117.95 f/s, time 28.9 min\n",
            "208462: done 1086 games, reward 442.240, eps 0.01, speed 108.71 f/s, time 29.0 min\n",
            "208870: done 1087 games, reward 445.000, eps 0.01, speed 129.71 f/s, time 29.0 min\n",
            "209078: done 1088 games, reward 442.760, eps 0.01, speed 130.08 f/s, time 29.1 min\n",
            "209121: done 1089 games, reward 441.880, eps 0.01, speed 126.75 f/s, time 29.1 min\n",
            "209501: done 1090 games, reward 443.640, eps 0.01, speed 130.32 f/s, time 29.1 min\n",
            "209963: done 1091 games, reward 449.960, eps 0.01, speed 105.39 f/s, time 29.2 min\n",
            "210088: done 1092 games, reward 445.960, eps 0.01, speed 128.01 f/s, time 29.2 min\n",
            "210182: done 1093 games, reward 444.840, eps 0.01, speed 127.41 f/s, time 29.2 min\n",
            "210364: done 1094 games, reward 447.000, eps 0.01, speed 130.90 f/s, time 29.2 min\n",
            "210865: done 1095 games, reward 449.440, eps 0.01, speed 131.01 f/s, time 29.3 min\n",
            "210962: done 1096 games, reward 447.680, eps 0.01, speed 130.82 f/s, time 29.3 min\n",
            "211534: done 1097 games, reward 455.920, eps 0.01, speed 108.92 f/s, time 29.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_455-20251201-0128-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_455-20251201-0128-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 452.400 -> 455.920\n",
            "212247: done 1098 games, reward 472.280, eps 0.01, speed 129.21 f/s, time 29.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_472-20251201-0128-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_472-20251201-0128-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 455.920 -> 472.280\n",
            "212341: done 1099 games, reward 469.560, eps 0.01, speed 121.21 f/s, time 29.5 min\n",
            "212713: done 1100 games, reward 474.960, eps 0.01, speed 127.44 f/s, time 29.6 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_474-20251201-0128-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_474-20251201-0128-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 472.280 -> 474.960\n",
            "212752: done 1101 games, reward 469.680, eps 0.01, speed 87.68 f/s, time 29.6 min\n",
            "213149: done 1102 games, reward 471.600, eps 0.01, speed 105.66 f/s, time 29.6 min\n",
            "213236: done 1103 games, reward 470.640, eps 0.01, speed 128.20 f/s, time 29.6 min\n",
            "213323: done 1104 games, reward 455.760, eps 0.01, speed 127.25 f/s, time 29.6 min\n",
            "213443: done 1105 games, reward 452.600, eps 0.01, speed 125.16 f/s, time 29.7 min\n",
            "214299: done 1106 games, reward 455.080, eps 0.01, speed 127.77 f/s, time 29.8 min\n",
            "214669: done 1107 games, reward 463.760, eps 0.01, speed 104.25 f/s, time 29.8 min\n",
            "214801: done 1108 games, reward 466.400, eps 0.01, speed 126.01 f/s, time 29.8 min\n",
            "215472: done 1109 games, reward 467.160, eps 0.01, speed 130.95 f/s, time 29.9 min\n",
            "216016: done 1110 games, reward 472.200, eps 0.01, speed 116.38 f/s, time 30.0 min\n",
            "216570: done 1111 games, reward 482.720, eps 0.01, speed 119.77 f/s, time 30.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_482-20251201-0128-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_482-20251201-0128-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 474.960 -> 482.720\n",
            "216667: done 1112 games, reward 478.400, eps 0.01, speed 123.26 f/s, time 30.1 min\n",
            "216800: done 1113 games, reward 473.240, eps 0.01, speed 127.85 f/s, time 30.1 min\n",
            "217662: done 1114 games, reward 490.200, eps 0.01, speed 116.92 f/s, time 30.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_490-20251201-0129-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_490-20251201-0129-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 482.720 -> 490.200\n",
            "217894: done 1115 games, reward 489.480, eps 0.01, speed 117.21 f/s, time 30.3 min\n",
            "218235: done 1116 games, reward 499.800, eps 0.01, speed 128.91 f/s, time 30.3 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_499-20251201-0129-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_499-20251201-0129-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 490.200 -> 499.800\n",
            "218517: done 1117 games, reward 500.680, eps 0.01, speed 125.19 f/s, time 30.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_500-20251201-0129-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_500-20251201-0129-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 499.800 -> 500.680\n",
            "Solved in 218517 frames!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "257ab3b6",
        "outputId": "3db06cff-4367-455e-b4fa-abdc14cdce7d"
      },
      "source": [
        "from gymnasium.wrappers import RecordVideo\n",
        "\n",
        "VIDEO_DIR_LOCAL = 'videos'\n",
        "VIDEO_DIR_DRIVE = f\"{save_dir}/videos\"\n",
        "\n",
        "print(f\"VIDEO_DIR_LOCAL: {VIDEO_DIR_LOCAL}\")\n",
        "print(f\"VIDEO_DIR_DRIVE: {VIDEO_DIR_DRIVE}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VIDEO_DIR_LOCAL: videos\n",
            "VIDEO_DIR_DRIVE: /content/drive/MyDrive/PUBLIC/Models/videos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "247d9179",
        "outputId": "96e525a6-2133-43ba-94ee-ec831c5f0b68"
      },
      "source": [
        "import os\n",
        "os.makedirs(VIDEO_DIR_LOCAL, exist_ok=True)\n",
        "os.makedirs(VIDEO_DIR_DRIVE, exist_ok=True)\n",
        "\n",
        "print(f\"Created local video directory: {VIDEO_DIR_LOCAL}\")\n",
        "print(f\"Created Google Drive video directory: {VIDEO_DIR_DRIVE}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created local video directory: videos\n",
            "Created Google Drive video directory: /content/drive/MyDrive/PUBLIC/Models/videos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f271fde9"
      },
      "source": [
        "def save_video_for_model(current_net, device, tag, num_episodes=1):\n",
        "    def make_video_env(env_name, video_dir):\n",
        "        # Create a new environment for video recording\n",
        "        env = gym.make(env_name, render_mode='rgb_array')\n",
        "        env = atari_wrappers.AtariWrapper(env, clip_reward=False, noop_max=0)\n",
        "        env = ImageToPyTorch(env)\n",
        "        env = BufferWrapper(env, n_steps=N_STEPS)\n",
        "        # Wrap with RecordVideo\n",
        "        env = RecordVideo(env, video_folder=video_dir, name_prefix=tag, episode_trigger=lambda x: True)\n",
        "        return env\n",
        "\n",
        "    # Create environments for local and Drive video saving\n",
        "    video_env_local = make_video_env(DEFAULT_ENV_NAME, VIDEO_DIR_LOCAL)\n",
        "    video_env_drive = make_video_env(DEFAULT_ENV_NAME, VIDEO_DIR_DRIVE)\n",
        "\n",
        "    # Load the current network's state dictionary into a new model for evaluation\n",
        "    eval_net = DQN(video_env_local.observation_space.shape, video_env_local.action_space.n).to(device)\n",
        "    eval_net.load_state_dict(current_net.state_dict())\n",
        "    eval_net.eval() # Set to evaluation mode\n",
        "\n",
        "    print(f\"Recording {num_episodes} episodes for tag: {tag}...\")\n",
        "    for i in range(num_episodes):\n",
        "        obs, _ = video_env_local.reset()\n",
        "        video_env_drive.reset() # Reset the drive env too for synchronization in recording logic\n",
        "\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "        while not done:\n",
        "            state_v = torch.as_tensor(obs).to(device)\n",
        "            state_v.unsqueeze_(0)\n",
        "            q_vals_v = eval_net(state_v)\n",
        "            _, act_v = torch.max(q_vals_v, dim=1)\n",
        "            action = int(act_v.item())\n",
        "\n",
        "            # Step both environments to ensure consistent video recording\n",
        "            obs, reward, is_done, is_tr, _ = video_env_local.step(action)\n",
        "            _, _, _, _, _ = video_env_drive.step(action)\n",
        "\n",
        "            total_reward += reward\n",
        "            done = is_done or is_tr\n",
        "\n",
        "        print(f\"  Episode {i+1} finished with reward: {total_reward}\")\n",
        "\n",
        "    video_env_local.close()\n",
        "    video_env_drive.close()\n",
        "    print(f\"Video recording for tag '{tag}' complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b034d4d7",
        "outputId": "29fa25e2-2338-47d5-be59-e0d3daeeeac9"
      },
      "source": [
        "VIDEO_FPS = 60\n",
        "MIN_VIDEO_DURATION_SECONDS = 10\n",
        "MAX_VIDEO_DURATION_SECONDS = 30\n",
        "VIDEO_RESOLUTION = (640, 480)\n",
        "\n",
        "print(f\"VIDEO_FPS: {VIDEO_FPS}\")\n",
        "print(f\"MIN_VIDEO_DURATION_SECONDS: {MIN_VIDEO_DURATION_SECONDS}\")\n",
        "print(f\"MAX_VIDEO_DURATION_SECONDS: {MAX_VIDEO_DURATION_SECONDS}\")\n",
        "print(f\"VIDEO_RESOLUTION: {VIDEO_RESOLUTION}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VIDEO_FPS: 60\n",
            "MIN_VIDEO_DURATION_SECONDS: 10\n",
            "MAX_VIDEO_DURATION_SECONDS: 30\n",
            "VIDEO_RESOLUTION: (640, 480)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a8b9d08"
      },
      "source": [
        "def save_video_for_model(current_net, device, tag, num_episodes=1):\n",
        "    def make_video_env(env_name, video_dir):\n",
        "        # Wrap with RecordVideo first to ensure it captures the full environment output\n",
        "        env = gym.make(env_name, render_mode='rgb_array')\n",
        "        env = RecordVideo(\n",
        "            env,\n",
        "            video_folder=video_dir,\n",
        "            name_prefix=tag,\n",
        "            episode_trigger=lambda x: True,\n",
        "            fps=VIDEO_FPS,\n",
        "            # Apply the desired video resolution\n",
        "            disable_logger=True # disable logger to prevent unnecessary output\n",
        "        )\n",
        "        # Then apply other wrappers like AtariWrapper\n",
        "        env = atari_wrappers.AtariWrapper(env, clip_reward=False, noop_max=0)\n",
        "        env = ImageToPyTorch(env)\n",
        "        env = BufferWrapper(env, n_steps=N_STEPS)\n",
        "        return env\n",
        "\n",
        "    # Calculate max frames based on FPS and max duration\n",
        "    MAX_FRAMES_PER_VIDEO = VIDEO_FPS * MAX_VIDEO_DURATION_SECONDS\n",
        "\n",
        "    # Create environments for local and Drive video saving\n",
        "    video_env_local = make_video_env(DEFAULT_ENV_NAME, VIDEO_DIR_LOCAL)\n",
        "    video_env_drive = make_video_env(DEFAULT_ENV_NAME, VIDEO_DIR_DRIVE)\n",
        "\n",
        "    # Load the current network's state dictionary into a new model for evaluation\n",
        "    eval_net = DQN(video_env_local.observation_space.shape, video_env_local.action_space.n).to(device)\n",
        "    eval_net.load_state_dict(current_net.state_dict())\n",
        "    eval_net.eval() # Set to evaluation mode\n",
        "\n",
        "    print(f\"Recording {num_episodes} episodes for tag: {tag}...\")\n",
        "    for i in range(num_episodes):\n",
        "        obs, _ = video_env_local.reset()\n",
        "        video_env_drive.reset() # Reset the drive env too for synchronization in recording logic\n",
        "\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "        frame_counter = 0\n",
        "        while not done and frame_counter < MAX_FRAMES_PER_VIDEO:\n",
        "            state_v = torch.as_tensor(obs).to(device)\n",
        "            state_v.unsqueeze_(0)\n",
        "            q_vals_v = eval_net(state_v)\n",
        "            _, act_v = torch.max(q_vals_v, dim=1)\n",
        "            action = int(act_v.item())\n",
        "\n",
        "            # Step both environments to ensure consistent video recording\n",
        "            obs, reward, is_done, is_tr, _ = video_env_local.step(action)\n",
        "            _, _, _, _, _ = video_env_drive.step(action)\n",
        "\n",
        "            total_reward += reward\n",
        "            done = is_done or is_tr\n",
        "            frame_counter += 1\n",
        "\n",
        "        print(f\"  Episode {i+1} finished with reward: {total_reward} (frames: {frame_counter})\")\n",
        "\n",
        "    video_env_local.close()\n",
        "    video_env_drive.close()\n",
        "    print(f\"Video recording for tag '{tag}' complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5ce0585",
        "outputId": "1f09e937-22db-4e61-9fbf-f6009ac47c1c"
      },
      "source": [
        "EARLY_VIDEO_FRAME_THRESHOLD = 5000\n",
        "TRAINED_VIDEO_REWARD_THRESHOLD = 100\n",
        "VIDEO_RECORD_EPISODES = 2\n",
        "\n",
        "print(f\"EARLY_VIDEO_FRAME_THRESHOLD: {EARLY_VIDEO_FRAME_THRESHOLD}\")\n",
        "print(f\"TRAINED_VIDEO_REWARD_THRESHOLD: {TRAINED_VIDEO_REWARD_THRESHOLD}\")\n",
        "print(f\"VIDEO_RECORD_EPISODES: {VIDEO_RECORD_EPISODES}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EARLY_VIDEO_FRAME_THRESHOLD: 5000\n",
            "TRAINED_VIDEO_REWARD_THRESHOLD: 100\n",
            "VIDEO_RECORD_EPISODES: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53fe0f1f",
        "outputId": "95338727-885f-4fb2-ee93-e5a987a8170f"
      },
      "source": [
        "model_comment = f\"lr{LEARNING_RATE}_gamma{GAMMA}_epsdec{EPSILON_DECAY_LAST_FRAME}_rs{REPLAY_START_SIZE}_bs{BATCH_SIZE}_sync{SYNC_TARGET_FRAMES}_fs{N_STEPS}\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "env = make_env(env_name)\n",
        "net = DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
        "tgt_net = DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
        "writer = SummaryWriter(comment=f\"-{env_name}-{model_comment}\")\n",
        "print(net)\n",
        "\n",
        "buffer = ExperienceBuffer(REPLAY_SIZE)\n",
        "agent = Agent(env, buffer)\n",
        "epsilon = EPSILON_START\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
        "total_rewards = []\n",
        "frame_idx = 0\n",
        "ts_frame = 0\n",
        "ts = time.time()\n",
        "best_m_reward = None\n",
        "\n",
        "hparams = {\n",
        "    'learning_rate': LEARNING_RATE,\n",
        "    'gamma': GAMMA,\n",
        "    'epsilon_start': EPSILON_START,\n",
        "    'epsilon_final': EPSILON_FINAL,\n",
        "    'epsilon_decay_last_frame': EPSILON_DECAY_LAST_FRAME,\n",
        "    'replay_size': REPLAY_SIZE,\n",
        "    'replay_start_size': REPLAY_START_SIZE,\n",
        "    'batch_size': BATCH_SIZE,\n",
        "    'sync_target_frames': SYNC_TARGET_FRAMES,\n",
        "    'frame_stack': N_STEPS,\n",
        "    'optimizer': 'Adam',\n",
        "    'mean_reward_bound': MEAN_REWARD_BOUND\n",
        "}\n",
        "\n",
        "# Flags to ensure video is recorded only once per trigger point\n",
        "early_video_recorded = False\n",
        "trained_video_recorded = False\n",
        "\n",
        "start_time = time.time()\n",
        "while True:\n",
        "    frame_idx += 1\n",
        "    epsilon = max(EPSILON_FINAL, EPSILON_START - frame_idx / EPSILON_DECAY_LAST_FRAME)\n",
        "\n",
        "    reward = agent.play_step(net, device, epsilon)\n",
        "    if reward is not None:\n",
        "        total_rewards.append(reward)\n",
        "        speed = (frame_idx - ts_frame) / (time.time() - ts)\n",
        "        elapsed = time.time() - start_time  # in seconds\n",
        "        ts_frame = frame_idx\n",
        "        ts = time.time()\n",
        "        m_reward = np.mean(total_rewards[-100:])\n",
        "        print(f\"{frame_idx}: done {len(total_rewards)} games, reward {m_reward:.3f}, \"\n",
        "             f\"eps {epsilon:.2f}, speed {speed:.2f} f/s, time {elapsed/60:.1f} min\")\n",
        "        writer.add_scalar(\"epsilon\", epsilon, frame_idx)\n",
        "        writer.add_scalar(\"speed\", speed, frame_idx)\n",
        "        writer.add_scalar(\"reward_100\", m_reward, frame_idx)\n",
        "        writer.add_scalar(\"reward\", reward, frame_idx)\n",
        "\n",
        "        # --- Video Recording Triggers ---\n",
        "        # 1. Early video recording\n",
        "        if not early_video_recorded and frame_idx >= EARLY_VIDEO_FRAME_THRESHOLD:\n",
        "            print(f\"\\n>>> Triggering early video recording at frame_idx {frame_idx} <<<\")\n",
        "            save_video_for_model(net, device, tag=f\"early_training_f{frame_idx}\", num_episodes=VIDEO_RECORD_EPISODES)\n",
        "            early_video_recorded = True\n",
        "\n",
        "        # 2. When the model starts performing well\n",
        "        if not trained_video_recorded and m_reward >= TRAINED_VIDEO_REWARD_THRESHOLD:\n",
        "            print(f\"\\n>>> Triggering trained video recording (m_reward {m_reward:.3f}) at frame_idx {frame_idx} <<<\")\n",
        "            save_video_for_model(net, device, tag=f\"trained_reward_{int(m_reward)}_f{frame_idx}\", num_episodes=VIDEO_RECORD_EPISODES)\n",
        "            trained_video_recorded = True\n",
        "        # --- End Video Recording Triggers ---\n",
        "\n",
        "        if best_m_reward is None or m_reward > best_m_reward + SAVE_EPSILON:\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
        "            model_filename = f\"{safe_env_name}-best_{int(m_reward)}-{timestamp}-{model_comment}.dat\"\n",
        "\n",
        "            model_path_drive = os.path.join(save_dir_drive, model_filename)\n",
        "            model_path_local = os.path.join(save_dir_local, model_filename)\n",
        "\n",
        "            torch.save(net.state_dict(), model_path_drive)\n",
        "            torch.save(net.state_dict(), model_path_local)\n",
        "\n",
        "            print(f\"ðŸ’¾ Model saved to:\\n - Google Drive: {model_path_drive}\\n - Local:        {model_path_local}\")\n",
        "            if best_m_reward is not None:\n",
        "                print(f\"Best reward updated {best_m_reward:.3f} -> {m_reward:.3f}\")\n",
        "            best_m_reward = m_reward\n",
        "\n",
        "            writer.add_hparams(hparams, {'metric/mean_reward': m_reward}, global_step=frame_idx)\n",
        "\n",
        "        if m_reward >= MEAN_REWARD_BOUND:\n",
        "            print(\"Solved in %d frames!\" % frame_idx)\n",
        "            # --- Video Recording Triggers ---\n",
        "            print(f\"\\n>>> Triggering final solved video recording (m_reward {m_reward:.3f}) at frame_idx {frame_idx} <<<\")\n",
        "            save_video_for_model(net, device, tag=f\"solved_reward_{int(m_reward)}_f{frame_idx}\", num_episodes=VIDEO_RECORD_EPISODES)\n",
        "            # --- End Video Recording Triggers ---\n",
        "            break\n",
        "\n",
        "    if len(buffer) < REPLAY_START_SIZE:\n",
        "        continue\n",
        "    if frame_idx % SYNC_TARGET_FRAMES == 0:\n",
        "        tgt_net.load_state_dict(net.state_dict())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    batch = buffer.sample(BATCH_SIZE)\n",
        "    loss_t = calc_loss(batch, net, tgt_net, device)\n",
        "    loss_t.backward()\n",
        "    optimizer.step()\n",
        "env.close()\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating environment ALE/BeamRider-v5\n",
            "DQN(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (5): ReLU()\n",
            "    (6): Flatten(start_dim=1, end_dim=-1)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=3136, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n",
            "110: done 1 games, reward 88.000, eps 0.99, speed 359.87 f/s, time 0.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_88-20251201-0129-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_88-20251201-0129-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "171: done 2 games, reward 88.000, eps 0.98, speed 316.22 f/s, time 0.0 min\n",
            "219: done 3 games, reward 58.667, eps 0.98, speed 362.60 f/s, time 0.0 min\n",
            "383: done 4 games, reward 132.000, eps 0.96, speed 369.97 f/s, time 0.0 min\n",
            "\n",
            ">>> Triggering trained video recording (m_reward 132.000) at frame_idx 383 <<<\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gymnasium/wrappers/rendering.py:293: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/gymnasium/wrappers/rendering.py:293: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/drive/MyDrive/PUBLIC/Models/videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recording 2 episodes for tag: trained_reward_132_f383...\n",
            "  Episode 1 finished with reward: 0.0 (frames: 241)\n",
            "  Episode 2 finished with reward: 0.0 (frames: 71)\n",
            "Video recording for tag 'trained_reward_132_f383' complete.\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_132-20251201-0129-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_132-20251201-0129-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 88.000 -> 132.000\n",
            "479: done 5 games, reward 114.400, eps 0.95, speed 11.08 f/s, time 0.2 min\n",
            "543: done 6 games, reward 95.333, eps 0.95, speed 367.85 f/s, time 0.2 min\n",
            "758: done 7 games, reward 100.571, eps 0.92, speed 354.32 f/s, time 0.2 min\n",
            "867: done 8 games, reward 104.500, eps 0.91, speed 361.07 f/s, time 0.2 min\n",
            "936: done 9 games, reward 97.778, eps 0.91, speed 365.55 f/s, time 0.2 min\n",
            "1094: done 10 games, reward 105.600, eps 0.89, speed 198.35 f/s, time 0.2 min\n",
            "1172: done 11 games, reward 108.000, eps 0.88, speed 152.70 f/s, time 0.2 min\n",
            "1300: done 12 games, reward 102.667, eps 0.87, speed 150.46 f/s, time 0.2 min\n",
            "1472: done 13 games, reward 104.923, eps 0.85, speed 147.85 f/s, time 0.2 min\n",
            "1527: done 14 games, reward 97.429, eps 0.85, speed 148.48 f/s, time 0.2 min\n",
            "1582: done 15 games, reward 96.800, eps 0.84, speed 140.20 f/s, time 0.3 min\n",
            "1840: done 16 games, reward 110.000, eps 0.82, speed 149.57 f/s, time 0.3 min\n",
            "1912: done 17 games, reward 106.118, eps 0.81, speed 105.15 f/s, time 0.3 min\n",
            "2047: done 18 games, reward 102.667, eps 0.80, speed 103.97 f/s, time 0.3 min\n",
            "2189: done 19 games, reward 113.474, eps 0.78, speed 109.68 f/s, time 0.3 min\n",
            "2304: done 20 games, reward 114.400, eps 0.77, speed 145.77 f/s, time 0.3 min\n",
            "2368: done 21 games, reward 113.143, eps 0.76, speed 147.25 f/s, time 0.4 min\n",
            "2477: done 22 games, reward 110.000, eps 0.75, speed 147.39 f/s, time 0.4 min\n",
            "2602: done 23 games, reward 107.130, eps 0.74, speed 146.81 f/s, time 0.4 min\n",
            "2724: done 24 games, reward 104.500, eps 0.73, speed 144.15 f/s, time 0.4 min\n",
            "2792: done 25 games, reward 102.080, eps 0.72, speed 144.12 f/s, time 0.4 min\n",
            "3006: done 26 games, reward 106.615, eps 0.70, speed 145.22 f/s, time 0.4 min\n",
            "3130: done 27 games, reward 107.556, eps 0.69, speed 146.60 f/s, time 0.4 min\n",
            "3303: done 28 games, reward 114.714, eps 0.67, speed 147.84 f/s, time 0.5 min\n",
            "3414: done 29 games, reward 113.793, eps 0.66, speed 145.13 f/s, time 0.5 min\n",
            "3556: done 30 games, reward 115.867, eps 0.64, speed 141.86 f/s, time 0.5 min\n",
            "3648: done 31 games, reward 113.548, eps 0.64, speed 117.54 f/s, time 0.5 min\n",
            "3759: done 32 games, reward 114.125, eps 0.62, speed 103.29 f/s, time 0.5 min\n",
            "3841: done 33 games, reward 112.000, eps 0.62, speed 104.81 f/s, time 0.5 min\n",
            "3939: done 34 games, reward 111.294, eps 0.61, speed 109.47 f/s, time 0.6 min\n",
            "4034: done 35 games, reward 113.143, eps 0.60, speed 140.52 f/s, time 0.6 min\n",
            "4104: done 36 games, reward 112.444, eps 0.59, speed 144.84 f/s, time 0.6 min\n",
            "4163: done 37 games, reward 109.405, eps 0.58, speed 142.54 f/s, time 0.6 min\n",
            "4372: done 38 games, reward 110.000, eps 0.56, speed 141.15 f/s, time 0.6 min\n",
            "4419: done 39 games, reward 107.179, eps 0.56, speed 141.80 f/s, time 0.6 min\n",
            "4471: done 40 games, reward 104.500, eps 0.55, speed 136.39 f/s, time 0.6 min\n",
            "4622: done 41 games, reward 104.098, eps 0.54, speed 141.54 f/s, time 0.6 min\n",
            "4730: done 42 games, reward 101.619, eps 0.53, speed 142.76 f/s, time 0.6 min\n",
            "4851: done 43 games, reward 104.372, eps 0.51, speed 139.61 f/s, time 0.7 min\n",
            "5053: done 44 games, reward 109.000, eps 0.49, speed 142.40 f/s, time 0.7 min\n",
            "\n",
            ">>> Triggering early video recording at frame_idx 5053 <<<\n",
            "Recording 2 episodes for tag: early_training_f5053...\n",
            "  Episode 1 finished with reward: 264.0 (frames: 168)\n",
            "  Episode 2 finished with reward: 176.0 (frames: 142)\n",
            "Video recording for tag 'early_training_f5053' complete.\n",
            "5150: done 45 games, reward 110.489, eps 0.48, speed 10.51 f/s, time 0.8 min\n",
            "5195: done 46 games, reward 108.087, eps 0.48, speed 137.09 f/s, time 0.8 min\n",
            "5420: done 47 games, reward 113.277, eps 0.46, speed 140.21 f/s, time 0.9 min\n",
            "5488: done 48 games, reward 111.833, eps 0.45, speed 138.77 f/s, time 0.9 min\n",
            "5539: done 49 games, reward 110.449, eps 0.45, speed 135.69 f/s, time 0.9 min\n",
            "5714: done 50 games, reward 112.640, eps 0.43, speed 140.55 f/s, time 0.9 min\n",
            "5761: done 51 games, reward 110.431, eps 0.42, speed 137.89 f/s, time 0.9 min\n",
            "5828: done 52 games, reward 109.154, eps 0.42, speed 141.60 f/s, time 0.9 min\n",
            "5936: done 53 games, reward 110.415, eps 0.41, speed 138.79 f/s, time 0.9 min\n",
            "6006: done 54 games, reward 110.000, eps 0.40, speed 137.94 f/s, time 0.9 min\n",
            "6160: done 55 games, reward 110.400, eps 0.38, speed 100.37 f/s, time 1.0 min\n",
            "6295: done 56 games, reward 110.786, eps 0.37, speed 99.64 f/s, time 1.0 min\n",
            "6353: done 57 games, reward 108.842, eps 0.36, speed 116.66 f/s, time 1.0 min\n",
            "6447: done 58 games, reward 108.483, eps 0.36, speed 136.11 f/s, time 1.0 min\n",
            "6763: done 59 games, reward 116.339, eps 0.32, speed 136.70 f/s, time 1.0 min\n",
            "6967: done 60 games, reward 116.667, eps 0.30, speed 138.23 f/s, time 1.1 min\n",
            "7033: done 61 games, reward 115.541, eps 0.30, speed 135.63 f/s, time 1.1 min\n",
            "7136: done 62 games, reward 115.097, eps 0.29, speed 135.49 f/s, time 1.1 min\n",
            "7184: done 63 games, reward 113.270, eps 0.28, speed 136.72 f/s, time 1.1 min\n",
            "7393: done 64 games, reward 117.688, eps 0.26, speed 134.91 f/s, time 1.1 min\n",
            "7517: done 65 games, reward 117.908, eps 0.25, speed 135.03 f/s, time 1.1 min\n",
            "7574: done 66 games, reward 116.121, eps 0.24, speed 137.64 f/s, time 1.1 min\n",
            "7622: done 67 games, reward 114.388, eps 0.24, speed 129.95 f/s, time 1.1 min\n",
            "7736: done 68 games, reward 114.000, eps 0.23, speed 103.99 f/s, time 1.2 min\n",
            "7791: done 69 games, reward 112.348, eps 0.22, speed 98.27 f/s, time 1.2 min\n",
            "7859: done 70 games, reward 112.000, eps 0.21, speed 98.25 f/s, time 1.2 min\n",
            "7966: done 71 games, reward 111.662, eps 0.20, speed 97.93 f/s, time 1.2 min\n",
            "8158: done 72 games, reward 115.000, eps 0.18, speed 132.96 f/s, time 1.2 min\n",
            "8209: done 73 games, reward 114.027, eps 0.18, speed 129.76 f/s, time 1.2 min\n",
            "8296: done 74 games, reward 114.270, eps 0.17, speed 132.48 f/s, time 1.2 min\n",
            "8350: done 75 games, reward 113.333, eps 0.17, speed 131.00 f/s, time 1.3 min\n",
            "8402: done 76 games, reward 111.842, eps 0.16, speed 133.64 f/s, time 1.3 min\n",
            "8520: done 77 games, reward 112.675, eps 0.15, speed 134.99 f/s, time 1.3 min\n",
            "8645: done 78 games, reward 114.615, eps 0.14, speed 134.61 f/s, time 1.3 min\n",
            "8703: done 79 games, reward 114.278, eps 0.13, speed 134.27 f/s, time 1.3 min\n",
            "8751: done 80 games, reward 112.850, eps 0.12, speed 132.13 f/s, time 1.3 min\n",
            "8949: done 81 games, reward 116.346, eps 0.11, speed 132.81 f/s, time 1.3 min\n",
            "9012: done 82 games, reward 115.463, eps 0.10, speed 134.26 f/s, time 1.3 min\n",
            "9100: done 83 games, reward 115.133, eps 0.09, speed 127.27 f/s, time 1.3 min\n",
            "9181: done 84 games, reward 115.333, eps 0.08, speed 131.55 f/s, time 1.4 min\n",
            "9373: done 85 games, reward 117.600, eps 0.06, speed 111.79 f/s, time 1.4 min\n",
            "9427: done 86 games, reward 116.744, eps 0.06, speed 91.63 f/s, time 1.4 min\n",
            "9525: done 87 games, reward 116.920, eps 0.05, speed 97.34 f/s, time 1.4 min\n",
            "9600: done 88 games, reward 117.091, eps 0.04, speed 103.53 f/s, time 1.4 min\n",
            "9648: done 89 games, reward 116.764, eps 0.04, speed 124.10 f/s, time 1.4 min\n",
            "9792: done 90 games, reward 116.933, eps 0.02, speed 130.32 f/s, time 1.5 min\n",
            "9913: done 91 games, reward 119.033, eps 0.01, speed 129.95 f/s, time 1.5 min\n",
            "9964: done 92 games, reward 117.739, eps 0.01, speed 131.54 f/s, time 1.5 min\n",
            "10166: done 93 games, reward 118.839, eps 0.01, speed 127.95 f/s, time 1.5 min\n",
            "10315: done 94 games, reward 118.979, eps 0.01, speed 130.84 f/s, time 1.5 min\n",
            "10363: done 95 games, reward 117.726, eps 0.01, speed 130.58 f/s, time 1.5 min\n",
            "10503: done 96 games, reward 117.875, eps 0.01, speed 130.56 f/s, time 1.5 min\n",
            "10561: done 97 games, reward 117.567, eps 0.01, speed 127.73 f/s, time 1.6 min\n",
            "10608: done 98 games, reward 117.265, eps 0.01, speed 129.93 f/s, time 1.6 min\n",
            "10699: done 99 games, reward 117.859, eps 0.01, speed 128.97 f/s, time 1.6 min\n",
            "10841: done 100 games, reward 118.880, eps 0.01, speed 130.18 f/s, time 1.6 min\n",
            "10950: done 101 games, reward 118.880, eps 0.01, speed 99.32 f/s, time 1.6 min\n",
            "11091: done 102 games, reward 121.960, eps 0.01, speed 95.20 f/s, time 1.6 min\n",
            "11192: done 103 games, reward 122.840, eps 0.01, speed 104.31 f/s, time 1.6 min\n",
            "11280: done 104 games, reward 119.760, eps 0.01, speed 128.06 f/s, time 1.7 min\n",
            "11391: done 105 games, reward 121.960, eps 0.01, speed 130.86 f/s, time 1.7 min\n",
            "11550: done 106 games, reward 123.720, eps 0.01, speed 128.04 f/s, time 1.7 min\n",
            "11614: done 107 games, reward 122.400, eps 0.01, speed 129.54 f/s, time 1.7 min\n",
            "11705: done 108 games, reward 122.400, eps 0.01, speed 121.10 f/s, time 1.7 min\n",
            "11807: done 109 games, reward 124.160, eps 0.01, speed 130.03 f/s, time 1.7 min\n",
            "11895: done 110 games, reward 123.720, eps 0.01, speed 130.96 f/s, time 1.7 min\n",
            "12019: done 111 games, reward 123.720, eps 0.01, speed 131.12 f/s, time 1.8 min\n",
            "12121: done 112 games, reward 124.160, eps 0.01, speed 130.96 f/s, time 1.8 min\n",
            "12213: done 113 games, reward 124.600, eps 0.01, speed 130.00 f/s, time 1.8 min\n",
            "12310: done 114 games, reward 125.920, eps 0.01, speed 131.80 f/s, time 1.8 min\n",
            "12362: done 115 games, reward 125.480, eps 0.01, speed 128.88 f/s, time 1.8 min\n",
            "12578: done 116 games, reward 124.160, eps 0.01, speed 106.98 f/s, time 1.8 min\n",
            "12703: done 117 games, reward 125.480, eps 0.01, speed 94.76 f/s, time 1.9 min\n",
            "12751: done 118 games, reward 125.040, eps 0.01, speed 109.02 f/s, time 1.9 min\n",
            "12802: done 119 games, reward 122.400, eps 0.01, speed 124.06 f/s, time 1.9 min\n",
            "12916: done 120 games, reward 122.840, eps 0.01, speed 129.88 f/s, time 1.9 min\n",
            "13123: done 121 games, reward 125.920, eps 0.01, speed 131.02 f/s, time 1.9 min\n",
            "13251: done 122 games, reward 126.360, eps 0.01, speed 131.18 f/s, time 1.9 min\n",
            "13391: done 123 games, reward 128.560, eps 0.01, speed 130.88 f/s, time 1.9 min\n",
            "13580: done 124 games, reward 131.640, eps 0.01, speed 131.13 f/s, time 2.0 min\n",
            "13673: done 125 games, reward 131.640, eps 0.01, speed 102.95 f/s, time 2.0 min\n",
            "13747: done 126 games, reward 131.360, eps 0.01, speed 91.53 f/s, time 2.0 min\n",
            "14089: done 127 games, reward 136.640, eps 0.01, speed 95.30 f/s, time 2.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_136-20251201-0131-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_136-20251201-0131-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 132.000 -> 136.640\n",
            "14128: done 128 games, reward 134.040, eps 0.01, speed 84.41 f/s, time 2.1 min\n",
            "14186: done 129 games, reward 133.160, eps 0.01, speed 87.95 f/s, time 2.1 min\n",
            "14302: done 130 games, reward 131.840, eps 0.01, speed 127.75 f/s, time 2.1 min\n",
            "14390: done 131 games, reward 133.160, eps 0.01, speed 130.31 f/s, time 2.1 min\n",
            "14473: done 132 games, reward 132.720, eps 0.01, speed 126.57 f/s, time 2.1 min\n",
            "14641: done 133 games, reward 134.920, eps 0.01, speed 130.50 f/s, time 2.1 min\n",
            "14802: done 134 games, reward 136.240, eps 0.01, speed 130.53 f/s, time 2.2 min\n",
            "14850: done 135 games, reward 134.480, eps 0.01, speed 131.14 f/s, time 2.2 min\n",
            "14994: done 136 games, reward 135.360, eps 0.01, speed 130.16 f/s, time 2.2 min\n",
            "15069: done 137 games, reward 135.360, eps 0.01, speed 130.75 f/s, time 2.2 min\n",
            "15138: done 138 games, reward 134.920, eps 0.01, speed 129.74 f/s, time 2.2 min\n",
            "15467: done 139 games, reward 140.640, eps 0.01, speed 129.66 f/s, time 2.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_140-20251201-0131-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_140-20251201-0131-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 136.640 -> 140.640\n",
            "15517: done 140 games, reward 140.640, eps 0.01, speed 94.19 f/s, time 2.2 min\n",
            "15595: done 141 games, reward 140.200, eps 0.01, speed 96.89 f/s, time 2.3 min\n",
            "15725: done 142 games, reward 142.400, eps 0.01, speed 96.85 f/s, time 2.3 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_142-20251201-0131-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_142-20251201-0131-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 140.640 -> 142.400\n",
            "15800: done 143 games, reward 141.520, eps 0.01, speed 97.44 f/s, time 2.3 min\n",
            "15881: done 144 games, reward 139.760, eps 0.01, speed 127.44 f/s, time 2.3 min\n",
            "15949: done 145 games, reward 138.440, eps 0.01, speed 131.81 f/s, time 2.3 min\n",
            "16033: done 146 games, reward 140.200, eps 0.01, speed 127.74 f/s, time 2.3 min\n",
            "16182: done 147 games, reward 137.560, eps 0.01, speed 128.82 f/s, time 2.3 min\n",
            "16244: done 148 games, reward 137.120, eps 0.01, speed 126.93 f/s, time 2.4 min\n",
            "16335: done 149 games, reward 138.000, eps 0.01, speed 131.20 f/s, time 2.4 min\n",
            "16426: done 150 games, reward 136.680, eps 0.01, speed 131.75 f/s, time 2.4 min\n",
            "16554: done 151 games, reward 139.320, eps 0.01, speed 127.34 f/s, time 2.4 min\n",
            "16635: done 152 games, reward 140.200, eps 0.01, speed 129.29 f/s, time 2.4 min\n",
            "16746: done 153 games, reward 140.640, eps 0.01, speed 127.49 f/s, time 2.4 min\n",
            "16864: done 154 games, reward 141.520, eps 0.01, speed 130.77 f/s, time 2.4 min\n",
            "17120: done 155 games, reward 143.720, eps 0.01, speed 118.83 f/s, time 2.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_143-20251201-0131-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_143-20251201-0131-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 142.400 -> 143.720\n",
            "17384: done 156 games, reward 145.480, eps 0.01, speed 96.39 f/s, time 2.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_145-20251201-0131-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_145-20251201-0131-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 143.720 -> 145.480\n",
            "17447: done 157 games, reward 145.960, eps 0.01, speed 119.95 f/s, time 2.5 min\n",
            "17592: done 158 games, reward 146.400, eps 0.01, speed 128.76 f/s, time 2.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_146-20251201-0131-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_146-20251201-0131-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 145.480 -> 146.400\n",
            "17663: done 159 games, reward 142.000, eps 0.01, speed 122.46 f/s, time 2.6 min\n",
            "17724: done 160 games, reward 141.080, eps 0.01, speed 126.67 f/s, time 2.6 min\n",
            "17862: done 161 games, reward 142.360, eps 0.01, speed 128.23 f/s, time 2.6 min\n",
            "17920: done 162 games, reward 141.920, eps 0.01, speed 130.90 f/s, time 2.6 min\n",
            "17969: done 163 games, reward 142.360, eps 0.01, speed 129.72 f/s, time 2.6 min\n",
            "18147: done 164 games, reward 140.160, eps 0.01, speed 128.83 f/s, time 2.6 min\n",
            "18305: done 165 games, reward 141.920, eps 0.01, speed 130.47 f/s, time 2.6 min\n",
            "18369: done 166 games, reward 142.360, eps 0.01, speed 116.19 f/s, time 2.6 min\n",
            "18477: done 167 games, reward 143.680, eps 0.01, speed 128.29 f/s, time 2.7 min\n",
            "18525: done 168 games, reward 142.800, eps 0.01, speed 127.46 f/s, time 2.7 min\n",
            "18582: done 169 games, reward 143.680, eps 0.01, speed 129.20 f/s, time 2.7 min\n",
            "18774: done 170 games, reward 146.320, eps 0.01, speed 99.07 f/s, time 2.7 min\n",
            "18906: done 171 games, reward 147.640, eps 0.01, speed 95.39 f/s, time 2.7 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_147-20251201-0131-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_147-20251201-0131-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 146.400 -> 147.640\n",
            "18974: done 172 games, reward 144.120, eps 0.01, speed 116.41 f/s, time 2.7 min\n",
            "19116: done 173 games, reward 146.760, eps 0.01, speed 129.35 f/s, time 2.8 min\n",
            "19228: done 174 games, reward 147.200, eps 0.01, speed 130.91 f/s, time 2.8 min\n",
            "19323: done 175 games, reward 148.080, eps 0.01, speed 131.30 f/s, time 2.8 min\n",
            "19470: done 176 games, reward 150.280, eps 0.01, speed 130.72 f/s, time 2.8 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_150-20251201-0131-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_150-20251201-0131-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 147.640 -> 150.280\n",
            "19569: done 177 games, reward 149.400, eps 0.01, speed 123.27 f/s, time 2.8 min\n",
            "19698: done 178 games, reward 148.520, eps 0.01, speed 129.25 f/s, time 2.8 min\n",
            "19821: done 179 games, reward 149.400, eps 0.01, speed 128.66 f/s, time 2.8 min\n",
            "19919: done 180 games, reward 150.720, eps 0.01, speed 128.82 f/s, time 2.9 min\n",
            "20057: done 181 games, reward 148.520, eps 0.01, speed 129.36 f/s, time 2.9 min\n",
            "20191: done 182 games, reward 151.600, eps 0.01, speed 120.55 f/s, time 2.9 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_151-20251201-0132-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_151-20251201-0132-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 150.280 -> 151.600\n",
            "20245: done 183 games, reward 150.720, eps 0.01, speed 90.12 f/s, time 2.9 min\n",
            "20356: done 184 games, reward 151.160, eps 0.01, speed 95.08 f/s, time 2.9 min\n",
            "20695: done 185 games, reward 154.240, eps 0.01, speed 115.65 f/s, time 3.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_154-20251201-0132-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_154-20251201-0132-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 151.600 -> 154.240\n",
            "20762: done 186 games, reward 154.240, eps 0.01, speed 120.31 f/s, time 3.0 min\n",
            "20823: done 187 games, reward 153.400, eps 0.01, speed 129.25 f/s, time 3.0 min\n",
            "20928: done 188 games, reward 153.840, eps 0.01, speed 126.83 f/s, time 3.0 min\n",
            "20979: done 189 games, reward 153.400, eps 0.01, speed 130.05 f/s, time 3.0 min\n",
            "21155: done 190 games, reward 155.600, eps 0.01, speed 130.59 f/s, time 3.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_155-20251201-0132-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_155-20251201-0132-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 154.240 -> 155.600\n",
            "21241: done 191 games, reward 154.720, eps 0.01, speed 123.35 f/s, time 3.0 min\n",
            "21377: done 192 games, reward 156.480, eps 0.01, speed 127.51 f/s, time 3.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_156-20251201-0132-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_156-20251201-0132-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 155.600 -> 156.480\n",
            "21523: done 193 games, reward 156.920, eps 0.01, speed 124.63 f/s, time 3.1 min\n",
            "21629: done 194 games, reward 157.800, eps 0.01, speed 124.89 f/s, time 3.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_157-20251201-0132-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_157-20251201-0132-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 156.480 -> 157.800\n",
            "21818: done 195 games, reward 161.320, eps 0.01, speed 108.38 f/s, time 3.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_161-20251201-0132-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_161-20251201-0132-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 157.800 -> 161.320\n",
            "21919: done 196 games, reward 160.880, eps 0.01, speed 90.65 f/s, time 3.1 min\n",
            "22041: done 197 games, reward 163.520, eps 0.01, speed 96.87 f/s, time 3.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_163-20251201-0132-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_163-20251201-0132-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 161.320 -> 163.520\n",
            "22160: done 198 games, reward 164.400, eps 0.01, speed 120.85 f/s, time 3.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_164-20251201-0132-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_164-20251201-0132-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 163.520 -> 164.400\n",
            "22242: done 199 games, reward 163.960, eps 0.01, speed 114.60 f/s, time 3.2 min\n",
            "22342: done 200 games, reward 163.080, eps 0.01, speed 125.91 f/s, time 3.2 min\n",
            "22424: done 201 games, reward 163.960, eps 0.01, speed 130.97 f/s, time 3.2 min\n",
            "22559: done 202 games, reward 161.760, eps 0.01, speed 126.51 f/s, time 3.2 min\n",
            "22677: done 203 games, reward 162.200, eps 0.01, speed 130.14 f/s, time 3.2 min\n",
            "22749: done 204 games, reward 162.200, eps 0.01, speed 129.14 f/s, time 3.3 min\n",
            "22820: done 205 games, reward 161.320, eps 0.01, speed 130.75 f/s, time 3.3 min\n",
            "22980: done 206 games, reward 163.080, eps 0.01, speed 130.40 f/s, time 3.3 min\n",
            "23041: done 207 games, reward 163.520, eps 0.01, speed 132.84 f/s, time 3.3 min\n",
            "23092: done 208 games, reward 162.640, eps 0.01, speed 129.54 f/s, time 3.3 min\n",
            "23210: done 209 games, reward 161.760, eps 0.01, speed 124.54 f/s, time 3.3 min\n",
            "23292: done 210 games, reward 160.880, eps 0.01, speed 117.48 f/s, time 3.3 min\n",
            "23393: done 211 games, reward 161.320, eps 0.01, speed 96.29 f/s, time 3.3 min\n",
            "23490: done 212 games, reward 162.640, eps 0.01, speed 96.01 f/s, time 3.4 min\n",
            "23565: done 213 games, reward 162.200, eps 0.01, speed 91.38 f/s, time 3.4 min\n",
            "23649: done 214 games, reward 163.520, eps 0.01, speed 123.39 f/s, time 3.4 min\n",
            "23813: done 215 games, reward 164.840, eps 0.01, speed 127.01 f/s, time 3.4 min\n",
            "23861: done 216 games, reward 163.960, eps 0.01, speed 130.29 f/s, time 3.4 min\n",
            "23979: done 217 games, reward 163.520, eps 0.01, speed 130.42 f/s, time 3.4 min\n",
            "24068: done 218 games, reward 164.400, eps 0.01, speed 130.44 f/s, time 3.4 min\n",
            "24180: done 219 games, reward 167.920, eps 0.01, speed 130.51 f/s, time 3.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_167-20251201-0132-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_167-20251201-0132-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 164.400 -> 167.920\n",
            "24274: done 220 games, reward 167.040, eps 0.01, speed 123.46 f/s, time 3.5 min\n",
            "24391: done 221 games, reward 164.400, eps 0.01, speed 129.97 f/s, time 3.5 min\n",
            "24478: done 222 games, reward 164.840, eps 0.01, speed 128.99 f/s, time 3.5 min\n",
            "24663: done 223 games, reward 166.600, eps 0.01, speed 128.88 f/s, time 3.5 min\n",
            "24829: done 224 games, reward 163.960, eps 0.01, speed 132.66 f/s, time 3.5 min\n",
            "24990: done 225 games, reward 167.480, eps 0.01, speed 99.13 f/s, time 3.6 min\n",
            "25119: done 226 games, reward 166.880, eps 0.01, speed 95.29 f/s, time 3.6 min\n",
            "25187: done 227 games, reward 160.280, eps 0.01, speed 109.94 f/s, time 3.6 min\n",
            "25298: done 228 games, reward 162.440, eps 0.01, speed 130.18 f/s, time 3.6 min\n",
            "25567: done 229 games, reward 166.400, eps 0.01, speed 129.29 f/s, time 3.6 min\n",
            "25632: done 230 games, reward 166.920, eps 0.01, speed 128.07 f/s, time 3.7 min\n",
            "25898: done 231 games, reward 170.000, eps 0.01, speed 129.98 f/s, time 3.7 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_170-20251201-0132-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_170-20251201-0132-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 167.920 -> 170.000\n",
            "25965: done 232 games, reward 169.120, eps 0.01, speed 121.69 f/s, time 3.7 min\n",
            "26093: done 233 games, reward 168.240, eps 0.01, speed 125.82 f/s, time 3.7 min\n",
            "26264: done 234 games, reward 168.240, eps 0.01, speed 129.51 f/s, time 3.7 min\n",
            "26318: done 235 games, reward 169.120, eps 0.01, speed 131.18 f/s, time 3.7 min\n",
            "26379: done 236 games, reward 167.360, eps 0.01, speed 126.52 f/s, time 3.8 min\n",
            "26516: done 237 games, reward 170.440, eps 0.01, speed 105.93 f/s, time 3.8 min\n",
            "26641: done 238 games, reward 171.760, eps 0.01, speed 96.40 f/s, time 3.8 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_171-20251201-0132-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_171-20251201-0132-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 170.000 -> 171.760\n",
            "26693: done 239 games, reward 166.040, eps 0.01, speed 81.24 f/s, time 3.8 min\n",
            "26882: done 240 games, reward 168.240, eps 0.01, speed 126.08 f/s, time 3.8 min\n",
            "26930: done 241 games, reward 167.800, eps 0.01, speed 130.39 f/s, time 3.8 min\n",
            "26999: done 242 games, reward 166.040, eps 0.01, speed 120.75 f/s, time 3.8 min\n",
            "27348: done 243 games, reward 171.320, eps 0.01, speed 129.10 f/s, time 3.9 min\n",
            "27385: done 244 games, reward 170.000, eps 0.01, speed 130.37 f/s, time 3.9 min\n",
            "27456: done 245 games, reward 171.480, eps 0.01, speed 130.96 f/s, time 3.9 min\n",
            "27575: done 246 games, reward 172.360, eps 0.01, speed 129.65 f/s, time 3.9 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_172-20251201-0133-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_172-20251201-0133-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 171.760 -> 172.360\n",
            "27623: done 247 games, reward 171.920, eps 0.01, speed 117.65 f/s, time 3.9 min\n",
            "27727: done 248 games, reward 174.560, eps 0.01, speed 127.45 f/s, time 3.9 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_174-20251201-0133-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_174-20251201-0133-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 172.360 -> 174.560\n",
            "27858: done 249 games, reward 175.880, eps 0.01, speed 127.05 f/s, time 4.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_175-20251201-0133-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_175-20251201-0133-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 174.560 -> 175.880\n",
            "27962: done 250 games, reward 176.760, eps 0.01, speed 121.51 f/s, time 4.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_176-20251201-0133-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_176-20251201-0133-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 175.880 -> 176.760\n",
            "28054: done 251 games, reward 175.440, eps 0.01, speed 78.79 f/s, time 4.0 min\n",
            "28204: done 252 games, reward 176.760, eps 0.01, speed 91.61 f/s, time 4.0 min\n",
            "28397: done 253 games, reward 175.880, eps 0.01, speed 113.82 f/s, time 4.1 min\n",
            "28442: done 254 games, reward 174.120, eps 0.01, speed 116.97 f/s, time 4.1 min\n",
            "28587: done 255 games, reward 171.920, eps 0.01, speed 127.81 f/s, time 4.1 min\n",
            "28787: done 256 games, reward 174.120, eps 0.01, speed 127.43 f/s, time 4.1 min\n",
            "28833: done 257 games, reward 173.640, eps 0.01, speed 129.76 f/s, time 4.1 min\n",
            "29099: done 258 games, reward 178.040, eps 0.01, speed 129.83 f/s, time 4.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_178-20251201-0133-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_178-20251201-0133-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 176.760 -> 178.040\n",
            "29207: done 259 games, reward 177.160, eps 0.01, speed 125.56 f/s, time 4.2 min\n",
            "29257: done 260 games, reward 177.160, eps 0.01, speed 130.23 f/s, time 4.2 min\n",
            "29371: done 261 games, reward 177.600, eps 0.01, speed 130.02 f/s, time 4.2 min\n",
            "29451: done 262 games, reward 178.040, eps 0.01, speed 131.58 f/s, time 4.2 min\n",
            "29548: done 263 games, reward 178.920, eps 0.01, speed 115.18 f/s, time 4.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_178-20251201-0133-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_178-20251201-0133-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 178.040 -> 178.920\n",
            "29666: done 264 games, reward 178.040, eps 0.01, speed 91.72 f/s, time 4.2 min\n",
            "29730: done 265 games, reward 174.960, eps 0.01, speed 96.95 f/s, time 4.2 min\n",
            "29791: done 266 games, reward 174.960, eps 0.01, speed 89.51 f/s, time 4.2 min\n",
            "29873: done 267 games, reward 175.400, eps 0.01, speed 124.97 f/s, time 4.3 min\n",
            "29927: done 268 games, reward 175.400, eps 0.01, speed 128.75 f/s, time 4.3 min\n",
            "30015: done 269 games, reward 174.520, eps 0.01, speed 131.01 f/s, time 4.3 min\n",
            "30112: done 270 games, reward 172.320, eps 0.01, speed 129.78 f/s, time 4.3 min\n",
            "30180: done 271 games, reward 171.000, eps 0.01, speed 131.08 f/s, time 4.3 min\n",
            "30239: done 272 games, reward 171.880, eps 0.01, speed 129.79 f/s, time 4.3 min\n",
            "30378: done 273 games, reward 171.000, eps 0.01, speed 129.01 f/s, time 4.3 min\n",
            "30473: done 274 games, reward 170.560, eps 0.01, speed 130.47 f/s, time 4.3 min\n",
            "30729: done 275 games, reward 172.320, eps 0.01, speed 131.29 f/s, time 4.4 min\n",
            "30867: done 276 games, reward 171.440, eps 0.01, speed 129.24 f/s, time 4.4 min\n",
            "30937: done 277 games, reward 171.880, eps 0.01, speed 126.46 f/s, time 4.4 min\n",
            "31034: done 278 games, reward 171.880, eps 0.01, speed 126.94 f/s, time 4.4 min\n",
            "31127: done 279 games, reward 171.880, eps 0.01, speed 110.54 f/s, time 4.4 min\n",
            "31205: done 280 games, reward 171.880, eps 0.01, speed 96.34 f/s, time 4.4 min\n",
            "31263: done 281 games, reward 170.120, eps 0.01, speed 97.29 f/s, time 4.4 min\n",
            "31420: done 282 games, reward 168.800, eps 0.01, speed 99.79 f/s, time 4.5 min\n",
            "31470: done 283 games, reward 168.800, eps 0.01, speed 130.35 f/s, time 4.5 min\n",
            "31686: done 284 games, reward 171.000, eps 0.01, speed 130.75 f/s, time 4.5 min\n",
            "31763: done 285 games, reward 166.160, eps 0.01, speed 124.61 f/s, time 4.5 min\n",
            "31860: done 286 games, reward 167.480, eps 0.01, speed 129.08 f/s, time 4.5 min\n",
            "31931: done 287 games, reward 167.880, eps 0.01, speed 131.13 f/s, time 4.5 min\n",
            "32011: done 288 games, reward 167.880, eps 0.01, speed 130.73 f/s, time 4.5 min\n",
            "32160: done 289 games, reward 170.080, eps 0.01, speed 130.24 f/s, time 4.6 min\n",
            "32235: done 290 games, reward 167.440, eps 0.01, speed 129.10 f/s, time 4.6 min\n",
            "32303: done 291 games, reward 165.680, eps 0.01, speed 129.89 f/s, time 4.6 min\n",
            "32447: done 292 games, reward 168.320, eps 0.01, speed 129.39 f/s, time 4.6 min\n",
            "32522: done 293 games, reward 166.560, eps 0.01, speed 126.00 f/s, time 4.6 min\n",
            "32587: done 294 games, reward 164.800, eps 0.01, speed 129.73 f/s, time 4.6 min\n",
            "32702: done 295 games, reward 163.480, eps 0.01, speed 115.14 f/s, time 4.6 min\n",
            "32807: done 296 games, reward 163.040, eps 0.01, speed 96.26 f/s, time 4.7 min\n",
            "32908: done 297 games, reward 159.960, eps 0.01, speed 95.97 f/s, time 4.7 min\n",
            "32999: done 298 games, reward 159.080, eps 0.01, speed 103.50 f/s, time 4.7 min\n",
            "33212: done 299 games, reward 158.200, eps 0.01, speed 128.66 f/s, time 4.7 min\n",
            "33294: done 300 games, reward 156.880, eps 0.01, speed 131.74 f/s, time 4.7 min\n",
            "33465: done 301 games, reward 156.880, eps 0.01, speed 130.98 f/s, time 4.7 min\n",
            "33587: done 302 games, reward 156.880, eps 0.01, speed 131.37 f/s, time 4.8 min\n",
            "33651: done 303 games, reward 156.440, eps 0.01, speed 129.87 f/s, time 4.8 min\n",
            "33755: done 304 games, reward 157.320, eps 0.01, speed 128.69 f/s, time 4.8 min\n",
            "33915: done 305 games, reward 157.320, eps 0.01, speed 131.01 f/s, time 4.8 min\n",
            "33979: done 306 games, reward 154.240, eps 0.01, speed 131.15 f/s, time 4.8 min\n",
            "34082: done 307 games, reward 155.120, eps 0.01, speed 129.67 f/s, time 4.8 min\n",
            "34149: done 308 games, reward 155.120, eps 0.01, speed 127.61 f/s, time 4.8 min\n",
            "34254: done 309 games, reward 155.560, eps 0.01, speed 128.90 f/s, time 4.8 min\n",
            "34409: done 310 games, reward 157.320, eps 0.01, speed 95.19 f/s, time 4.9 min\n",
            "34531: done 311 games, reward 156.880, eps 0.01, speed 93.71 f/s, time 4.9 min\n",
            "34595: done 312 games, reward 155.560, eps 0.01, speed 118.93 f/s, time 4.9 min\n",
            "34780: done 313 games, reward 157.320, eps 0.01, speed 130.09 f/s, time 4.9 min\n",
            "34906: done 314 games, reward 157.320, eps 0.01, speed 130.72 f/s, time 4.9 min\n",
            "35175: done 315 games, reward 156.000, eps 0.01, speed 131.88 f/s, time 5.0 min\n",
            "35326: done 316 games, reward 158.640, eps 0.01, speed 131.30 f/s, time 5.0 min\n",
            "35599: done 317 games, reward 160.400, eps 0.01, speed 130.37 f/s, time 5.0 min\n",
            "35641: done 318 games, reward 159.520, eps 0.01, speed 126.06 f/s, time 5.0 min\n",
            "35803: done 319 games, reward 157.760, eps 0.01, speed 132.67 f/s, time 5.1 min\n",
            "35928: done 320 games, reward 158.640, eps 0.01, speed 104.28 f/s, time 5.1 min\n",
            "36063: done 321 games, reward 159.960, eps 0.01, speed 94.88 f/s, time 5.1 min\n",
            "36184: done 322 games, reward 160.840, eps 0.01, speed 105.39 f/s, time 5.1 min\n",
            "36235: done 323 games, reward 156.440, eps 0.01, speed 128.25 f/s, time 5.1 min\n",
            "36306: done 324 games, reward 156.000, eps 0.01, speed 128.32 f/s, time 5.1 min\n",
            "36816: done 325 games, reward 158.640, eps 0.01, speed 130.98 f/s, time 5.2 min\n",
            "36897: done 326 games, reward 157.800, eps 0.01, speed 130.60 f/s, time 5.2 min\n",
            "36938: done 327 games, reward 157.800, eps 0.01, speed 127.31 f/s, time 5.2 min\n",
            "37133: done 328 games, reward 160.000, eps 0.01, speed 130.85 f/s, time 5.2 min\n",
            "37200: done 329 games, reward 156.480, eps 0.01, speed 128.41 f/s, time 5.3 min\n",
            "37261: done 330 games, reward 155.960, eps 0.01, speed 132.65 f/s, time 5.3 min\n",
            "37668: done 331 games, reward 157.720, eps 0.01, speed 107.92 f/s, time 5.3 min\n",
            "37722: done 332 games, reward 159.160, eps 0.01, speed 92.80 f/s, time 5.3 min\n",
            "37840: done 333 games, reward 160.760, eps 0.01, speed 127.31 f/s, time 5.3 min\n",
            "37964: done 334 games, reward 159.880, eps 0.01, speed 130.40 f/s, time 5.4 min\n",
            "38012: done 335 games, reward 159.440, eps 0.01, speed 126.89 f/s, time 5.4 min\n",
            "38148: done 336 games, reward 160.760, eps 0.01, speed 128.16 f/s, time 5.4 min\n",
            "38368: done 337 games, reward 162.080, eps 0.01, speed 131.00 f/s, time 5.4 min\n",
            "38453: done 338 games, reward 161.200, eps 0.01, speed 129.19 f/s, time 5.4 min\n",
            "38523: done 339 games, reward 161.200, eps 0.01, speed 132.94 f/s, time 5.4 min\n",
            "38682: done 340 games, reward 159.440, eps 0.01, speed 131.12 f/s, time 5.5 min\n",
            "38840: done 341 games, reward 162.080, eps 0.01, speed 131.53 f/s, time 5.5 min\n",
            "38918: done 342 games, reward 162.080, eps 0.01, speed 131.75 f/s, time 5.5 min\n",
            "39050: done 343 games, reward 158.120, eps 0.01, speed 117.66 f/s, time 5.5 min\n",
            "39326: done 344 games, reward 162.960, eps 0.01, speed 96.07 f/s, time 5.6 min\n",
            "39397: done 345 games, reward 161.480, eps 0.01, speed 126.57 f/s, time 5.6 min\n",
            "39472: done 346 games, reward 160.160, eps 0.01, speed 129.41 f/s, time 5.6 min\n",
            "39610: done 347 games, reward 162.360, eps 0.01, speed 130.00 f/s, time 5.6 min\n",
            "39715: done 348 games, reward 160.600, eps 0.01, speed 129.56 f/s, time 5.6 min\n",
            "39836: done 349 games, reward 158.840, eps 0.01, speed 130.33 f/s, time 5.6 min\n",
            "40011: done 350 games, reward 160.600, eps 0.01, speed 130.65 f/s, time 5.6 min\n",
            "40542: done 351 games, reward 162.360, eps 0.01, speed 131.33 f/s, time 5.7 min\n",
            "40600: done 352 games, reward 159.720, eps 0.01, speed 119.04 f/s, time 5.7 min\n",
            "41033: done 353 games, reward 165.000, eps 0.01, speed 104.63 f/s, time 5.8 min\n",
            "41122: done 354 games, reward 165.960, eps 0.01, speed 131.52 f/s, time 5.8 min\n",
            "41169: done 355 games, reward 165.120, eps 0.01, speed 127.51 f/s, time 5.8 min\n",
            "41404: done 356 games, reward 164.680, eps 0.01, speed 130.88 f/s, time 5.8 min\n",
            "41537: done 357 games, reward 165.560, eps 0.01, speed 131.05 f/s, time 5.8 min\n",
            "41592: done 358 games, reward 160.720, eps 0.01, speed 126.26 f/s, time 5.9 min\n",
            "41736: done 359 games, reward 162.480, eps 0.01, speed 130.31 f/s, time 5.9 min\n",
            "41875: done 360 games, reward 163.800, eps 0.01, speed 130.76 f/s, time 5.9 min\n",
            "42247: done 361 games, reward 164.240, eps 0.01, speed 125.24 f/s, time 5.9 min\n",
            "42358: done 362 games, reward 164.680, eps 0.01, speed 98.06 f/s, time 6.0 min\n",
            "42419: done 363 games, reward 163.360, eps 0.01, speed 97.65 f/s, time 6.0 min\n",
            "42491: done 364 games, reward 163.360, eps 0.01, speed 92.59 f/s, time 6.0 min\n",
            "42605: done 365 games, reward 165.120, eps 0.01, speed 128.45 f/s, time 6.0 min\n",
            "42835: done 366 games, reward 168.640, eps 0.01, speed 127.93 f/s, time 6.0 min\n",
            "42987: done 367 games, reward 167.320, eps 0.01, speed 129.60 f/s, time 6.0 min\n",
            "43148: done 368 games, reward 169.080, eps 0.01, speed 130.27 f/s, time 6.1 min\n",
            "43195: done 369 games, reward 169.080, eps 0.01, speed 131.28 f/s, time 6.1 min\n",
            "43270: done 370 games, reward 167.760, eps 0.01, speed 126.44 f/s, time 6.1 min\n",
            "43546: done 371 games, reward 172.600, eps 0.01, speed 129.34 f/s, time 6.1 min\n",
            "43924: done 372 games, reward 172.160, eps 0.01, speed 93.76 f/s, time 6.2 min\n",
            "43999: done 373 games, reward 170.400, eps 0.01, speed 83.73 f/s, time 6.2 min\n",
            "44183: done 374 games, reward 172.600, eps 0.01, speed 102.64 f/s, time 6.2 min\n",
            "44310: done 375 games, reward 171.720, eps 0.01, speed 128.28 f/s, time 6.2 min\n",
            "44515: done 376 games, reward 171.280, eps 0.01, speed 128.88 f/s, time 6.3 min\n",
            "44672: done 377 games, reward 172.160, eps 0.01, speed 130.85 f/s, time 6.3 min\n",
            "44724: done 378 games, reward 170.840, eps 0.01, speed 130.68 f/s, time 6.3 min\n",
            "44846: done 379 games, reward 170.400, eps 0.01, speed 129.65 f/s, time 6.3 min\n",
            "44964: done 380 games, reward 172.160, eps 0.01, speed 129.62 f/s, time 6.3 min\n",
            "45046: done 381 games, reward 172.160, eps 0.01, speed 122.52 f/s, time 6.3 min\n",
            "45277: done 382 games, reward 173.480, eps 0.01, speed 132.33 f/s, time 6.4 min\n",
            "45438: done 383 games, reward 176.120, eps 0.01, speed 115.94 f/s, time 6.4 min\n",
            "45485: done 384 games, reward 172.600, eps 0.01, speed 98.88 f/s, time 6.4 min\n",
            "45768: done 385 games, reward 174.360, eps 0.01, speed 102.13 f/s, time 6.4 min\n",
            "46000: done 386 games, reward 175.680, eps 0.01, speed 131.16 f/s, time 6.5 min\n",
            "46065: done 387 games, reward 175.240, eps 0.01, speed 128.98 f/s, time 6.5 min\n",
            "46173: done 388 games, reward 174.800, eps 0.01, speed 130.37 f/s, time 6.5 min\n",
            "46224: done 389 games, reward 172.160, eps 0.01, speed 130.91 f/s, time 6.5 min\n",
            "46378: done 390 games, reward 173.040, eps 0.01, speed 127.68 f/s, time 6.5 min\n",
            "46567: done 391 games, reward 175.680, eps 0.01, speed 129.70 f/s, time 6.6 min\n",
            "46888: done 392 games, reward 172.600, eps 0.01, speed 132.02 f/s, time 6.6 min\n",
            "47535: done 393 games, reward 177.880, eps 0.01, speed 111.48 f/s, time 6.7 min\n",
            "47607: done 394 games, reward 177.880, eps 0.01, speed 130.13 f/s, time 6.7 min\n",
            "47692: done 395 games, reward 176.640, eps 0.01, speed 129.01 f/s, time 6.7 min\n",
            "47880: done 396 games, reward 179.720, eps 0.01, speed 129.49 f/s, time 6.7 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_179-20251201-0135-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_179-20251201-0135-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 178.920 -> 179.720\n",
            "48330: done 397 games, reward 182.360, eps 0.01, speed 129.93 f/s, time 6.8 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_182-20251201-0135-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_182-20251201-0135-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 179.720 -> 182.360\n",
            "48444: done 398 games, reward 182.440, eps 0.01, speed 123.46 f/s, time 6.8 min\n",
            "48628: done 399 games, reward 185.080, eps 0.01, speed 113.69 f/s, time 6.8 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_185-20251201-0135-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_185-20251201-0135-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 182.360 -> 185.080\n",
            "48683: done 400 games, reward 185.080, eps 0.01, speed 83.77 f/s, time 6.8 min\n",
            "48731: done 401 games, reward 183.320, eps 0.01, speed 92.63 f/s, time 6.9 min\n",
            "48832: done 402 games, reward 182.880, eps 0.01, speed 93.02 f/s, time 6.9 min\n",
            "48963: done 403 games, reward 182.440, eps 0.01, speed 121.21 f/s, time 6.9 min\n",
            "49048: done 404 games, reward 182.000, eps 0.01, speed 126.25 f/s, time 6.9 min\n",
            "49226: done 405 games, reward 182.440, eps 0.01, speed 125.80 f/s, time 6.9 min\n",
            "49388: done 406 games, reward 185.080, eps 0.01, speed 129.81 f/s, time 6.9 min\n",
            "49747: done 407 games, reward 185.080, eps 0.01, speed 131.64 f/s, time 7.0 min\n",
            "49841: done 408 games, reward 186.400, eps 0.01, speed 130.14 f/s, time 7.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_186-20251201-0136-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_186-20251201-0136-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 185.080 -> 186.400\n",
            "49949: done 409 games, reward 186.400, eps 0.01, speed 122.88 f/s, time 7.0 min\n",
            "50128: done 410 games, reward 186.400, eps 0.01, speed 129.79 f/s, time 7.0 min\n",
            "50218: done 411 games, reward 186.400, eps 0.01, speed 96.62 f/s, time 7.1 min\n",
            "50299: done 412 games, reward 186.840, eps 0.01, speed 94.70 f/s, time 7.1 min\n",
            "50472: done 413 games, reward 186.400, eps 0.01, speed 101.19 f/s, time 7.1 min\n",
            "50792: done 414 games, reward 189.040, eps 0.01, speed 129.75 f/s, time 7.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_189-20251201-0136-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_189-20251201-0136-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 186.400 -> 189.040\n",
            "51126: done 415 games, reward 189.480, eps 0.01, speed 128.54 f/s, time 7.2 min\n",
            "51211: done 416 games, reward 186.400, eps 0.01, speed 130.05 f/s, time 7.2 min\n",
            "51314: done 417 games, reward 185.080, eps 0.01, speed 131.40 f/s, time 7.2 min\n",
            "51385: done 418 games, reward 185.080, eps 0.01, speed 128.70 f/s, time 7.2 min\n",
            "51614: done 419 games, reward 187.280, eps 0.01, speed 131.09 f/s, time 7.2 min\n",
            "51725: done 420 games, reward 186.840, eps 0.01, speed 122.46 f/s, time 7.3 min\n",
            "51968: done 421 games, reward 187.280, eps 0.01, speed 95.32 f/s, time 7.3 min\n",
            "52036: done 422 games, reward 185.520, eps 0.01, speed 107.58 f/s, time 7.3 min\n",
            "52159: done 423 games, reward 187.720, eps 0.01, speed 129.12 f/s, time 7.3 min\n",
            "52307: done 424 games, reward 188.600, eps 0.01, speed 129.22 f/s, time 7.3 min\n",
            "52422: done 425 games, reward 183.320, eps 0.01, speed 126.98 f/s, time 7.4 min\n",
            "52668: done 426 games, reward 186.800, eps 0.01, speed 128.95 f/s, time 7.4 min\n",
            "53101: done 427 games, reward 189.440, eps 0.01, speed 132.38 f/s, time 7.4 min\n",
            "53179: done 428 games, reward 185.560, eps 0.01, speed 128.31 f/s, time 7.5 min\n",
            "53306: done 429 games, reward 186.880, eps 0.01, speed 125.75 f/s, time 7.5 min\n",
            "53356: done 430 games, reward 186.880, eps 0.01, speed 97.87 f/s, time 7.5 min\n",
            "53403: done 431 games, reward 180.720, eps 0.01, speed 94.63 f/s, time 7.5 min\n",
            "53634: done 432 games, reward 181.480, eps 0.01, speed 98.17 f/s, time 7.5 min\n",
            "53688: done 433 games, reward 178.560, eps 0.01, speed 130.25 f/s, time 7.5 min\n",
            "53780: done 434 games, reward 179.000, eps 0.01, speed 128.13 f/s, time 7.6 min\n",
            "53954: done 435 games, reward 181.200, eps 0.01, speed 130.91 f/s, time 7.6 min\n",
            "54001: done 436 games, reward 179.880, eps 0.01, speed 125.90 f/s, time 7.6 min\n",
            "54112: done 437 games, reward 176.800, eps 0.01, speed 128.26 f/s, time 7.6 min\n",
            "54333: done 438 games, reward 176.360, eps 0.01, speed 129.24 f/s, time 7.6 min\n",
            "54398: done 439 games, reward 177.240, eps 0.01, speed 127.72 f/s, time 7.6 min\n",
            "54557: done 440 games, reward 179.000, eps 0.01, speed 130.62 f/s, time 7.7 min\n",
            "55224: done 441 games, reward 182.960, eps 0.01, speed 111.84 f/s, time 7.8 min\n",
            "55355: done 442 games, reward 183.480, eps 0.01, speed 127.94 f/s, time 7.8 min\n",
            "55484: done 443 games, reward 182.280, eps 0.01, speed 127.54 f/s, time 7.8 min\n",
            "55820: done 444 games, reward 182.280, eps 0.01, speed 130.71 f/s, time 7.8 min\n",
            "55884: done 445 games, reward 182.280, eps 0.01, speed 127.85 f/s, time 7.8 min\n",
            "56185: done 446 games, reward 182.280, eps 0.01, speed 132.38 f/s, time 7.9 min\n",
            "56508: done 447 games, reward 184.920, eps 0.01, speed 124.72 f/s, time 7.9 min\n",
            "57138: done 448 games, reward 186.800, eps 0.01, speed 113.32 f/s, time 8.0 min\n",
            "57207: done 449 games, reward 186.400, eps 0.01, speed 125.69 f/s, time 8.0 min\n",
            "57371: done 450 games, reward 186.840, eps 0.01, speed 130.20 f/s, time 8.0 min\n",
            "57457: done 451 games, reward 184.640, eps 0.01, speed 129.40 f/s, time 8.1 min\n",
            "57719: done 452 games, reward 186.400, eps 0.01, speed 131.45 f/s, time 8.1 min\n",
            "58042: done 453 games, reward 182.880, eps 0.01, speed 129.59 f/s, time 8.1 min\n",
            "58197: done 454 games, reward 183.680, eps 0.01, speed 99.02 f/s, time 8.2 min\n",
            "58292: done 455 games, reward 184.080, eps 0.01, speed 96.53 f/s, time 8.2 min\n",
            "58804: done 456 games, reward 183.200, eps 0.01, speed 123.56 f/s, time 8.2 min\n",
            "58883: done 457 games, reward 182.760, eps 0.01, speed 130.86 f/s, time 8.2 min\n",
            "58961: done 458 games, reward 182.760, eps 0.01, speed 128.59 f/s, time 8.3 min\n",
            "59603: done 459 games, reward 187.160, eps 0.01, speed 130.84 f/s, time 8.3 min\n",
            "59700: done 460 games, reward 185.400, eps 0.01, speed 111.16 f/s, time 8.4 min\n",
            "59874: done 461 games, reward 184.680, eps 0.01, speed 95.84 f/s, time 8.4 min\n",
            "60023: done 462 games, reward 186.440, eps 0.01, speed 106.08 f/s, time 8.4 min\n",
            "60235: done 463 games, reward 189.080, eps 0.01, speed 128.68 f/s, time 8.4 min\n",
            "60573: done 464 games, reward 189.080, eps 0.01, speed 130.20 f/s, time 8.5 min\n",
            "60802: done 465 games, reward 189.960, eps 0.01, speed 129.93 f/s, time 8.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_189-20251201-0137-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_189-20251201-0137-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 189.040 -> 189.960\n",
            "61045: done 466 games, reward 189.080, eps 0.01, speed 124.55 f/s, time 8.5 min\n",
            "61301: done 467 games, reward 189.080, eps 0.01, speed 118.34 f/s, time 8.6 min\n",
            "61449: done 468 games, reward 188.640, eps 0.01, speed 94.19 f/s, time 8.6 min\n",
            "61519: done 469 games, reward 189.080, eps 0.01, speed 92.57 f/s, time 8.6 min\n",
            "61572: done 470 games, reward 189.520, eps 0.01, speed 123.77 f/s, time 8.6 min\n",
            "61723: done 471 games, reward 188.200, eps 0.01, speed 127.68 f/s, time 8.6 min\n",
            "62033: done 472 games, reward 189.080, eps 0.01, speed 129.46 f/s, time 8.7 min\n",
            "62206: done 473 games, reward 189.080, eps 0.01, speed 130.34 f/s, time 8.7 min\n",
            "62418: done 474 games, reward 187.320, eps 0.01, speed 128.74 f/s, time 8.7 min\n",
            "62620: done 475 games, reward 186.880, eps 0.01, speed 130.41 f/s, time 8.8 min\n",
            "62664: done 476 games, reward 186.000, eps 0.01, speed 128.60 f/s, time 8.8 min\n",
            "62829: done 477 games, reward 185.120, eps 0.01, speed 121.60 f/s, time 8.8 min\n",
            "63032: done 478 games, reward 188.200, eps 0.01, speed 95.85 f/s, time 8.8 min\n",
            "63117: done 479 games, reward 187.320, eps 0.01, speed 97.43 f/s, time 8.8 min\n",
            "63263: done 480 games, reward 187.320, eps 0.01, speed 127.36 f/s, time 8.9 min\n",
            "63395: done 481 games, reward 189.520, eps 0.01, speed 129.26 f/s, time 8.9 min\n",
            "63594: done 482 games, reward 187.320, eps 0.01, speed 130.52 f/s, time 8.9 min\n",
            "63826: done 483 games, reward 186.880, eps 0.01, speed 131.62 f/s, time 8.9 min\n",
            "63989: done 484 games, reward 188.200, eps 0.01, speed 129.71 f/s, time 8.9 min\n",
            "64212: done 485 games, reward 187.320, eps 0.01, speed 129.82 f/s, time 9.0 min\n",
            "64430: done 486 games, reward 186.000, eps 0.01, speed 121.81 f/s, time 9.0 min\n",
            "64477: done 487 games, reward 185.560, eps 0.01, speed 98.26 f/s, time 9.0 min\n",
            "64636: done 488 games, reward 185.120, eps 0.01, speed 94.38 f/s, time 9.0 min\n",
            "64999: done 489 games, reward 189.080, eps 0.01, speed 121.69 f/s, time 9.1 min\n",
            "65152: done 490 games, reward 189.520, eps 0.01, speed 129.05 f/s, time 9.1 min\n",
            "65201: done 491 games, reward 186.880, eps 0.01, speed 129.66 f/s, time 9.1 min\n",
            "65471: done 492 games, reward 188.200, eps 0.01, speed 129.76 f/s, time 9.2 min\n",
            "65596: done 493 games, reward 183.800, eps 0.01, speed 130.26 f/s, time 9.2 min\n",
            "65674: done 494 games, reward 184.240, eps 0.01, speed 129.25 f/s, time 9.2 min\n",
            "66014: done 495 games, reward 189.000, eps 0.01, speed 127.02 f/s, time 9.2 min\n",
            "66090: done 496 games, reward 186.360, eps 0.01, speed 97.14 f/s, time 9.2 min\n",
            "66234: done 497 games, reward 183.760, eps 0.01, speed 94.72 f/s, time 9.3 min\n",
            "66408: done 498 games, reward 184.560, eps 0.01, speed 119.75 f/s, time 9.3 min\n",
            "66455: done 499 games, reward 181.480, eps 0.01, speed 133.82 f/s, time 9.3 min\n",
            "66638: done 500 games, reward 184.120, eps 0.01, speed 130.16 f/s, time 9.3 min\n",
            "67814: done 501 games, reward 190.720, eps 0.01, speed 122.00 f/s, time 9.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_190-20251201-0138-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_190-20251201-0138-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 189.960 -> 190.720\n",
            "67906: done 502 games, reward 189.880, eps 0.01, speed 98.59 f/s, time 9.5 min\n",
            "67958: done 503 games, reward 189.440, eps 0.01, speed 124.82 f/s, time 9.5 min\n",
            "68152: done 504 games, reward 191.200, eps 0.01, speed 130.37 f/s, time 9.5 min\n",
            "68217: done 505 games, reward 189.440, eps 0.01, speed 126.04 f/s, time 9.5 min\n",
            "68322: done 506 games, reward 188.120, eps 0.01, speed 131.72 f/s, time 9.5 min\n",
            "68526: done 507 games, reward 188.120, eps 0.01, speed 129.50 f/s, time 9.6 min\n",
            "68637: done 508 games, reward 187.240, eps 0.01, speed 129.71 f/s, time 9.6 min\n",
            "68896: done 509 games, reward 189.440, eps 0.01, speed 130.71 f/s, time 9.6 min\n",
            "69202: done 510 games, reward 191.640, eps 0.01, speed 121.10 f/s, time 9.7 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_191-20251201-0138-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_191-20251201-0138-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 190.720 -> 191.640\n",
            "69459: done 511 games, reward 192.080, eps 0.01, speed 95.50 f/s, time 9.7 min\n",
            "69547: done 512 games, reward 190.760, eps 0.01, speed 127.92 f/s, time 9.7 min\n",
            "69916: done 513 games, reward 191.640, eps 0.01, speed 127.76 f/s, time 9.8 min\n",
            "69961: done 514 games, reward 186.360, eps 0.01, speed 128.80 f/s, time 9.8 min\n",
            "70016: done 515 games, reward 185.920, eps 0.01, speed 130.31 f/s, time 9.8 min\n",
            "70184: done 516 games, reward 187.240, eps 0.01, speed 129.81 f/s, time 9.8 min\n",
            "70282: done 517 games, reward 185.920, eps 0.01, speed 130.39 f/s, time 9.8 min\n",
            "70488: done 518 games, reward 189.000, eps 0.01, speed 127.47 f/s, time 9.8 min\n",
            "70622: done 519 games, reward 185.480, eps 0.01, speed 130.43 f/s, time 9.9 min\n",
            "70914: done 520 games, reward 187.240, eps 0.01, speed 106.26 f/s, time 9.9 min\n",
            "71035: done 521 games, reward 185.480, eps 0.01, speed 96.20 f/s, time 9.9 min\n",
            "71356: done 522 games, reward 188.560, eps 0.01, speed 130.30 f/s, time 10.0 min\n",
            "71438: done 523 games, reward 187.240, eps 0.01, speed 129.23 f/s, time 10.0 min\n",
            "71492: done 524 games, reward 185.920, eps 0.01, speed 130.72 f/s, time 10.0 min\n",
            "71869: done 525 games, reward 186.360, eps 0.01, speed 129.34 f/s, time 10.0 min\n",
            "71923: done 526 games, reward 182.400, eps 0.01, speed 129.91 f/s, time 10.0 min\n",
            "71991: done 527 games, reward 180.200, eps 0.01, speed 127.37 f/s, time 10.0 min\n",
            "72138: done 528 games, reward 181.000, eps 0.01, speed 129.64 f/s, time 10.1 min\n",
            "72185: done 529 games, reward 179.240, eps 0.01, speed 128.82 f/s, time 10.1 min\n",
            "72245: done 530 games, reward 180.120, eps 0.01, speed 124.49 f/s, time 10.1 min\n",
            "72625: done 531 games, reward 183.640, eps 0.01, speed 100.95 f/s, time 10.1 min\n",
            "72669: done 532 games, reward 181.880, eps 0.01, speed 126.13 f/s, time 10.1 min\n",
            "73129: done 533 games, reward 183.640, eps 0.01, speed 131.47 f/s, time 10.2 min\n",
            "73229: done 534 games, reward 183.200, eps 0.01, speed 129.25 f/s, time 10.2 min\n",
            "73498: done 535 games, reward 183.200, eps 0.01, speed 130.78 f/s, time 10.3 min\n",
            "73644: done 536 games, reward 184.960, eps 0.01, speed 130.20 f/s, time 10.3 min\n",
            "73987: done 537 games, reward 187.600, eps 0.01, speed 101.22 f/s, time 10.3 min\n",
            "74064: done 538 games, reward 187.600, eps 0.01, speed 83.19 f/s, time 10.3 min\n",
            "74290: done 539 games, reward 188.480, eps 0.01, speed 84.06 f/s, time 10.4 min\n",
            "74494: done 540 games, reward 188.920, eps 0.01, speed 128.88 f/s, time 10.4 min\n",
            "74797: done 541 games, reward 186.280, eps 0.01, speed 131.03 f/s, time 10.5 min\n",
            "74972: done 542 games, reward 185.800, eps 0.01, speed 131.60 f/s, time 10.5 min\n",
            "75887: done 543 games, reward 190.960, eps 0.01, speed 116.40 f/s, time 10.6 min\n",
            "75997: done 544 games, reward 187.080, eps 0.01, speed 127.02 f/s, time 10.6 min\n",
            "76061: done 545 games, reward 187.600, eps 0.01, speed 128.12 f/s, time 10.6 min\n",
            "76209: done 546 games, reward 187.160, eps 0.01, speed 129.93 f/s, time 10.6 min\n",
            "76290: done 547 games, reward 182.320, eps 0.01, speed 128.54 f/s, time 10.7 min\n",
            "76489: done 548 games, reward 181.760, eps 0.01, speed 131.70 f/s, time 10.7 min\n",
            "76632: done 549 games, reward 183.920, eps 0.01, speed 131.62 f/s, time 10.7 min\n",
            "76703: done 550 games, reward 180.400, eps 0.01, speed 129.42 f/s, time 10.7 min\n",
            "77175: done 551 games, reward 182.600, eps 0.01, speed 130.97 f/s, time 10.8 min\n",
            "77407: done 552 games, reward 183.040, eps 0.01, speed 94.09 f/s, time 10.8 min\n",
            "77554: done 553 games, reward 181.720, eps 0.01, speed 112.44 f/s, time 10.8 min\n",
            "77901: done 554 games, reward 182.600, eps 0.01, speed 131.80 f/s, time 10.9 min\n",
            "78154: done 555 games, reward 183.920, eps 0.01, speed 131.53 f/s, time 10.9 min\n",
            "78330: done 556 games, reward 182.160, eps 0.01, speed 128.62 f/s, time 10.9 min\n",
            "78532: done 557 games, reward 183.040, eps 0.01, speed 132.12 f/s, time 11.0 min\n",
            "78629: done 558 games, reward 183.040, eps 0.01, speed 130.36 f/s, time 11.0 min\n",
            "78748: done 559 games, reward 177.320, eps 0.01, speed 131.83 f/s, time 11.0 min\n",
            "78988: done 560 games, reward 180.840, eps 0.01, speed 99.17 f/s, time 11.0 min\n",
            "79298: done 561 games, reward 181.120, eps 0.01, speed 116.92 f/s, time 11.1 min\n",
            "79349: done 562 games, reward 178.040, eps 0.01, speed 133.78 f/s, time 11.1 min\n",
            "79523: done 563 games, reward 178.040, eps 0.01, speed 130.59 f/s, time 11.1 min\n",
            "79684: done 564 games, reward 179.360, eps 0.01, speed 129.60 f/s, time 11.1 min\n",
            "79783: done 565 games, reward 178.040, eps 0.01, speed 132.50 f/s, time 11.1 min\n",
            "80261: done 566 games, reward 178.040, eps 0.01, speed 132.05 f/s, time 11.2 min\n",
            "80500: done 567 games, reward 179.360, eps 0.01, speed 108.82 f/s, time 11.2 min\n",
            "80888: done 568 games, reward 182.440, eps 0.01, speed 113.90 f/s, time 11.3 min\n",
            "80940: done 569 games, reward 182.440, eps 0.01, speed 130.70 f/s, time 11.3 min\n",
            "81130: done 570 games, reward 184.200, eps 0.01, speed 130.06 f/s, time 11.3 min\n",
            "81299: done 571 games, reward 182.000, eps 0.01, speed 130.11 f/s, time 11.3 min\n",
            "81350: done 572 games, reward 180.680, eps 0.01, speed 123.16 f/s, time 11.3 min\n",
            "81702: done 573 games, reward 184.200, eps 0.01, speed 129.25 f/s, time 11.4 min\n",
            "82058: done 574 games, reward 184.640, eps 0.01, speed 117.97 f/s, time 11.4 min\n",
            "82133: done 575 games, reward 182.880, eps 0.01, speed 94.68 f/s, time 11.5 min\n",
            "82317: done 576 games, reward 184.200, eps 0.01, speed 106.76 f/s, time 11.5 min\n",
            "82802: done 577 games, reward 187.720, eps 0.01, speed 127.75 f/s, time 11.5 min\n",
            "82998: done 578 games, reward 184.640, eps 0.01, speed 130.03 f/s, time 11.6 min\n",
            "83198: done 579 games, reward 185.520, eps 0.01, speed 131.09 f/s, time 11.6 min\n",
            "83269: done 580 games, reward 182.880, eps 0.01, speed 126.59 f/s, time 11.6 min\n",
            "83387: done 581 games, reward 182.440, eps 0.01, speed 130.93 f/s, time 11.6 min\n",
            "83626: done 582 games, reward 182.880, eps 0.01, speed 114.12 f/s, time 11.7 min\n",
            "83734: done 583 games, reward 182.440, eps 0.01, speed 94.64 f/s, time 11.7 min\n",
            "83809: done 584 games, reward 182.000, eps 0.01, speed 90.49 f/s, time 11.7 min\n",
            "83950: done 585 games, reward 182.000, eps 0.01, speed 128.02 f/s, time 11.7 min\n",
            "84025: done 586 games, reward 181.560, eps 0.01, speed 129.08 f/s, time 11.7 min\n",
            "84164: done 587 games, reward 182.880, eps 0.01, speed 127.23 f/s, time 11.7 min\n",
            "84355: done 588 games, reward 183.760, eps 0.01, speed 130.48 f/s, time 11.8 min\n",
            "84679: done 589 games, reward 184.640, eps 0.01, speed 130.02 f/s, time 11.8 min\n",
            "84770: done 590 games, reward 184.360, eps 0.01, speed 130.68 f/s, time 11.8 min\n",
            "84887: done 591 games, reward 185.680, eps 0.01, speed 131.82 f/s, time 11.8 min\n",
            "85143: done 592 games, reward 184.800, eps 0.01, speed 123.97 f/s, time 11.9 min\n",
            "85279: done 593 games, reward 184.360, eps 0.01, speed 95.46 f/s, time 11.9 min\n",
            "85614: done 594 games, reward 188.760, eps 0.01, speed 115.11 f/s, time 11.9 min\n",
            "85713: done 595 games, reward 183.480, eps 0.01, speed 131.00 f/s, time 11.9 min\n",
            "85950: done 596 games, reward 183.480, eps 0.01, speed 132.15 f/s, time 12.0 min\n",
            "86631: done 597 games, reward 189.600, eps 0.01, speed 130.36 f/s, time 12.1 min\n",
            "86693: done 598 games, reward 187.840, eps 0.01, speed 129.32 f/s, time 12.1 min\n",
            "86797: done 599 games, reward 187.840, eps 0.01, speed 95.64 f/s, time 12.1 min\n",
            "87164: done 600 games, reward 187.840, eps 0.01, speed 108.14 f/s, time 12.1 min\n",
            "87218: done 601 games, reward 181.240, eps 0.01, speed 131.17 f/s, time 12.2 min\n",
            "87674: done 602 games, reward 185.200, eps 0.01, speed 131.06 f/s, time 12.2 min\n",
            "87873: done 603 games, reward 186.960, eps 0.01, speed 130.24 f/s, time 12.2 min\n",
            "87987: done 604 games, reward 185.640, eps 0.01, speed 130.55 f/s, time 12.3 min\n",
            "88069: done 605 games, reward 186.520, eps 0.01, speed 131.27 f/s, time 12.3 min\n",
            "88321: done 606 games, reward 188.280, eps 0.01, speed 122.71 f/s, time 12.3 min\n",
            "88375: done 607 games, reward 186.960, eps 0.01, speed 97.32 f/s, time 12.3 min\n",
            "88500: done 608 games, reward 187.400, eps 0.01, speed 95.01 f/s, time 12.3 min\n",
            "88611: done 609 games, reward 184.760, eps 0.01, speed 101.81 f/s, time 12.3 min\n",
            "88753: done 610 games, reward 180.800, eps 0.01, speed 129.94 f/s, time 12.4 min\n",
            "88846: done 611 games, reward 180.360, eps 0.01, speed 128.58 f/s, time 12.4 min\n",
            "89031: done 612 games, reward 183.000, eps 0.01, speed 129.28 f/s, time 12.4 min\n",
            "89119: done 613 games, reward 180.360, eps 0.01, speed 129.27 f/s, time 12.4 min\n",
            "89177: done 614 games, reward 180.360, eps 0.01, speed 130.90 f/s, time 12.4 min\n",
            "89369: done 615 games, reward 182.120, eps 0.01, speed 130.62 f/s, time 12.4 min\n",
            "89466: done 616 games, reward 182.560, eps 0.01, speed 131.44 f/s, time 12.5 min\n",
            "89887: done 617 games, reward 184.320, eps 0.01, speed 127.85 f/s, time 12.5 min\n",
            "90173: done 618 games, reward 183.440, eps 0.01, speed 96.53 f/s, time 12.6 min\n",
            "90426: done 619 games, reward 186.080, eps 0.01, speed 128.45 f/s, time 12.6 min\n",
            "90476: done 620 games, reward 183.000, eps 0.01, speed 127.51 f/s, time 12.6 min\n",
            "90697: done 621 games, reward 182.120, eps 0.01, speed 131.41 f/s, time 12.6 min\n",
            "90816: done 622 games, reward 179.920, eps 0.01, speed 130.05 f/s, time 12.6 min\n",
            "90995: done 623 games, reward 181.240, eps 0.01, speed 130.28 f/s, time 12.7 min\n",
            "91207: done 624 games, reward 182.120, eps 0.01, speed 129.67 f/s, time 12.7 min\n",
            "91518: done 625 games, reward 183.880, eps 0.01, speed 120.12 f/s, time 12.7 min\n",
            "91880: done 626 games, reward 186.080, eps 0.01, speed 106.11 f/s, time 12.8 min\n",
            "92192: done 627 games, reward 189.160, eps 0.01, speed 130.02 f/s, time 12.8 min\n",
            "92683: done 628 games, reward 190.480, eps 0.01, speed 130.33 f/s, time 12.9 min\n",
            "92754: done 629 games, reward 190.480, eps 0.01, speed 129.84 f/s, time 12.9 min\n",
            "92942: done 630 games, reward 190.480, eps 0.01, speed 130.28 f/s, time 12.9 min\n",
            "93216: done 631 games, reward 191.800, eps 0.01, speed 107.58 f/s, time 13.0 min\n",
            "93381: done 632 games, reward 193.760, eps 0.01, speed 100.65 f/s, time 13.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_193-20251201-0142-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_193-20251201-0142-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 191.640 -> 193.760\n",
            "93593: done 633 games, reward 193.320, eps 0.01, speed 127.21 f/s, time 13.0 min\n",
            "93779: done 634 games, reward 195.960, eps 0.01, speed 126.84 f/s, time 13.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_195-20251201-0142-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_195-20251201-0142-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 193.760 -> 195.960\n",
            "94009: done 635 games, reward 195.160, eps 0.01, speed 129.98 f/s, time 13.1 min\n",
            "94150: done 636 games, reward 194.720, eps 0.01, speed 130.03 f/s, time 13.1 min\n",
            "94438: done 637 games, reward 195.600, eps 0.01, speed 129.87 f/s, time 13.1 min\n",
            "94513: done 638 games, reward 195.160, eps 0.01, speed 133.13 f/s, time 13.1 min\n",
            "94675: done 639 games, reward 195.160, eps 0.01, speed 112.73 f/s, time 13.2 min\n",
            "94777: done 640 games, reward 194.280, eps 0.01, speed 96.05 f/s, time 13.2 min\n",
            "95023: done 641 games, reward 193.400, eps 0.01, speed 108.08 f/s, time 13.2 min\n",
            "95141: done 642 games, reward 194.680, eps 0.01, speed 131.41 f/s, time 13.2 min\n",
            "95395: done 643 games, reward 191.600, eps 0.01, speed 130.00 f/s, time 13.3 min\n",
            "95550: done 644 games, reward 191.960, eps 0.01, speed 131.06 f/s, time 13.3 min\n",
            "95975: done 645 games, reward 197.600, eps 0.01, speed 131.13 f/s, time 13.3 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_197-20251201-0142-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_197-20251201-0142-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 195.960 -> 197.600\n",
            "96116: done 646 games, reward 198.640, eps 0.01, speed 124.84 f/s, time 13.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_198-20251201-0142-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_198-20251201-0142-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 197.600 -> 198.640\n",
            "96154: done 647 games, reward 198.200, eps 0.01, speed 114.99 f/s, time 13.4 min\n",
            "96420: done 648 games, reward 201.720, eps 0.01, speed 97.75 f/s, time 13.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_201-20251201-0142-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_201-20251201-0142-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 198.640 -> 201.720\n",
            "96498: done 649 games, reward 199.960, eps 0.01, speed 89.72 f/s, time 13.4 min\n",
            "96659: done 650 games, reward 201.920, eps 0.01, speed 127.71 f/s, time 13.4 min\n",
            "96777: done 651 games, reward 200.600, eps 0.01, speed 129.36 f/s, time 13.5 min\n",
            "96848: done 652 games, reward 200.160, eps 0.01, speed 132.17 f/s, time 13.5 min\n",
            "97044: done 653 games, reward 201.480, eps 0.01, speed 130.86 f/s, time 13.5 min\n",
            "97610: done 654 games, reward 206.400, eps 0.01, speed 128.28 f/s, time 13.6 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_206-20251201-0142-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_206-20251201-0142-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 201.720 -> 206.400\n",
            "97662: done 655 games, reward 204.680, eps 0.01, speed 120.02 f/s, time 13.6 min\n",
            "97717: done 656 games, reward 202.960, eps 0.01, speed 126.00 f/s, time 13.6 min\n",
            "97859: done 657 games, reward 203.400, eps 0.01, speed 105.92 f/s, time 13.6 min\n",
            "97910: done 658 games, reward 202.960, eps 0.01, speed 93.25 f/s, time 13.6 min\n",
            "98140: done 659 games, reward 205.160, eps 0.01, speed 103.89 f/s, time 13.7 min\n",
            "98248: done 660 games, reward 203.400, eps 0.01, speed 129.96 f/s, time 13.7 min\n",
            "98306: done 661 games, reward 201.200, eps 0.01, speed 130.06 f/s, time 13.7 min\n",
            "98424: done 662 games, reward 201.640, eps 0.01, speed 129.72 f/s, time 13.7 min\n",
            "98788: done 663 games, reward 205.160, eps 0.01, speed 130.59 f/s, time 13.7 min\n",
            "98988: done 664 games, reward 203.880, eps 0.01, speed 128.92 f/s, time 13.8 min\n",
            "99025: done 665 games, reward 202.560, eps 0.01, speed 127.66 f/s, time 13.8 min\n",
            "99436: done 666 games, reward 203.440, eps 0.01, speed 121.21 f/s, time 13.8 min\n",
            "99625: done 667 games, reward 203.880, eps 0.01, speed 94.34 f/s, time 13.9 min\n",
            "99778: done 668 games, reward 201.360, eps 0.01, speed 125.46 f/s, time 13.9 min\n",
            "100060: done 669 games, reward 205.320, eps 0.01, speed 129.70 f/s, time 13.9 min\n",
            "100146: done 670 games, reward 205.320, eps 0.01, speed 130.95 f/s, time 13.9 min\n",
            "100285: done 671 games, reward 204.560, eps 0.01, speed 127.66 f/s, time 13.9 min\n",
            "100544: done 672 games, reward 209.840, eps 0.01, speed 130.38 f/s, time 14.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_209-20251201-0143-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_209-20251201-0143-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 206.400 -> 209.840\n",
            "100673: done 673 games, reward 207.200, eps 0.01, speed 127.00 f/s, time 14.0 min\n",
            "100721: done 674 games, reward 205.000, eps 0.01, speed 126.64 f/s, time 14.0 min\n",
            "100895: done 675 games, reward 207.640, eps 0.01, speed 132.56 f/s, time 14.0 min\n",
            "101078: done 676 games, reward 209.400, eps 0.01, speed 100.21 f/s, time 14.1 min\n",
            "101167: done 677 games, reward 205.440, eps 0.01, speed 97.98 f/s, time 14.1 min\n",
            "101773: done 678 games, reward 213.520, eps 0.01, speed 123.84 f/s, time 14.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_213-20251201-0143-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_213-20251201-0143-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 209.840 -> 213.520\n",
            "101864: done 679 games, reward 213.160, eps 0.01, speed 123.78 f/s, time 14.2 min\n",
            "101928: done 680 games, reward 213.200, eps 0.01, speed 130.61 f/s, time 14.2 min\n",
            "102113: done 681 games, reward 214.520, eps 0.01, speed 130.37 f/s, time 14.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_214-20251201-0143-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_214-20251201-0143-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 213.520 -> 214.520\n",
            "102249: done 682 games, reward 214.960, eps 0.01, speed 125.00 f/s, time 14.2 min\n",
            "102403: done 683 games, reward 215.480, eps 0.01, speed 130.84 f/s, time 14.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_215-20251201-0143-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_215-20251201-0143-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 214.520 -> 215.480\n",
            "102518: done 684 games, reward 215.920, eps 0.01, speed 119.69 f/s, time 14.2 min\n",
            "102869: done 685 games, reward 218.120, eps 0.01, speed 99.60 f/s, time 14.3 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_218-20251201-0143-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_218-20251201-0143-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 215.480 -> 218.120\n",
            "103063: done 686 games, reward 219.160, eps 0.01, speed 121.96 f/s, time 14.3 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_219-20251201-0143-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_219-20251201-0143-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 218.120 -> 219.160\n",
            "103171: done 687 games, reward 219.160, eps 0.01, speed 125.68 f/s, time 14.3 min\n",
            "103441: done 688 games, reward 222.240, eps 0.01, speed 131.55 f/s, time 14.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_222-20251201-0143-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_222-20251201-0143-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 219.160 -> 222.240\n",
            "103489: done 689 games, reward 217.400, eps 0.01, speed 112.89 f/s, time 14.4 min\n",
            "103886: done 690 games, reward 219.000, eps 0.01, speed 126.59 f/s, time 14.4 min\n",
            "104105: done 691 games, reward 220.320, eps 0.01, speed 120.24 f/s, time 14.5 min\n",
            "104162: done 692 games, reward 219.040, eps 0.01, speed 96.34 f/s, time 14.5 min\n",
            "104270: done 693 games, reward 219.480, eps 0.01, speed 93.53 f/s, time 14.5 min\n",
            "104439: done 694 games, reward 216.400, eps 0.01, speed 96.60 f/s, time 14.5 min\n",
            "104504: done 695 games, reward 216.400, eps 0.01, speed 92.65 f/s, time 14.5 min\n",
            "104604: done 696 games, reward 216.840, eps 0.01, speed 92.08 f/s, time 14.6 min\n",
            "104664: done 697 games, reward 210.240, eps 0.01, speed 92.90 f/s, time 14.6 min\n",
            "104874: done 698 games, reward 214.200, eps 0.01, speed 127.89 f/s, time 14.6 min\n",
            "104962: done 699 games, reward 215.520, eps 0.01, speed 131.75 f/s, time 14.6 min\n",
            "105026: done 700 games, reward 213.320, eps 0.01, speed 126.33 f/s, time 14.6 min\n",
            "105152: done 701 games, reward 214.200, eps 0.01, speed 129.88 f/s, time 14.6 min\n",
            "105270: done 702 games, reward 211.080, eps 0.01, speed 129.70 f/s, time 14.6 min\n",
            "105560: done 703 games, reward 214.600, eps 0.01, speed 123.60 f/s, time 14.7 min\n",
            "105601: done 704 games, reward 213.280, eps 0.01, speed 96.65 f/s, time 14.7 min\n",
            "105739: done 705 games, reward 214.160, eps 0.01, speed 95.10 f/s, time 14.7 min\n",
            "105786: done 706 games, reward 211.080, eps 0.01, speed 91.45 f/s, time 14.7 min\n",
            "105882: done 707 games, reward 212.400, eps 0.01, speed 114.97 f/s, time 14.7 min\n",
            "106014: done 708 games, reward 213.720, eps 0.01, speed 129.56 f/s, time 14.8 min\n",
            "106062: done 709 games, reward 212.840, eps 0.01, speed 126.42 f/s, time 14.8 min\n",
            "106187: done 710 games, reward 215.480, eps 0.01, speed 128.95 f/s, time 14.8 min\n",
            "106328: done 711 games, reward 216.360, eps 0.01, speed 130.51 f/s, time 14.8 min\n",
            "106453: done 712 games, reward 214.600, eps 0.01, speed 124.44 f/s, time 14.8 min\n",
            "106645: done 713 games, reward 216.800, eps 0.01, speed 129.37 f/s, time 14.8 min\n",
            "106762: done 714 games, reward 219.000, eps 0.01, speed 128.81 f/s, time 14.9 min\n",
            "106810: done 715 games, reward 217.240, eps 0.01, speed 132.38 f/s, time 14.9 min\n",
            "107020: done 716 games, reward 219.000, eps 0.01, speed 129.62 f/s, time 14.9 min\n",
            "107064: done 717 games, reward 216.800, eps 0.01, speed 129.75 f/s, time 14.9 min\n",
            "107209: done 718 games, reward 217.240, eps 0.01, speed 100.36 f/s, time 14.9 min\n",
            "107256: done 719 games, reward 213.720, eps 0.01, speed 96.76 f/s, time 14.9 min\n",
            "107550: done 720 games, reward 217.680, eps 0.01, speed 112.13 f/s, time 15.0 min\n",
            "108092: done 721 games, reward 223.840, eps 0.01, speed 130.76 f/s, time 15.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_223-20251201-0144-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_223-20251201-0144-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 222.240 -> 223.840\n",
            "108301: done 722 games, reward 225.880, eps 0.01, speed 125.02 f/s, time 15.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_225-20251201-0144-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_225-20251201-0144-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 223.840 -> 225.880\n",
            "108351: done 723 games, reward 223.680, eps 0.01, speed 119.69 f/s, time 15.1 min\n",
            "108566: done 724 games, reward 224.120, eps 0.01, speed 129.05 f/s, time 15.1 min\n",
            "108940: done 725 games, reward 225.880, eps 0.01, speed 101.72 f/s, time 15.2 min\n",
            "109003: done 726 games, reward 224.160, eps 0.01, speed 116.37 f/s, time 15.2 min\n",
            "109147: done 727 games, reward 222.840, eps 0.01, speed 129.66 f/s, time 15.2 min\n",
            "109469: done 728 games, reward 223.720, eps 0.01, speed 129.62 f/s, time 15.2 min\n",
            "109531: done 729 games, reward 224.160, eps 0.01, speed 127.35 f/s, time 15.2 min\n",
            "109722: done 730 games, reward 226.360, eps 0.01, speed 131.73 f/s, time 15.3 min\n",
            "109867: done 731 games, reward 223.280, eps 0.01, speed 131.68 f/s, time 15.3 min\n",
            "109976: done 732 games, reward 221.760, eps 0.01, speed 130.13 f/s, time 15.3 min\n",
            "110384: done 733 games, reward 226.600, eps 0.01, speed 117.31 f/s, time 15.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_226-20251201-0144-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_226-20251201-0144-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 225.880 -> 226.600\n",
            "110476: done 734 games, reward 222.640, eps 0.01, speed 92.36 f/s, time 15.4 min\n",
            "110553: done 735 games, reward 221.280, eps 0.01, speed 96.06 f/s, time 15.4 min\n",
            "110647: done 736 games, reward 220.840, eps 0.01, speed 127.73 f/s, time 15.4 min\n",
            "110921: done 737 games, reward 221.720, eps 0.01, speed 131.20 f/s, time 15.4 min\n",
            "110958: done 738 games, reward 221.280, eps 0.01, speed 126.30 f/s, time 15.4 min\n",
            "111072: done 739 games, reward 220.840, eps 0.01, speed 129.50 f/s, time 15.5 min\n",
            "111275: done 740 games, reward 221.720, eps 0.01, speed 131.35 f/s, time 15.5 min\n",
            "111336: done 741 games, reward 219.520, eps 0.01, speed 127.55 f/s, time 15.5 min\n",
            "111461: done 742 games, reward 219.520, eps 0.01, speed 130.88 f/s, time 15.5 min\n",
            "111701: done 743 games, reward 219.520, eps 0.01, speed 129.62 f/s, time 15.5 min\n",
            "111933: done 744 games, reward 219.520, eps 0.01, speed 111.07 f/s, time 15.6 min\n",
            "112013: done 745 games, reward 214.240, eps 0.01, speed 94.74 f/s, time 15.6 min\n",
            "112161: done 746 games, reward 213.640, eps 0.01, speed 99.07 f/s, time 15.6 min\n",
            "112212: done 747 games, reward 214.080, eps 0.01, speed 129.07 f/s, time 15.6 min\n",
            "112663: done 748 games, reward 214.960, eps 0.01, speed 129.97 f/s, time 15.7 min\n",
            "112717: done 749 games, reward 214.080, eps 0.01, speed 130.83 f/s, time 15.7 min\n",
            "112878: done 750 games, reward 213.600, eps 0.01, speed 130.42 f/s, time 15.7 min\n",
            "112999: done 751 games, reward 214.040, eps 0.01, speed 129.99 f/s, time 15.7 min\n",
            "113111: done 752 games, reward 213.600, eps 0.01, speed 129.51 f/s, time 15.7 min\n",
            "113216: done 753 games, reward 211.400, eps 0.01, speed 126.55 f/s, time 15.7 min\n",
            "113385: done 754 games, reward 206.480, eps 0.01, speed 130.60 f/s, time 15.8 min\n",
            "113584: done 755 games, reward 209.520, eps 0.01, speed 98.43 f/s, time 15.8 min\n",
            "113699: done 756 games, reward 209.480, eps 0.01, speed 93.77 f/s, time 15.8 min\n",
            "113982: done 757 games, reward 213.000, eps 0.01, speed 129.59 f/s, time 15.9 min\n",
            "114034: done 758 games, reward 213.000, eps 0.01, speed 132.15 f/s, time 15.9 min\n",
            "114254: done 759 games, reward 210.800, eps 0.01, speed 130.69 f/s, time 15.9 min\n",
            "114628: done 760 games, reward 215.640, eps 0.01, speed 130.99 f/s, time 15.9 min\n",
            "114736: done 761 games, reward 216.120, eps 0.01, speed 129.85 f/s, time 15.9 min\n",
            "114806: done 762 games, reward 217.120, eps 0.01, speed 131.49 f/s, time 16.0 min\n",
            "114961: done 763 games, reward 212.280, eps 0.01, speed 131.61 f/s, time 16.0 min\n",
            "115181: done 764 games, reward 215.320, eps 0.01, speed 102.25 f/s, time 16.0 min\n",
            "115387: done 765 games, reward 216.640, eps 0.01, speed 107.06 f/s, time 16.0 min\n",
            "115541: done 766 games, reward 214.440, eps 0.01, speed 127.55 f/s, time 16.1 min\n",
            "115672: done 767 games, reward 214.440, eps 0.01, speed 130.52 f/s, time 16.1 min\n",
            "115892: done 768 games, reward 214.320, eps 0.01, speed 129.55 f/s, time 16.1 min\n",
            "116064: done 769 games, reward 213.000, eps 0.01, speed 129.46 f/s, time 16.1 min\n",
            "116361: done 770 games, reward 213.880, eps 0.01, speed 130.69 f/s, time 16.2 min\n",
            "116438: done 771 games, reward 212.880, eps 0.01, speed 130.06 f/s, time 16.2 min\n",
            "116568: done 772 games, reward 211.120, eps 0.01, speed 130.52 f/s, time 16.2 min\n",
            "116706: done 773 games, reward 210.680, eps 0.01, speed 99.26 f/s, time 16.2 min\n",
            "116768: done 774 games, reward 211.560, eps 0.01, speed 96.25 f/s, time 16.2 min\n",
            "117335: done 775 games, reward 215.520, eps 0.01, speed 121.73 f/s, time 16.3 min\n",
            "117954: done 776 games, reward 226.400, eps 0.01, speed 130.85 f/s, time 16.4 min\n",
            "118043: done 777 games, reward 226.560, eps 0.01, speed 130.07 f/s, time 16.4 min\n",
            "118254: done 778 games, reward 220.680, eps 0.01, speed 115.61 f/s, time 16.4 min\n",
            "118470: done 779 games, reward 222.800, eps 0.01, speed 95.77 f/s, time 16.5 min\n",
            "118716: done 780 games, reward 223.200, eps 0.01, speed 130.95 f/s, time 16.5 min\n",
            "118897: done 781 games, reward 222.320, eps 0.01, speed 129.14 f/s, time 16.5 min\n",
            "119541: done 782 games, reward 224.520, eps 0.01, speed 130.64 f/s, time 16.6 min\n",
            "119673: done 783 games, reward 222.240, eps 0.01, speed 131.32 f/s, time 16.6 min\n",
            "119951: done 784 games, reward 224.440, eps 0.01, speed 104.43 f/s, time 16.7 min\n",
            "120066: done 785 games, reward 221.800, eps 0.01, speed 96.48 f/s, time 16.7 min\n",
            "120409: done 786 games, reward 220.320, eps 0.01, speed 129.11 f/s, time 16.7 min\n",
            "120688: done 787 games, reward 224.280, eps 0.01, speed 128.83 f/s, time 16.8 min\n",
            "120756: done 788 games, reward 219.880, eps 0.01, speed 132.16 f/s, time 16.8 min\n",
            "120955: done 789 games, reward 220.760, eps 0.01, speed 129.83 f/s, time 16.8 min\n",
            "121150: done 790 games, reward 220.320, eps 0.01, speed 130.40 f/s, time 16.8 min\n",
            "121579: done 791 games, reward 220.760, eps 0.01, speed 110.17 f/s, time 16.9 min\n",
            "121636: done 792 games, reward 220.760, eps 0.01, speed 94.40 f/s, time 16.9 min\n",
            "121838: done 793 games, reward 219.880, eps 0.01, speed 128.79 f/s, time 16.9 min\n",
            "121912: done 794 games, reward 218.560, eps 0.01, speed 130.61 f/s, time 16.9 min\n",
            "122024: done 795 games, reward 219.880, eps 0.01, speed 130.50 f/s, time 16.9 min\n",
            "122148: done 796 games, reward 220.760, eps 0.01, speed 129.96 f/s, time 17.0 min\n",
            "122214: done 797 games, reward 221.200, eps 0.01, speed 127.85 f/s, time 17.0 min\n",
            "122386: done 798 games, reward 220.320, eps 0.01, speed 130.36 f/s, time 17.0 min\n",
            "122763: done 799 games, reward 224.280, eps 0.01, speed 130.91 f/s, time 17.0 min\n",
            "122831: done 800 games, reward 224.280, eps 0.01, speed 129.41 f/s, time 17.1 min\n",
            "123051: done 801 games, reward 223.840, eps 0.01, speed 108.03 f/s, time 17.1 min\n",
            "123199: done 802 games, reward 224.280, eps 0.01, speed 95.48 f/s, time 17.1 min\n",
            "123483: done 803 games, reward 222.960, eps 0.01, speed 127.13 f/s, time 17.1 min\n",
            "123773: done 804 games, reward 223.400, eps 0.01, speed 130.80 f/s, time 17.2 min\n",
            "124165: done 805 games, reward 226.040, eps 0.01, speed 130.18 f/s, time 17.2 min\n",
            "124289: done 806 games, reward 227.360, eps 0.01, speed 127.38 f/s, time 17.3 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_227-20251201-0146-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_227-20251201-0146-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 226.600 -> 227.360\n",
            "124413: done 807 games, reward 227.480, eps 0.01, speed 125.12 f/s, time 17.3 min\n",
            "125036: done 808 games, reward 231.440, eps 0.01, speed 112.38 f/s, time 17.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_231-20251201-0146-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_231-20251201-0146-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 227.360 -> 231.440\n",
            "125084: done 809 games, reward 231.480, eps 0.01, speed 115.27 f/s, time 17.4 min\n",
            "125382: done 810 games, reward 233.680, eps 0.01, speed 131.77 f/s, time 17.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_233-20251201-0146-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_233-20251201-0146-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 231.440 -> 233.680\n",
            "125539: done 811 games, reward 233.240, eps 0.01, speed 123.18 f/s, time 17.4 min\n",
            "125617: done 812 games, reward 233.680, eps 0.01, speed 128.31 f/s, time 17.4 min\n",
            "125855: done 813 games, reward 232.800, eps 0.01, speed 129.78 f/s, time 17.5 min\n",
            "126093: done 814 games, reward 233.680, eps 0.01, speed 125.42 f/s, time 17.5 min\n",
            "126169: done 815 games, reward 234.120, eps 0.01, speed 88.24 f/s, time 17.5 min\n",
            "126425: done 816 games, reward 232.800, eps 0.01, speed 99.91 f/s, time 17.6 min\n",
            "127149: done 817 games, reward 239.400, eps 0.01, speed 130.00 f/s, time 17.6 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_239-20251201-0146-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_239-20251201-0146-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 233.680 -> 239.400\n",
            "127327: done 818 games, reward 238.200, eps 0.01, speed 128.32 f/s, time 17.7 min\n",
            "127384: done 819 games, reward 238.680, eps 0.01, speed 127.78 f/s, time 17.7 min\n",
            "127815: done 820 games, reward 240.000, eps 0.01, speed 112.07 f/s, time 17.7 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_240-20251201-0146-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_240-20251201-0146-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 239.400 -> 240.000\n",
            "127901: done 821 games, reward 234.720, eps 0.01, speed 85.62 f/s, time 17.8 min\n",
            "128036: done 822 games, reward 232.800, eps 0.01, speed 110.29 f/s, time 17.8 min\n",
            "128235: done 823 games, reward 234.560, eps 0.01, speed 128.73 f/s, time 17.8 min\n",
            "128322: done 824 games, reward 235.440, eps 0.01, speed 127.13 f/s, time 17.8 min\n",
            "128456: done 825 games, reward 232.800, eps 0.01, speed 130.43 f/s, time 17.8 min\n",
            "129102: done 826 games, reward 238.920, eps 0.01, speed 130.23 f/s, time 17.9 min\n",
            "129213: done 827 games, reward 238.160, eps 0.01, speed 129.28 f/s, time 17.9 min\n",
            "129392: done 828 games, reward 237.560, eps 0.01, speed 95.46 f/s, time 18.0 min\n",
            "129654: done 829 games, reward 239.320, eps 0.01, speed 99.69 f/s, time 18.0 min\n",
            "129941: done 830 games, reward 239.320, eps 0.01, speed 123.31 f/s, time 18.0 min\n",
            "130049: done 831 games, reward 237.560, eps 0.01, speed 130.16 f/s, time 18.1 min\n",
            "130584: done 832 games, reward 243.280, eps 0.01, speed 127.37 f/s, time 18.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_243-20251201-0147-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_243-20251201-0147-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 240.000 -> 243.280\n",
            "130658: done 833 games, reward 236.680, eps 0.01, speed 120.57 f/s, time 18.1 min\n",
            "130768: done 834 games, reward 237.640, eps 0.01, speed 127.48 f/s, time 18.2 min\n",
            "130906: done 835 games, reward 240.680, eps 0.01, speed 93.08 f/s, time 18.2 min\n",
            "131089: done 836 games, reward 242.440, eps 0.01, speed 97.36 f/s, time 18.2 min\n",
            "131137: done 837 games, reward 236.720, eps 0.01, speed 123.87 f/s, time 18.2 min\n",
            "131498: done 838 games, reward 242.440, eps 0.01, speed 129.78 f/s, time 18.3 min\n",
            "131777: done 839 games, reward 241.560, eps 0.01, speed 130.08 f/s, time 18.3 min\n",
            "131898: done 840 games, reward 239.360, eps 0.01, speed 131.89 f/s, time 18.3 min\n",
            "132255: done 841 games, reward 244.200, eps 0.01, speed 130.47 f/s, time 18.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_244-20251201-0147-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_244-20251201-0147-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 243.280 -> 244.200\n",
            "132379: done 842 games, reward 243.320, eps 0.01, speed 112.46 f/s, time 18.4 min\n",
            "132500: done 843 games, reward 240.280, eps 0.01, speed 95.34 f/s, time 18.4 min\n",
            "132650: done 844 games, reward 242.040, eps 0.01, speed 96.12 f/s, time 18.4 min\n",
            "133116: done 845 games, reward 247.600, eps 0.01, speed 126.94 f/s, time 18.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_247-20251201-0147-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_247-20251201-0147-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 244.200 -> 247.600\n",
            "133164: done 846 games, reward 246.760, eps 0.01, speed 116.85 f/s, time 18.5 min\n",
            "133329: done 847 games, reward 247.640, eps 0.01, speed 126.75 f/s, time 18.5 min\n",
            "133721: done 848 games, reward 245.880, eps 0.01, speed 126.87 f/s, time 18.6 min\n",
            "133841: done 849 games, reward 246.320, eps 0.01, speed 129.55 f/s, time 18.6 min\n",
            "133982: done 850 games, reward 246.160, eps 0.01, speed 102.73 f/s, time 18.6 min\n",
            "134035: done 851 games, reward 244.400, eps 0.01, speed 86.59 f/s, time 18.6 min\n",
            "134082: done 852 games, reward 243.960, eps 0.01, speed 93.16 f/s, time 18.6 min\n",
            "134547: done 853 games, reward 248.360, eps 0.01, speed 117.83 f/s, time 18.7 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_248-20251201-0147-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_248-20251201-0147-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 247.600 -> 248.360\n",
            "134768: done 854 games, reward 247.040, eps 0.01, speed 127.41 f/s, time 18.7 min\n",
            "134900: done 855 games, reward 245.920, eps 0.01, speed 128.26 f/s, time 18.7 min\n",
            "135543: done 856 games, reward 252.080, eps 0.01, speed 98.91 f/s, time 18.8 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_252-20251201-0148-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_252-20251201-0148-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 248.360 -> 252.080\n",
            "135715: done 857 games, reward 247.760, eps 0.01, speed 100.73 f/s, time 18.9 min\n",
            "135830: done 858 games, reward 248.760, eps 0.01, speed 124.44 f/s, time 18.9 min\n",
            "136375: done 859 games, reward 254.480, eps 0.01, speed 128.37 f/s, time 19.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_254-20251201-0148-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_254-20251201-0148-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 252.080 -> 254.480\n",
            "136505: done 860 games, reward 249.320, eps 0.01, speed 122.85 f/s, time 19.0 min\n",
            "136554: done 861 games, reward 248.840, eps 0.01, speed 126.73 f/s, time 19.0 min\n",
            "136756: done 862 games, reward 250.040, eps 0.01, speed 128.79 f/s, time 19.0 min\n",
            "136895: done 863 games, reward 250.480, eps 0.01, speed 122.55 f/s, time 19.0 min\n",
            "136972: done 864 games, reward 246.960, eps 0.01, speed 96.73 f/s, time 19.0 min\n",
            "137124: done 865 games, reward 248.280, eps 0.01, speed 94.46 f/s, time 19.1 min\n",
            "137638: done 866 games, reward 250.960, eps 0.01, speed 123.15 f/s, time 19.1 min\n",
            "137716: done 867 games, reward 249.720, eps 0.01, speed 127.68 f/s, time 19.1 min\n",
            "137874: done 868 games, reward 250.600, eps 0.01, speed 129.89 f/s, time 19.2 min\n",
            "137925: done 869 games, reward 247.960, eps 0.01, speed 133.08 f/s, time 19.2 min\n",
            "138017: done 870 games, reward 246.200, eps 0.01, speed 128.86 f/s, time 19.2 min\n",
            "138135: done 871 games, reward 247.520, eps 0.01, speed 125.37 f/s, time 19.2 min\n",
            "138274: done 872 games, reward 245.760, eps 0.01, speed 129.51 f/s, time 19.2 min\n",
            "138506: done 873 games, reward 247.960, eps 0.01, speed 121.11 f/s, time 19.3 min\n",
            "138698: done 874 games, reward 249.280, eps 0.01, speed 96.36 f/s, time 19.3 min\n",
            "138854: done 875 games, reward 244.880, eps 0.01, speed 113.42 f/s, time 19.3 min\n",
            "139054: done 876 games, reward 233.120, eps 0.01, speed 129.82 f/s, time 19.3 min\n",
            "139139: done 877 games, reward 233.400, eps 0.01, speed 132.05 f/s, time 19.3 min\n",
            "140061: done 878 games, reward 238.920, eps 0.01, speed 128.70 f/s, time 19.5 min\n",
            "140136: done 879 games, reward 236.320, eps 0.01, speed 97.38 f/s, time 19.5 min\n",
            "140284: done 880 games, reward 237.200, eps 0.01, speed 96.37 f/s, time 19.5 min\n",
            "140389: done 881 games, reward 236.760, eps 0.01, speed 107.08 f/s, time 19.5 min\n",
            "140647: done 882 games, reward 235.440, eps 0.01, speed 130.68 f/s, time 19.6 min\n",
            "140863: done 883 games, reward 238.080, eps 0.01, speed 127.40 f/s, time 19.6 min\n",
            "141148: done 884 games, reward 238.080, eps 0.01, speed 130.80 f/s, time 19.6 min\n",
            "141209: done 885 games, reward 236.320, eps 0.01, speed 130.84 f/s, time 19.6 min\n",
            "141737: done 886 games, reward 242.040, eps 0.01, speed 121.25 f/s, time 19.7 min\n",
            "141799: done 887 games, reward 236.760, eps 0.01, speed 94.79 f/s, time 19.7 min\n",
            "141908: done 888 games, reward 238.240, eps 0.01, speed 90.81 f/s, time 19.7 min\n",
            "142006: done 889 games, reward 238.680, eps 0.01, speed 125.46 f/s, time 19.7 min\n",
            "142114: done 890 games, reward 236.480, eps 0.01, speed 127.16 f/s, time 19.8 min\n",
            "142326: done 891 games, reward 235.600, eps 0.01, speed 129.97 f/s, time 19.8 min\n",
            "142675: done 892 games, reward 240.400, eps 0.01, speed 129.42 f/s, time 19.8 min\n",
            "142787: done 893 games, reward 240.400, eps 0.01, speed 128.51 f/s, time 19.8 min\n",
            "143149: done 894 games, reward 244.760, eps 0.01, speed 130.15 f/s, time 19.9 min\n",
            "143523: done 895 games, reward 249.600, eps 0.01, speed 101.13 f/s, time 19.9 min\n",
            "143766: done 896 games, reward 248.840, eps 0.01, speed 128.12 f/s, time 20.0 min\n",
            "144003: done 897 games, reward 252.240, eps 0.01, speed 129.19 f/s, time 20.0 min\n",
            "144609: done 898 games, reward 255.320, eps 0.01, speed 130.03 f/s, time 20.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_255-20251201-0149-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_255-20251201-0149-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 254.480 -> 255.320\n",
            "144716: done 899 games, reward 250.480, eps 0.01, speed 123.57 f/s, time 20.1 min\n",
            "144929: done 900 games, reward 251.960, eps 0.01, speed 102.94 f/s, time 20.1 min\n",
            "145127: done 901 games, reward 254.600, eps 0.01, speed 102.12 f/s, time 20.2 min\n",
            "145653: done 902 games, reward 258.280, eps 0.01, speed 131.08 f/s, time 20.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_258-20251201-0149-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_258-20251201-0149-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 255.320 -> 258.280\n",
            "145781: done 903 games, reward 255.760, eps 0.01, speed 126.30 f/s, time 20.3 min\n",
            "145936: done 904 games, reward 258.400, eps 0.01, speed 129.14 f/s, time 20.3 min\n",
            "145987: done 905 games, reward 254.000, eps 0.01, speed 131.82 f/s, time 20.3 min\n",
            "146589: done 906 games, reward 255.800, eps 0.01, speed 116.21 f/s, time 20.4 min\n",
            "147615: done 907 games, reward 264.800, eps 0.01, speed 126.30 f/s, time 20.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_264-20251201-0149-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_264-20251201-0149-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 258.280 -> 264.800\n",
            "147714: done 908 games, reward 258.680, eps 0.01, speed 119.63 f/s, time 20.5 min\n",
            "148076: done 909 games, reward 265.760, eps 0.01, speed 114.63 f/s, time 20.6 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_265-20251201-0149-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_265-20251201-0149-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 264.800 -> 265.760\n",
            "148541: done 910 games, reward 266.640, eps 0.01, speed 113.59 f/s, time 20.6 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_266-20251201-0149-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_266-20251201-0149-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 265.760 -> 266.640\n",
            "148740: done 911 games, reward 264.880, eps 0.01, speed 129.11 f/s, time 20.7 min\n",
            "149019: done 912 games, reward 265.440, eps 0.01, speed 128.40 f/s, time 20.7 min\n",
            "149307: done 913 games, reward 268.960, eps 0.01, speed 130.76 f/s, time 20.7 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_268-20251201-0149-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_268-20251201-0149-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 266.640 -> 268.960\n",
            "149500: done 914 games, reward 266.760, eps 0.01, speed 123.56 f/s, time 20.8 min\n",
            "149649: done 915 games, reward 266.360, eps 0.01, speed 96.41 f/s, time 20.8 min\n",
            "149816: done 916 games, reward 265.480, eps 0.01, speed 95.68 f/s, time 20.8 min\n",
            "150038: done 917 games, reward 262.400, eps 0.01, speed 128.12 f/s, time 20.8 min\n",
            "150736: done 918 games, reward 267.560, eps 0.01, speed 130.69 f/s, time 20.9 min\n",
            "151059: done 919 games, reward 271.480, eps 0.01, speed 130.02 f/s, time 21.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_271-20251201-0150-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_271-20251201-0150-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 268.960 -> 271.480\n",
            "151516: done 920 games, reward 269.360, eps 0.01, speed 104.88 f/s, time 21.0 min\n",
            "151647: done 921 games, reward 270.920, eps 0.01, speed 127.60 f/s, time 21.1 min\n",
            "152303: done 922 games, reward 275.640, eps 0.01, speed 128.46 f/s, time 21.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_275-20251201-0150-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_275-20251201-0150-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 271.480 -> 275.640\n",
            "152805: done 923 games, reward 279.120, eps 0.01, speed 116.97 f/s, time 21.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_279-20251201-0150-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_279-20251201-0150-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 275.640 -> 279.120\n",
            "152857: done 924 games, reward 277.400, eps 0.01, speed 87.08 f/s, time 21.2 min\n",
            "153126: done 925 games, reward 279.160, eps 0.01, speed 113.65 f/s, time 21.3 min\n",
            "153854: done 926 games, reward 279.080, eps 0.01, speed 129.18 f/s, time 21.4 min\n",
            "153909: done 927 games, reward 277.640, eps 0.01, speed 129.85 f/s, time 21.4 min\n",
            "154114: done 928 games, reward 278.240, eps 0.01, speed 129.25 f/s, time 21.4 min\n",
            "154577: done 929 games, reward 278.680, eps 0.01, speed 105.80 f/s, time 21.5 min\n",
            "154823: done 930 games, reward 277.560, eps 0.01, speed 129.53 f/s, time 21.5 min\n",
            "155370: done 931 games, reward 283.720, eps 0.01, speed 130.58 f/s, time 21.6 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_283-20251201-0150-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_283-20251201-0150-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 279.120 -> 283.720\n",
            "155644: done 932 games, reward 283.360, eps 0.01, speed 124.73 f/s, time 21.6 min\n",
            "155793: done 933 games, reward 283.840, eps 0.01, speed 128.08 f/s, time 21.6 min\n",
            "156142: done 934 games, reward 290.440, eps 0.01, speed 99.64 f/s, time 21.7 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_290-20251201-0150-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_290-20251201-0150-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 283.720 -> 290.440\n",
            "156215: done 935 games, reward 288.360, eps 0.01, speed 119.24 f/s, time 21.7 min\n",
            "156343: done 936 games, reward 287.160, eps 0.01, speed 125.58 f/s, time 21.7 min\n",
            "156508: done 937 games, reward 289.800, eps 0.01, speed 127.53 f/s, time 21.7 min\n",
            "156983: done 938 games, reward 288.040, eps 0.01, speed 127.62 f/s, time 21.8 min\n",
            "157127: done 939 games, reward 288.080, eps 0.01, speed 126.36 f/s, time 21.8 min\n",
            "157432: done 940 games, reward 293.800, eps 0.01, speed 115.73 f/s, time 21.9 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_293-20251201-0151-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_293-20251201-0151-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 290.440 -> 293.800\n",
            "158118: done 941 games, reward 293.320, eps 0.01, speed 113.27 f/s, time 22.0 min\n",
            "158420: done 942 games, reward 299.520, eps 0.01, speed 130.56 f/s, time 22.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_299-20251201-0151-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_299-20251201-0151-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 293.800 -> 299.520\n",
            "158826: done 943 games, reward 305.200, eps 0.01, speed 127.81 f/s, time 22.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_305-20251201-0151-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_305-20251201-0151-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 299.520 -> 305.200\n",
            "159172: done 944 games, reward 302.560, eps 0.01, speed 101.77 f/s, time 22.1 min\n",
            "159229: done 945 games, reward 297.120, eps 0.01, speed 89.46 f/s, time 22.1 min\n",
            "159421: done 946 games, reward 299.280, eps 0.01, speed 130.24 f/s, time 22.1 min\n",
            "159759: done 947 games, reward 301.920, eps 0.01, speed 131.78 f/s, time 22.2 min\n",
            "159861: done 948 games, reward 297.080, eps 0.01, speed 127.66 f/s, time 22.2 min\n",
            "159958: done 949 games, reward 297.960, eps 0.01, speed 133.41 f/s, time 22.2 min\n",
            "160401: done 950 games, reward 301.480, eps 0.01, speed 131.59 f/s, time 22.3 min\n",
            "160489: done 951 games, reward 301.520, eps 0.01, speed 132.47 f/s, time 22.3 min\n",
            "160654: done 952 games, reward 302.400, eps 0.01, speed 101.27 f/s, time 22.3 min\n",
            "160762: done 953 games, reward 298.440, eps 0.01, speed 95.85 f/s, time 22.3 min\n",
            "161188: done 954 games, reward 302.080, eps 0.01, speed 124.51 f/s, time 22.4 min\n",
            "161363: done 955 games, reward 302.760, eps 0.01, speed 127.95 f/s, time 22.4 min\n",
            "161453: done 956 games, reward 297.480, eps 0.01, speed 130.93 f/s, time 22.4 min\n",
            "161782: done 957 games, reward 298.720, eps 0.01, speed 131.59 f/s, time 22.5 min\n",
            "161872: done 958 games, reward 299.040, eps 0.01, speed 131.42 f/s, time 22.5 min\n",
            "161991: done 959 games, reward 293.320, eps 0.01, speed 130.66 f/s, time 22.5 min\n",
            "162445: done 960 games, reward 297.280, eps 0.01, speed 106.12 f/s, time 22.6 min\n",
            "162653: done 961 games, reward 299.920, eps 0.01, speed 126.63 f/s, time 22.6 min\n",
            "163536: done 962 games, reward 301.720, eps 0.01, speed 132.02 f/s, time 22.7 min\n",
            "163615: done 963 games, reward 300.440, eps 0.01, speed 127.38 f/s, time 22.7 min\n",
            "164137: done 964 games, reward 305.720, eps 0.01, speed 106.81 f/s, time 22.8 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_305-20251201-0151-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_305-20251201-0151-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 305.200 -> 305.720\n",
            "164371: done 965 games, reward 303.960, eps 0.01, speed 125.80 f/s, time 22.8 min\n",
            "164471: done 966 games, reward 300.960, eps 0.01, speed 128.14 f/s, time 22.8 min\n",
            "164718: done 967 games, reward 302.640, eps 0.01, speed 129.24 f/s, time 22.9 min\n",
            "164856: done 968 games, reward 302.200, eps 0.01, speed 130.19 f/s, time 22.9 min\n",
            "164975: done 969 games, reward 303.080, eps 0.01, speed 127.84 f/s, time 22.9 min\n",
            "165666: done 970 games, reward 312.680, eps 0.01, speed 111.58 f/s, time 23.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_312-20251201-0152-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_312-20251201-0152-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 305.720 -> 312.680\n",
            "165727: done 971 games, reward 310.920, eps 0.01, speed 121.45 f/s, time 23.0 min\n",
            "165864: done 972 games, reward 311.560, eps 0.01, speed 116.12 f/s, time 23.0 min\n",
            "166143: done 973 games, reward 314.200, eps 0.01, speed 96.42 f/s, time 23.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_314-20251201-0152-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_314-20251201-0152-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 312.680 -> 314.200\n",
            "166577: done 974 games, reward 318.640, eps 0.01, speed 126.70 f/s, time 23.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_318-20251201-0152-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_318-20251201-0152-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 314.200 -> 318.640\n",
            "166729: done 975 games, reward 317.880, eps 0.01, speed 122.80 f/s, time 23.2 min\n",
            "167432: done 976 games, reward 324.200, eps 0.01, speed 110.37 f/s, time 23.3 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_324-20251201-0152-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_324-20251201-0152-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 318.640 -> 324.200\n",
            "167553: done 977 games, reward 325.280, eps 0.01, speed 124.48 f/s, time 23.3 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_325-20251201-0152-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_325-20251201-0152-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 324.200 -> 325.280\n",
            "167642: done 978 games, reward 318.080, eps 0.01, speed 121.32 f/s, time 23.3 min\n",
            "168029: done 979 games, reward 325.640, eps 0.01, speed 130.58 f/s, time 23.3 min\n",
            "168190: done 980 games, reward 325.320, eps 0.01, speed 129.61 f/s, time 23.4 min\n",
            "168275: done 981 games, reward 325.000, eps 0.01, speed 128.35 f/s, time 23.4 min\n",
            "168541: done 982 games, reward 323.680, eps 0.01, speed 93.72 f/s, time 23.4 min\n",
            "168830: done 983 games, reward 325.880, eps 0.01, speed 121.99 f/s, time 23.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_325-20251201-0152-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_325-20251201-0152-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 325.280 -> 325.880\n",
            "169269: done 984 games, reward 327.680, eps 0.01, speed 128.68 f/s, time 23.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_327-20251201-0152-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_327-20251201-0152-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 325.880 -> 327.680\n",
            "169702: done 985 games, reward 332.960, eps 0.01, speed 128.03 f/s, time 23.6 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_332-20251201-0152-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_332-20251201-0152-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 327.680 -> 332.960\n",
            "170090: done 986 games, reward 328.160, eps 0.01, speed 99.45 f/s, time 23.6 min\n",
            "170145: done 987 games, reward 329.120, eps 0.01, speed 101.17 f/s, time 23.6 min\n",
            "170316: done 988 games, reward 331.160, eps 0.01, speed 127.80 f/s, time 23.7 min\n",
            "170622: done 989 games, reward 332.480, eps 0.01, speed 128.29 f/s, time 23.7 min\n",
            "170749: done 990 games, reward 332.560, eps 0.01, speed 123.26 f/s, time 23.7 min\n",
            "171224: done 991 games, reward 334.760, eps 0.01, speed 127.73 f/s, time 23.8 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_334-20251201-0152-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_334-20251201-0152-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 332.960 -> 334.760\n",
            "171269: done 992 games, reward 329.480, eps 0.01, speed 118.70 f/s, time 23.8 min\n",
            "171411: done 993 games, reward 330.360, eps 0.01, speed 117.65 f/s, time 23.8 min\n",
            "171761: done 994 games, reward 331.280, eps 0.01, speed 99.08 f/s, time 23.9 min\n",
            "171891: done 995 games, reward 325.120, eps 0.01, speed 126.83 f/s, time 23.9 min\n",
            "172134: done 996 games, reward 325.600, eps 0.01, speed 126.04 f/s, time 23.9 min\n",
            "172480: done 997 games, reward 328.360, eps 0.01, speed 126.76 f/s, time 24.0 min\n",
            "172588: done 998 games, reward 323.160, eps 0.01, speed 124.20 f/s, time 24.0 min\n",
            "172643: done 999 games, reward 323.680, eps 0.01, speed 124.40 f/s, time 24.0 min\n",
            "172754: done 1000 games, reward 323.520, eps 0.01, speed 127.12 f/s, time 24.0 min\n",
            "173114: done 1001 games, reward 325.280, eps 0.01, speed 106.40 f/s, time 24.1 min\n",
            "173475: done 1002 games, reward 326.080, eps 0.01, speed 113.82 f/s, time 24.1 min\n",
            "173748: done 1003 games, reward 330.800, eps 0.01, speed 129.82 f/s, time 24.1 min\n",
            "174055: done 1004 games, reward 331.040, eps 0.01, speed 129.59 f/s, time 24.2 min\n",
            "174126: done 1005 games, reward 331.560, eps 0.01, speed 131.33 f/s, time 24.2 min\n",
            "174806: done 1006 games, reward 338.440, eps 0.01, speed 112.03 f/s, time 24.3 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_338-20251201-0153-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_338-20251201-0153-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 334.760 -> 338.440\n",
            "174899: done 1007 games, reward 329.440, eps 0.01, speed 120.47 f/s, time 24.3 min\n",
            "174955: done 1008 games, reward 328.960, eps 0.01, speed 127.72 f/s, time 24.3 min\n",
            "175406: done 1009 games, reward 328.000, eps 0.01, speed 130.00 f/s, time 24.4 min\n",
            "175445: done 1010 games, reward 321.840, eps 0.01, speed 129.98 f/s, time 24.4 min\n",
            "175541: done 1011 games, reward 323.760, eps 0.01, speed 126.70 f/s, time 24.4 min\n",
            "176143: done 1012 games, reward 333.280, eps 0.01, speed 123.72 f/s, time 24.5 min\n",
            "176237: done 1013 games, reward 329.000, eps 0.01, speed 93.68 f/s, time 24.5 min\n",
            "176527: done 1014 games, reward 329.080, eps 0.01, speed 111.85 f/s, time 24.5 min\n",
            "176700: done 1015 games, reward 332.120, eps 0.01, speed 130.94 f/s, time 24.6 min\n",
            "176862: done 1016 games, reward 332.120, eps 0.01, speed 130.81 f/s, time 24.6 min\n",
            "177131: done 1017 games, reward 332.800, eps 0.01, speed 129.02 f/s, time 24.6 min\n",
            "177491: done 1018 games, reward 330.600, eps 0.01, speed 130.43 f/s, time 24.7 min\n",
            "177634: done 1019 games, reward 328.400, eps 0.01, speed 130.14 f/s, time 24.7 min\n",
            "177794: done 1020 games, reward 328.600, eps 0.01, speed 98.82 f/s, time 24.7 min\n",
            "177924: done 1021 games, reward 328.360, eps 0.01, speed 94.43 f/s, time 24.7 min\n",
            "178382: done 1022 games, reward 331.920, eps 0.01, speed 126.94 f/s, time 24.8 min\n",
            "178467: done 1023 games, reward 328.120, eps 0.01, speed 128.43 f/s, time 24.8 min\n",
            "178977: done 1024 games, reward 334.240, eps 0.01, speed 130.92 f/s, time 24.9 min\n",
            "179112: done 1025 games, reward 330.320, eps 0.01, speed 130.66 f/s, time 24.9 min\n",
            "179295: done 1026 games, reward 327.640, eps 0.01, speed 116.46 f/s, time 24.9 min\n",
            "179433: done 1027 games, reward 331.160, eps 0.01, speed 95.21 f/s, time 24.9 min\n",
            "179739: done 1028 games, reward 330.280, eps 0.01, speed 115.27 f/s, time 25.0 min\n",
            "179824: done 1029 games, reward 328.600, eps 0.01, speed 127.35 f/s, time 25.0 min\n",
            "180382: done 1030 games, reward 332.800, eps 0.01, speed 131.07 f/s, time 25.1 min\n",
            "180423: done 1031 games, reward 326.200, eps 0.01, speed 131.86 f/s, time 25.1 min\n",
            "180554: done 1032 games, reward 320.920, eps 0.01, speed 127.92 f/s, time 25.1 min\n",
            "180696: done 1033 games, reward 323.520, eps 0.01, speed 126.91 f/s, time 25.1 min\n",
            "180745: done 1034 games, reward 315.960, eps 0.01, speed 124.95 f/s, time 25.1 min\n",
            "180880: done 1035 games, reward 317.160, eps 0.01, speed 109.86 f/s, time 25.1 min\n",
            "181233: done 1036 games, reward 323.280, eps 0.01, speed 105.21 f/s, time 25.2 min\n",
            "181406: done 1037 games, reward 323.520, eps 0.01, speed 129.55 f/s, time 25.2 min\n",
            "181489: done 1038 games, reward 320.040, eps 0.01, speed 129.39 f/s, time 25.2 min\n",
            "181956: done 1039 games, reward 329.520, eps 0.01, speed 130.99 f/s, time 25.3 min\n",
            "182021: done 1040 games, reward 323.360, eps 0.01, speed 128.49 f/s, time 25.3 min\n",
            "182099: done 1041 games, reward 318.600, eps 0.01, speed 129.52 f/s, time 25.3 min\n",
            "182501: done 1042 games, reward 318.120, eps 0.01, speed 118.79 f/s, time 25.3 min\n",
            "182698: done 1043 games, reward 317.720, eps 0.01, speed 96.15 f/s, time 25.4 min\n",
            "182745: done 1044 games, reward 317.760, eps 0.01, speed 122.50 f/s, time 25.4 min\n",
            "183235: done 1045 games, reward 322.920, eps 0.01, speed 129.58 f/s, time 25.4 min\n",
            "183491: done 1046 games, reward 326.040, eps 0.01, speed 128.78 f/s, time 25.5 min\n",
            "183769: done 1047 games, reward 326.640, eps 0.01, speed 131.51 f/s, time 25.5 min\n",
            "184255: done 1048 games, reward 334.680, eps 0.01, speed 108.38 f/s, time 25.6 min\n",
            "184401: done 1049 games, reward 335.760, eps 0.01, speed 119.74 f/s, time 25.6 min\n",
            "184762: done 1050 games, reward 339.560, eps 0.01, speed 131.30 f/s, time 25.7 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_339-20251201-0154-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_339-20251201-0154-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 338.440 -> 339.560\n",
            "184909: done 1051 games, reward 341.280, eps 0.01, speed 126.75 f/s, time 25.7 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_341-20251201-0154-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_341-20251201-0154-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 339.560 -> 341.280\n",
            "185397: done 1052 games, reward 344.880, eps 0.01, speed 130.68 f/s, time 25.7 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_344-20251201-0154-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_344-20251201-0154-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 341.280 -> 344.880\n",
            "185576: done 1053 games, reward 345.480, eps 0.01, speed 116.17 f/s, time 25.8 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_345-20251201-0154-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_345-20251201-0154-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 344.880 -> 345.480\n",
            "185838: done 1054 games, reward 344.920, eps 0.01, speed 94.11 f/s, time 25.8 min\n",
            "186256: done 1055 games, reward 348.360, eps 0.01, speed 125.86 f/s, time 25.9 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_348-20251201-0155-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_348-20251201-0155-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 345.480 -> 348.360\n",
            "186559: done 1056 games, reward 349.440, eps 0.01, speed 129.11 f/s, time 25.9 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_349-20251201-0155-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_349-20251201-0155-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 348.360 -> 349.440\n",
            "186865: done 1057 games, reward 352.080, eps 0.01, speed 127.96 f/s, time 25.9 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_352-20251201-0155-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_352-20251201-0155-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 349.440 -> 352.080\n",
            "187600: done 1058 games, reward 358.800, eps 0.01, speed 111.49 f/s, time 26.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_358-20251201-0155-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_358-20251201-0155-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 352.080 -> 358.800\n",
            "187651: done 1059 games, reward 358.400, eps 0.01, speed 115.44 f/s, time 26.1 min\n",
            "187910: done 1060 games, reward 356.520, eps 0.01, speed 128.32 f/s, time 26.1 min\n",
            "188390: done 1061 games, reward 358.880, eps 0.01, speed 130.19 f/s, time 26.2 min\n",
            "188547: done 1062 games, reward 358.760, eps 0.01, speed 126.29 f/s, time 26.2 min\n",
            "188934: done 1063 games, reward 364.440, eps 0.01, speed 104.45 f/s, time 26.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_364-20251201-0155-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_364-20251201-0155-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 358.800 -> 364.440\n",
            "189036: done 1064 games, reward 359.160, eps 0.01, speed 111.15 f/s, time 26.3 min\n",
            "189229: done 1065 games, reward 362.120, eps 0.01, speed 129.96 f/s, time 26.3 min\n",
            "190338: done 1066 games, reward 369.680, eps 0.01, speed 126.34 f/s, time 26.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_369-20251201-0155-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_369-20251201-0155-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 364.440 -> 369.680\n",
            "190450: done 1067 games, reward 368.480, eps 0.01, speed 92.48 f/s, time 26.4 min\n",
            "190551: done 1068 games, reward 366.760, eps 0.01, speed 96.03 f/s, time 26.5 min\n",
            "191149: done 1069 games, reward 372.040, eps 0.01, speed 131.59 f/s, time 26.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_372-20251201-0155-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_372-20251201-0155-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 369.680 -> 372.040\n",
            "191300: done 1070 games, reward 363.520, eps 0.01, speed 126.39 f/s, time 26.6 min\n",
            "191706: done 1071 games, reward 368.320, eps 0.01, speed 126.39 f/s, time 26.6 min\n",
            "192217: done 1072 games, reward 372.520, eps 0.01, speed 107.34 f/s, time 26.7 min\n",
            "192259: done 1073 games, reward 367.280, eps 0.01, speed 126.08 f/s, time 26.7 min\n",
            "192534: done 1074 games, reward 366.400, eps 0.01, speed 130.26 f/s, time 26.7 min\n",
            "192879: done 1075 games, reward 373.480, eps 0.01, speed 131.53 f/s, time 26.8 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_373-20251201-0155-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_373-20251201-0155-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 372.040 -> 373.480\n",
            "193044: done 1076 games, reward 365.440, eps 0.01, speed 125.82 f/s, time 26.8 min\n",
            "193095: done 1077 games, reward 363.520, eps 0.01, speed 126.79 f/s, time 26.8 min\n",
            "193363: done 1078 games, reward 367.840, eps 0.01, speed 128.22 f/s, time 26.8 min\n",
            "193590: done 1079 games, reward 360.680, eps 0.01, speed 97.17 f/s, time 26.9 min\n",
            "193951: done 1080 games, reward 364.000, eps 0.01, speed 114.30 f/s, time 26.9 min\n",
            "194409: done 1081 games, reward 369.640, eps 0.01, speed 125.91 f/s, time 27.0 min\n",
            "194476: done 1082 games, reward 369.320, eps 0.01, speed 124.39 f/s, time 27.0 min\n",
            "194607: done 1083 games, reward 365.440, eps 0.01, speed 127.55 f/s, time 27.0 min\n",
            "195276: done 1084 games, reward 368.200, eps 0.01, speed 106.91 f/s, time 27.1 min\n",
            "195452: done 1085 games, reward 366.280, eps 0.01, speed 124.91 f/s, time 27.1 min\n",
            "195505: done 1086 games, reward 365.440, eps 0.01, speed 122.98 f/s, time 27.2 min\n",
            "196077: done 1087 games, reward 375.400, eps 0.01, speed 128.08 f/s, time 27.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_375-20251201-0156-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_375-20251201-0156-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 373.480 -> 375.400\n",
            "196551: done 1088 games, reward 379.000, eps 0.01, speed 118.79 f/s, time 27.3 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_379-20251201-0156-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_379-20251201-0156-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 375.400 -> 379.000\n",
            "196663: done 1089 games, reward 378.440, eps 0.01, speed 87.67 f/s, time 27.3 min\n",
            "197026: done 1090 games, reward 383.640, eps 0.01, speed 89.06 f/s, time 27.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_383-20251201-0156-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_383-20251201-0156-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 379.000 -> 383.640\n",
            "197367: done 1091 games, reward 383.560, eps 0.01, speed 121.38 f/s, time 27.4 min\n",
            "197420: done 1092 games, reward 384.040, eps 0.01, speed 121.50 f/s, time 27.4 min\n",
            "197967: done 1093 games, reward 393.200, eps 0.01, speed 119.99 f/s, time 27.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_393-20251201-0156-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_393-20251201-0156-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 383.640 -> 393.200\n",
            "198131: done 1094 games, reward 389.440, eps 0.01, speed 88.52 f/s, time 27.5 min\n",
            "198296: done 1095 games, reward 390.000, eps 0.01, speed 117.86 f/s, time 27.6 min\n",
            "198704: done 1096 games, reward 394.680, eps 0.01, speed 126.10 f/s, time 27.6 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_394-20251201-0156-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_394-20251201-0156-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 393.200 -> 394.680\n",
            "198832: done 1097 games, reward 390.000, eps 0.01, speed 122.36 f/s, time 27.6 min\n",
            "199073: done 1098 games, reward 394.320, eps 0.01, speed 128.57 f/s, time 27.7 min\n",
            "199440: done 1099 games, reward 398.200, eps 0.01, speed 121.01 f/s, time 27.7 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_398-20251201-0156-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_398-20251201-0156-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 394.680 -> 398.200\n",
            "199940: done 1100 games, reward 403.960, eps 0.01, speed 104.04 f/s, time 27.8 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_403-20251201-0156-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_403-20251201-0156-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 398.200 -> 403.960\n",
            "200063: done 1101 games, reward 400.560, eps 0.01, speed 121.62 f/s, time 27.8 min\n",
            "200731: done 1102 games, reward 405.240, eps 0.01, speed 126.70 f/s, time 27.9 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_405-20251201-0157-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_405-20251201-0157-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 403.960 -> 405.240\n",
            "201042: done 1103 games, reward 406.640, eps 0.01, speed 110.00 f/s, time 28.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_406-20251201-0157-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_406-20251201-0157-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 405.240 -> 406.640\n",
            "201155: done 1104 games, reward 405.400, eps 0.01, speed 87.14 f/s, time 28.0 min\n",
            "201410: done 1105 games, reward 407.960, eps 0.01, speed 113.13 f/s, time 28.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_407-20251201-0157-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_407-20251201-0157-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 406.640 -> 407.960\n",
            "201478: done 1106 games, reward 397.520, eps 0.01, speed 113.75 f/s, time 28.0 min\n",
            "201546: done 1107 games, reward 397.400, eps 0.01, speed 124.69 f/s, time 28.0 min\n",
            "202044: done 1108 games, reward 407.840, eps 0.01, speed 126.31 f/s, time 28.1 min\n",
            "202107: done 1109 games, reward 401.720, eps 0.01, speed 116.96 f/s, time 28.1 min\n",
            "202411: done 1110 games, reward 404.600, eps 0.01, speed 127.21 f/s, time 28.1 min\n",
            "202800: done 1111 games, reward 409.280, eps 0.01, speed 100.01 f/s, time 28.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_409-20251201-0157-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_409-20251201-0157-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 407.960 -> 409.280\n",
            "202943: done 1112 games, reward 399.800, eps 0.01, speed 121.85 f/s, time 28.2 min\n",
            "203192: done 1113 games, reward 403.640, eps 0.01, speed 126.33 f/s, time 28.3 min\n",
            "203655: done 1114 games, reward 410.720, eps 0.01, speed 127.63 f/s, time 28.3 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_410-20251201-0157-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_410-20251201-0157-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 409.280 -> 410.720\n",
            "203904: done 1115 games, reward 412.480, eps 0.01, speed 122.19 f/s, time 28.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_412-20251201-0157-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_412-20251201-0157-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 410.720 -> 412.480\n",
            "203955: done 1116 games, reward 410.720, eps 0.01, speed 114.74 f/s, time 28.4 min\n",
            "204083: done 1117 games, reward 408.720, eps 0.01, speed 99.27 f/s, time 28.4 min\n",
            "204148: done 1118 games, reward 404.760, eps 0.01, speed 89.48 f/s, time 28.4 min\n",
            "204285: done 1119 games, reward 406.520, eps 0.01, speed 94.59 f/s, time 28.4 min\n",
            "204913: done 1120 games, reward 413.600, eps 0.01, speed 125.71 f/s, time 28.5 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_413-20251201-0157-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_413-20251201-0157-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 412.480 -> 413.600\n",
            "204996: done 1121 games, reward 411.920, eps 0.01, speed 121.56 f/s, time 28.5 min\n",
            "205127: done 1122 games, reward 404.600, eps 0.01, speed 128.54 f/s, time 28.5 min\n",
            "205454: done 1123 games, reward 409.760, eps 0.01, speed 128.23 f/s, time 28.6 min\n",
            "205630: done 1124 games, reward 407.960, eps 0.01, speed 104.24 f/s, time 28.6 min\n",
            "205701: done 1125 games, reward 408.920, eps 0.01, speed 86.93 f/s, time 28.6 min\n",
            "205818: done 1126 games, reward 407.280, eps 0.01, speed 90.86 f/s, time 28.6 min\n",
            "206064: done 1127 games, reward 407.720, eps 0.01, speed 126.82 f/s, time 28.7 min\n",
            "206121: done 1128 games, reward 405.080, eps 0.01, speed 121.92 f/s, time 28.7 min\n",
            "206279: done 1129 games, reward 406.760, eps 0.01, speed 127.00 f/s, time 28.7 min\n",
            "206650: done 1130 games, reward 404.120, eps 0.01, speed 128.29 f/s, time 28.7 min\n",
            "206729: done 1131 games, reward 405.080, eps 0.01, speed 125.51 f/s, time 28.8 min\n",
            "206922: done 1132 games, reward 407.200, eps 0.01, speed 125.52 f/s, time 28.8 min\n",
            "207232: done 1133 games, reward 409.080, eps 0.01, speed 107.74 f/s, time 28.8 min\n",
            "207475: done 1134 games, reward 411.960, eps 0.01, speed 103.99 f/s, time 28.9 min\n",
            "207848: done 1135 games, reward 413.720, eps 0.01, speed 128.32 f/s, time 28.9 min\n",
            "208052: done 1136 games, reward 408.360, eps 0.01, speed 127.97 f/s, time 28.9 min\n",
            "208474: done 1137 games, reward 412.680, eps 0.01, speed 128.93 f/s, time 29.0 min\n",
            "208643: done 1138 games, reward 415.280, eps 0.01, speed 123.42 f/s, time 29.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_415-20251201-0158-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_415-20251201-0158-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 413.600 -> 415.280\n",
            "208946: done 1139 games, reward 408.840, eps 0.01, speed 94.51 f/s, time 29.1 min\n",
            "209175: done 1140 games, reward 411.720, eps 0.01, speed 125.48 f/s, time 29.1 min\n",
            "209361: done 1141 games, reward 414.320, eps 0.01, speed 127.49 f/s, time 29.1 min\n",
            "209650: done 1142 games, reward 411.240, eps 0.01, speed 130.94 f/s, time 29.2 min\n",
            "209763: done 1143 games, reward 407.400, eps 0.01, speed 127.27 f/s, time 29.2 min\n",
            "210009: done 1144 games, reward 411.320, eps 0.01, speed 127.34 f/s, time 29.2 min\n",
            "210182: done 1145 games, reward 406.920, eps 0.01, speed 125.86 f/s, time 29.2 min\n",
            "210270: done 1146 games, reward 401.160, eps 0.01, speed 94.58 f/s, time 29.3 min\n",
            "210583: done 1147 games, reward 402.320, eps 0.01, speed 103.28 f/s, time 29.3 min\n",
            "210814: done 1148 games, reward 395.160, eps 0.01, speed 129.40 f/s, time 29.3 min\n",
            "210950: done 1149 games, reward 393.240, eps 0.01, speed 128.84 f/s, time 29.4 min\n",
            "211749: done 1150 games, reward 397.960, eps 0.01, speed 128.85 f/s, time 29.5 min\n",
            "211789: done 1151 games, reward 395.760, eps 0.01, speed 91.84 f/s, time 29.5 min\n",
            "211998: done 1152 games, reward 397.680, eps 0.01, speed 92.52 f/s, time 29.5 min\n",
            "212345: done 1153 games, reward 401.040, eps 0.01, speed 123.81 f/s, time 29.5 min\n",
            "212771: done 1154 games, reward 400.840, eps 0.01, speed 128.78 f/s, time 29.6 min\n",
            "212857: done 1155 games, reward 396.240, eps 0.01, speed 120.86 f/s, time 29.6 min\n",
            "213319: done 1156 games, reward 400.440, eps 0.01, speed 123.72 f/s, time 29.7 min\n",
            "213421: done 1157 games, reward 397.040, eps 0.01, speed 92.85 f/s, time 29.7 min\n",
            "213616: done 1158 games, reward 393.840, eps 0.01, speed 96.92 f/s, time 29.7 min\n",
            "214174: done 1159 games, reward 401.400, eps 0.01, speed 127.50 f/s, time 29.8 min\n",
            "214231: done 1160 games, reward 399.320, eps 0.01, speed 128.65 f/s, time 29.8 min\n",
            "214306: done 1161 games, reward 395.280, eps 0.01, speed 126.09 f/s, time 29.8 min\n",
            "214489: done 1162 games, reward 393.600, eps 0.01, speed 127.15 f/s, time 29.8 min\n",
            "214982: done 1163 games, reward 392.360, eps 0.01, speed 116.99 f/s, time 29.9 min\n",
            "215106: done 1164 games, reward 392.400, eps 0.01, speed 92.23 f/s, time 29.9 min\n",
            "215435: done 1165 games, reward 395.160, eps 0.01, speed 122.96 f/s, time 30.0 min\n",
            "215583: done 1166 games, reward 387.120, eps 0.01, speed 127.98 f/s, time 30.0 min\n",
            "215707: done 1167 games, reward 387.120, eps 0.01, speed 128.31 f/s, time 30.0 min\n",
            "215804: done 1168 games, reward 387.520, eps 0.01, speed 127.47 f/s, time 30.0 min\n",
            "215897: done 1169 games, reward 381.800, eps 0.01, speed 130.28 f/s, time 30.0 min\n",
            "215951: done 1170 games, reward 379.400, eps 0.01, speed 126.81 f/s, time 30.0 min\n",
            "216358: done 1171 games, reward 381.200, eps 0.01, speed 128.33 f/s, time 30.1 min\n",
            "216487: done 1172 games, reward 377.000, eps 0.01, speed 101.47 f/s, time 30.1 min\n",
            "216696: done 1173 games, reward 380.840, eps 0.01, speed 92.31 f/s, time 30.2 min\n",
            "216989: done 1174 games, reward 381.240, eps 0.01, speed 128.66 f/s, time 30.2 min\n",
            "217412: done 1175 games, reward 377.480, eps 0.01, speed 129.42 f/s, time 30.3 min\n",
            "217510: done 1176 games, reward 377.480, eps 0.01, speed 128.77 f/s, time 30.3 min\n",
            "217702: done 1177 games, reward 380.520, eps 0.01, speed 128.80 f/s, time 30.3 min\n",
            "218001: done 1178 games, reward 378.320, eps 0.01, speed 125.69 f/s, time 30.3 min\n",
            "218150: done 1179 games, reward 380.800, eps 0.01, speed 94.26 f/s, time 30.4 min\n",
            "218375: done 1180 games, reward 381.320, eps 0.01, speed 105.73 f/s, time 30.4 min\n",
            "218490: done 1181 games, reward 375.120, eps 0.01, speed 129.13 f/s, time 30.4 min\n",
            "219033: done 1182 games, reward 384.960, eps 0.01, speed 129.48 f/s, time 30.5 min\n",
            "219068: done 1183 games, reward 384.000, eps 0.01, speed 122.56 f/s, time 30.5 min\n",
            "219507: done 1184 games, reward 383.040, eps 0.01, speed 130.72 f/s, time 30.5 min\n",
            "219698: done 1185 games, reward 383.040, eps 0.01, speed 99.58 f/s, time 30.6 min\n",
            "219948: done 1186 games, reward 384.960, eps 0.01, speed 105.82 f/s, time 30.6 min\n",
            "220169: done 1187 games, reward 378.000, eps 0.01, speed 125.66 f/s, time 30.6 min\n",
            "220399: done 1188 games, reward 374.520, eps 0.01, speed 130.89 f/s, time 30.7 min\n",
            "220724: done 1189 games, reward 378.200, eps 0.01, speed 129.87 f/s, time 30.7 min\n",
            "220986: done 1190 games, reward 377.760, eps 0.01, speed 129.72 f/s, time 30.7 min\n",
            "221067: done 1191 games, reward 373.880, eps 0.01, speed 130.10 f/s, time 30.8 min\n",
            "221159: done 1192 games, reward 374.360, eps 0.01, speed 105.69 f/s, time 30.8 min\n",
            "221604: done 1193 games, reward 371.480, eps 0.01, speed 106.05 f/s, time 30.8 min\n",
            "221753: done 1194 games, reward 370.520, eps 0.01, speed 127.34 f/s, time 30.9 min\n",
            "221828: done 1195 games, reward 369.520, eps 0.01, speed 126.77 f/s, time 30.9 min\n",
            "222108: done 1196 games, reward 366.440, eps 0.01, speed 130.01 f/s, time 30.9 min\n",
            "222230: done 1197 games, reward 367.160, eps 0.01, speed 129.59 f/s, time 30.9 min\n",
            "222290: done 1198 games, reward 362.320, eps 0.01, speed 132.20 f/s, time 30.9 min\n",
            "222989: done 1199 games, reward 368.880, eps 0.01, speed 113.90 f/s, time 31.0 min\n",
            "223121: done 1200 games, reward 363.280, eps 0.01, speed 127.09 f/s, time 31.0 min\n",
            "223312: done 1201 games, reward 362.840, eps 0.01, speed 129.90 f/s, time 31.1 min\n",
            "223546: done 1202 games, reward 357.200, eps 0.01, speed 131.40 f/s, time 31.1 min\n",
            "223692: done 1203 games, reward 350.960, eps 0.01, speed 129.80 f/s, time 31.1 min\n",
            "223837: done 1204 games, reward 350.800, eps 0.01, speed 126.44 f/s, time 31.1 min\n",
            "224212: done 1205 games, reward 353.880, eps 0.01, speed 131.21 f/s, time 31.2 min\n",
            "224670: done 1206 games, reward 361.080, eps 0.01, speed 105.69 f/s, time 31.3 min\n",
            "224838: done 1207 games, reward 362.880, eps 0.01, speed 128.84 f/s, time 31.3 min\n",
            "225001: done 1208 games, reward 356.400, eps 0.01, speed 130.44 f/s, time 31.3 min\n",
            "225278: done 1209 games, reward 360.000, eps 0.01, speed 130.91 f/s, time 31.3 min\n",
            "225427: done 1210 games, reward 360.000, eps 0.01, speed 130.41 f/s, time 31.4 min\n",
            "225571: done 1211 games, reward 356.480, eps 0.01, speed 130.41 f/s, time 31.4 min\n",
            "225814: done 1212 games, reward 357.200, eps 0.01, speed 130.91 f/s, time 31.4 min\n",
            "226231: done 1213 games, reward 355.680, eps 0.01, speed 104.26 f/s, time 31.5 min\n",
            "226578: done 1214 games, reward 353.800, eps 0.01, speed 131.75 f/s, time 31.5 min\n",
            "226775: done 1215 games, reward 350.880, eps 0.01, speed 131.41 f/s, time 31.5 min\n",
            "227307: done 1216 games, reward 361.880, eps 0.01, speed 131.68 f/s, time 31.6 min\n",
            "227709: done 1217 games, reward 366.280, eps 0.01, speed 106.79 f/s, time 31.7 min\n",
            "227959: done 1218 games, reward 370.640, eps 0.01, speed 101.95 f/s, time 31.7 min\n",
            "228044: done 1219 games, reward 367.640, eps 0.01, speed 96.06 f/s, time 31.7 min\n",
            "228462: done 1220 games, reward 363.800, eps 0.01, speed 118.72 f/s, time 31.8 min\n",
            "228508: done 1221 games, reward 362.840, eps 0.01, speed 131.68 f/s, time 31.8 min\n",
            "228612: done 1222 games, reward 362.360, eps 0.01, speed 128.91 f/s, time 31.8 min\n",
            "229227: done 1223 games, reward 366.200, eps 0.01, speed 111.09 f/s, time 31.9 min\n",
            "229264: done 1224 games, reward 361.400, eps 0.01, speed 123.33 f/s, time 31.9 min\n",
            "229420: done 1225 games, reward 362.360, eps 0.01, speed 128.64 f/s, time 31.9 min\n",
            "230095: done 1226 games, reward 370.600, eps 0.01, speed 130.68 f/s, time 32.0 min\n",
            "230262: done 1227 games, reward 370.000, eps 0.01, speed 127.02 f/s, time 32.0 min\n",
            "230318: done 1228 games, reward 369.560, eps 0.01, speed 127.83 f/s, time 32.0 min\n",
            "230783: done 1229 games, reward 373.080, eps 0.01, speed 106.40 f/s, time 32.1 min\n",
            "230886: done 1230 games, reward 369.560, eps 0.01, speed 119.88 f/s, time 32.1 min\n",
            "231183: done 1231 games, reward 373.400, eps 0.01, speed 128.63 f/s, time 32.2 min\n",
            "231590: done 1232 games, reward 375.160, eps 0.01, speed 130.41 f/s, time 32.2 min\n",
            "231825: done 1233 games, reward 372.920, eps 0.01, speed 128.81 f/s, time 32.2 min\n",
            "232022: done 1234 games, reward 375.800, eps 0.01, speed 130.75 f/s, time 32.3 min\n",
            "232126: done 1235 games, reward 372.720, eps 0.01, speed 113.31 f/s, time 32.3 min\n",
            "232454: done 1236 games, reward 374.920, eps 0.01, speed 101.26 f/s, time 32.3 min\n",
            "232633: done 1237 games, reward 370.040, eps 0.01, speed 131.07 f/s, time 32.4 min\n",
            "232720: done 1238 games, reward 368.720, eps 0.01, speed 131.83 f/s, time 32.4 min\n",
            "233787: done 1239 games, reward 382.440, eps 0.01, speed 127.24 f/s, time 32.5 min\n",
            "233979: done 1240 games, reward 382.160, eps 0.01, speed 94.96 f/s, time 32.5 min\n",
            "234491: done 1241 games, reward 386.160, eps 0.01, speed 129.74 f/s, time 32.6 min\n",
            "234553: done 1242 games, reward 383.120, eps 0.01, speed 126.24 f/s, time 32.6 min\n",
            "234610: done 1243 games, reward 381.680, eps 0.01, speed 122.92 f/s, time 32.6 min\n",
            "234982: done 1244 games, reward 386.280, eps 0.01, speed 130.17 f/s, time 32.7 min\n",
            "235022: done 1245 games, reward 384.080, eps 0.01, speed 130.67 f/s, time 32.7 min\n",
            "235277: done 1246 games, reward 388.400, eps 0.01, speed 127.57 f/s, time 32.7 min\n",
            "235709: done 1247 games, reward 390.240, eps 0.01, speed 105.07 f/s, time 32.8 min\n",
            "235764: done 1248 games, reward 389.840, eps 0.01, speed 130.93 f/s, time 32.8 min\n",
            "235940: done 1249 games, reward 393.200, eps 0.01, speed 129.88 f/s, time 32.8 min\n",
            "236373: done 1250 games, reward 386.000, eps 0.01, speed 131.06 f/s, time 32.9 min\n",
            "236506: done 1251 games, reward 387.440, eps 0.01, speed 130.10 f/s, time 32.9 min\n",
            "237145: done 1252 games, reward 390.600, eps 0.01, speed 112.36 f/s, time 33.0 min\n",
            "237235: done 1253 games, reward 387.520, eps 0.01, speed 126.40 f/s, time 33.0 min\n",
            "237566: done 1254 games, reward 387.720, eps 0.01, speed 131.40 f/s, time 33.0 min\n",
            "237692: done 1255 games, reward 387.240, eps 0.01, speed 129.43 f/s, time 33.0 min\n",
            "237803: done 1256 games, reward 383.520, eps 0.01, speed 130.00 f/s, time 33.1 min\n",
            "238100: done 1257 games, reward 387.800, eps 0.01, speed 129.13 f/s, time 33.1 min\n",
            "238317: done 1258 games, reward 384.360, eps 0.01, speed 128.58 f/s, time 33.1 min\n",
            "238412: done 1259 games, reward 376.800, eps 0.01, speed 127.44 f/s, time 33.1 min\n",
            "238562: done 1260 games, reward 378.440, eps 0.01, speed 99.85 f/s, time 33.2 min\n",
            "238884: done 1261 games, reward 381.960, eps 0.01, speed 109.93 f/s, time 33.2 min\n",
            "239181: done 1262 games, reward 383.160, eps 0.01, speed 131.49 f/s, time 33.3 min\n",
            "239854: done 1263 games, reward 386.280, eps 0.01, speed 131.15 f/s, time 33.3 min\n",
            "239972: done 1264 games, reward 387.240, eps 0.01, speed 130.08 f/s, time 33.4 min\n",
            "240187: done 1265 games, reward 385.480, eps 0.01, speed 104.51 f/s, time 33.4 min\n",
            "240315: done 1266 games, reward 387.160, eps 0.01, speed 94.86 f/s, time 33.4 min\n",
            "240613: done 1267 games, reward 389.680, eps 0.01, speed 130.41 f/s, time 33.4 min\n",
            "240795: done 1268 games, reward 391.680, eps 0.01, speed 130.96 f/s, time 33.5 min\n",
            "240923: done 1269 games, reward 393.000, eps 0.01, speed 131.62 f/s, time 33.5 min\n",
            "241121: done 1270 games, reward 397.400, eps 0.01, speed 132.51 f/s, time 33.5 min\n",
            "241361: done 1271 games, reward 394.160, eps 0.01, speed 130.23 f/s, time 33.5 min\n",
            "241671: done 1272 games, reward 395.720, eps 0.01, speed 123.78 f/s, time 33.6 min\n",
            "241942: done 1273 games, reward 394.520, eps 0.01, speed 97.07 f/s, time 33.6 min\n",
            "242090: done 1274 games, reward 389.800, eps 0.01, speed 128.69 f/s, time 33.6 min\n",
            "242184: done 1275 games, reward 386.360, eps 0.01, speed 129.71 f/s, time 33.7 min\n",
            "242238: done 1276 games, reward 386.320, eps 0.01, speed 132.34 f/s, time 33.7 min\n",
            "242442: done 1277 games, reward 386.760, eps 0.01, speed 127.96 f/s, time 33.7 min\n",
            "242576: done 1278 games, reward 385.000, eps 0.01, speed 130.49 f/s, time 33.7 min\n",
            "242786: done 1279 games, reward 386.040, eps 0.01, speed 131.32 f/s, time 33.7 min\n",
            "242980: done 1280 games, reward 382.120, eps 0.01, speed 130.25 f/s, time 33.8 min\n",
            "243727: done 1281 games, reward 393.120, eps 0.01, speed 113.77 f/s, time 33.9 min\n",
            "243767: done 1282 games, reward 381.840, eps 0.01, speed 131.61 f/s, time 33.9 min\n",
            "243821: done 1283 games, reward 382.320, eps 0.01, speed 126.73 f/s, time 33.9 min\n",
            "244421: done 1284 games, reward 382.320, eps 0.01, speed 131.61 f/s, time 34.0 min\n",
            "244492: done 1285 games, reward 379.440, eps 0.01, speed 129.18 f/s, time 34.0 min\n",
            "244615: done 1286 games, reward 378.960, eps 0.01, speed 130.97 f/s, time 34.0 min\n",
            "244785: done 1287 games, reward 378.080, eps 0.01, speed 130.15 f/s, time 34.0 min\n",
            "245049: done 1288 games, reward 377.520, eps 0.01, speed 97.25 f/s, time 34.1 min\n",
            "245131: done 1289 games, reward 372.240, eps 0.01, speed 109.19 f/s, time 34.1 min\n",
            "245438: done 1290 games, reward 372.240, eps 0.01, speed 130.29 f/s, time 34.1 min\n",
            "245540: done 1291 games, reward 372.240, eps 0.01, speed 130.77 f/s, time 34.1 min\n",
            "245794: done 1292 games, reward 374.640, eps 0.01, speed 128.81 f/s, time 34.2 min\n",
            "246216: done 1293 games, reward 373.200, eps 0.01, speed 131.08 f/s, time 34.2 min\n",
            "246729: done 1294 games, reward 379.480, eps 0.01, speed 107.24 f/s, time 34.3 min\n",
            "246829: done 1295 games, reward 382.080, eps 0.01, speed 128.79 f/s, time 34.3 min\n",
            "247342: done 1296 games, reward 388.040, eps 0.01, speed 130.89 f/s, time 34.4 min\n",
            "247651: done 1297 games, reward 389.720, eps 0.01, speed 128.64 f/s, time 34.4 min\n",
            "247933: done 1298 games, reward 393.440, eps 0.01, speed 131.26 f/s, time 34.4 min\n",
            "248107: done 1299 games, reward 383.360, eps 0.01, speed 100.94 f/s, time 34.5 min\n",
            "248162: done 1300 games, reward 381.880, eps 0.01, speed 97.14 f/s, time 34.5 min\n",
            "248325: done 1301 games, reward 383.520, eps 0.01, speed 106.60 f/s, time 34.5 min\n",
            "248817: done 1302 games, reward 383.960, eps 0.01, speed 130.88 f/s, time 34.6 min\n",
            "249177: done 1303 games, reward 384.480, eps 0.01, speed 131.28 f/s, time 34.6 min\n",
            "249481: done 1304 games, reward 390.360, eps 0.01, speed 129.10 f/s, time 34.6 min\n",
            "249887: done 1305 games, reward 390.360, eps 0.01, speed 103.85 f/s, time 34.7 min\n",
            "250149: done 1306 games, reward 390.360, eps 0.01, speed 129.29 f/s, time 34.7 min\n",
            "250409: done 1307 games, reward 391.400, eps 0.01, speed 128.92 f/s, time 34.8 min\n",
            "250573: done 1308 games, reward 390.080, eps 0.01, speed 129.61 f/s, time 34.8 min\n",
            "250793: done 1309 games, reward 388.640, eps 0.01, speed 130.62 f/s, time 34.8 min\n",
            "250902: done 1310 games, reward 386.640, eps 0.01, speed 128.71 f/s, time 34.8 min\n",
            "251053: done 1311 games, reward 386.200, eps 0.01, speed 130.45 f/s, time 34.9 min\n",
            "251357: done 1312 games, reward 387.080, eps 0.01, speed 104.60 f/s, time 34.9 min\n",
            "251533: done 1313 games, reward 384.240, eps 0.01, speed 113.08 f/s, time 34.9 min\n",
            "251707: done 1314 games, reward 381.160, eps 0.01, speed 129.15 f/s, time 35.0 min\n",
            "252475: done 1315 games, reward 386.160, eps 0.01, speed 130.71 f/s, time 35.1 min\n",
            "252543: done 1316 games, reward 375.160, eps 0.01, speed 125.26 f/s, time 35.1 min\n",
            "252742: done 1317 games, reward 371.200, eps 0.01, speed 121.81 f/s, time 35.1 min\n",
            "253192: done 1318 games, reward 370.840, eps 0.01, speed 105.94 f/s, time 35.2 min\n",
            "253246: done 1319 games, reward 371.320, eps 0.01, speed 130.53 f/s, time 35.2 min\n",
            "253391: done 1320 games, reward 367.360, eps 0.01, speed 129.62 f/s, time 35.2 min\n",
            "253439: done 1321 games, reward 367.800, eps 0.01, speed 129.61 f/s, time 35.2 min\n",
            "253527: done 1322 games, reward 367.640, eps 0.01, speed 129.49 f/s, time 35.2 min\n",
            "253728: done 1323 games, reward 358.080, eps 0.01, speed 129.70 f/s, time 35.2 min\n",
            "253799: done 1324 games, reward 358.520, eps 0.01, speed 131.07 f/s, time 35.2 min\n",
            "254112: done 1325 games, reward 361.400, eps 0.01, speed 131.20 f/s, time 35.3 min\n",
            "254277: done 1326 games, reward 353.600, eps 0.01, speed 130.10 f/s, time 35.3 min\n",
            "254861: done 1327 games, reward 360.920, eps 0.01, speed 110.12 f/s, time 35.4 min\n",
            "255049: done 1328 games, reward 362.440, eps 0.01, speed 130.99 f/s, time 35.4 min\n",
            "255167: done 1329 games, reward 358.480, eps 0.01, speed 130.97 f/s, time 35.4 min\n",
            "255218: done 1330 games, reward 358.040, eps 0.01, speed 133.56 f/s, time 35.4 min\n",
            "255401: done 1331 games, reward 357.200, eps 0.01, speed 130.76 f/s, time 35.5 min\n",
            "255771: done 1332 games, reward 356.760, eps 0.01, speed 131.57 f/s, time 35.5 min\n",
            "255924: done 1333 games, reward 354.920, eps 0.01, speed 121.46 f/s, time 35.5 min\n",
            "256183: done 1334 games, reward 351.440, eps 0.01, speed 96.48 f/s, time 35.6 min\n",
            "256937: done 1335 games, reward 358.160, eps 0.01, speed 129.63 f/s, time 35.7 min\n",
            "257147: done 1336 games, reward 359.520, eps 0.01, speed 129.99 f/s, time 35.7 min\n",
            "257419: done 1337 games, reward 365.000, eps 0.01, speed 129.97 f/s, time 35.7 min\n",
            "257544: done 1338 games, reward 365.880, eps 0.01, speed 110.52 f/s, time 35.8 min\n",
            "257897: done 1339 games, reward 354.520, eps 0.01, speed 105.16 f/s, time 35.8 min\n",
            "258073: done 1340 games, reward 353.840, eps 0.01, speed 129.19 f/s, time 35.8 min\n",
            "259123: done 1341 games, reward 364.720, eps 0.01, speed 127.69 f/s, time 36.0 min\n",
            "259623: done 1342 games, reward 377.680, eps 0.01, speed 110.91 f/s, time 36.0 min\n",
            "259746: done 1343 games, reward 380.000, eps 0.01, speed 128.68 f/s, time 36.1 min\n",
            "259936: done 1344 games, reward 374.960, eps 0.01, speed 130.90 f/s, time 36.1 min\n",
            "260251: done 1345 games, reward 379.040, eps 0.01, speed 130.65 f/s, time 36.1 min\n",
            "260290: done 1346 games, reward 374.720, eps 0.01, speed 128.92 f/s, time 36.1 min\n",
            "260798: done 1347 games, reward 373.760, eps 0.01, speed 93.74 f/s, time 36.2 min\n",
            "260914: done 1348 games, reward 375.200, eps 0.01, speed 103.55 f/s, time 36.2 min\n",
            "261166: done 1349 games, reward 375.680, eps 0.01, speed 128.83 f/s, time 36.3 min\n",
            "261249: done 1350 games, reward 370.400, eps 0.01, speed 130.51 f/s, time 36.3 min\n",
            "261508: done 1351 games, reward 373.800, eps 0.01, speed 131.23 f/s, time 36.3 min\n",
            "261623: done 1352 games, reward 363.800, eps 0.01, speed 129.94 f/s, time 36.3 min\n",
            "261835: done 1353 games, reward 363.800, eps 0.01, speed 130.19 f/s, time 36.4 min\n",
            "261932: done 1354 games, reward 359.840, eps 0.01, speed 126.55 f/s, time 36.4 min\n",
            "262085: done 1355 games, reward 360.160, eps 0.01, speed 124.24 f/s, time 36.4 min\n",
            "262621: done 1356 games, reward 370.120, eps 0.01, speed 108.72 f/s, time 36.5 min\n",
            "262677: done 1357 games, reward 364.400, eps 0.01, speed 133.04 f/s, time 36.5 min\n",
            "262751: done 1358 games, reward 363.040, eps 0.01, speed 127.02 f/s, time 36.5 min\n",
            "263112: done 1359 games, reward 369.160, eps 0.01, speed 130.76 f/s, time 36.5 min\n",
            "263298: done 1360 games, reward 371.840, eps 0.01, speed 130.19 f/s, time 36.6 min\n",
            "263369: done 1361 games, reward 367.840, eps 0.01, speed 129.32 f/s, time 36.6 min\n",
            "263484: done 1362 games, reward 367.080, eps 0.01, speed 130.09 f/s, time 36.6 min\n",
            "263640: done 1363 games, reward 360.360, eps 0.01, speed 131.20 f/s, time 36.6 min\n",
            "263766: done 1364 games, reward 359.800, eps 0.01, speed 118.83 f/s, time 36.6 min\n",
            "263968: done 1365 games, reward 359.360, eps 0.01, speed 96.74 f/s, time 36.7 min\n",
            "264286: done 1366 games, reward 360.840, eps 0.01, speed 120.36 f/s, time 36.7 min\n",
            "264421: done 1367 games, reward 359.760, eps 0.01, speed 128.07 f/s, time 36.7 min\n",
            "264552: done 1368 games, reward 359.520, eps 0.01, speed 130.09 f/s, time 36.7 min\n",
            "265574: done 1369 games, reward 373.160, eps 0.01, speed 119.65 f/s, time 36.9 min\n",
            "265617: done 1370 games, reward 368.760, eps 0.01, speed 95.38 f/s, time 36.9 min\n",
            "265732: done 1371 games, reward 366.720, eps 0.01, speed 128.12 f/s, time 36.9 min\n",
            "266005: done 1372 games, reward 366.280, eps 0.01, speed 128.98 f/s, time 36.9 min\n",
            "266119: done 1373 games, reward 364.920, eps 0.01, speed 129.73 f/s, time 36.9 min\n",
            "266257: done 1374 games, reward 365.240, eps 0.01, speed 131.75 f/s, time 37.0 min\n",
            "266392: done 1375 games, reward 366.560, eps 0.01, speed 129.60 f/s, time 37.0 min\n",
            "266477: done 1376 games, reward 366.560, eps 0.01, speed 128.97 f/s, time 37.0 min\n",
            "266727: done 1377 games, reward 365.680, eps 0.01, speed 130.60 f/s, time 37.0 min\n",
            "267111: done 1378 games, reward 374.120, eps 0.01, speed 110.00 f/s, time 37.1 min\n",
            "267306: done 1379 games, reward 373.800, eps 0.01, speed 110.16 f/s, time 37.1 min\n",
            "267687: done 1380 games, reward 379.040, eps 0.01, speed 129.55 f/s, time 37.2 min\n",
            "267759: done 1381 games, reward 368.120, eps 0.01, speed 129.14 f/s, time 37.2 min\n",
            "267815: done 1382 games, reward 368.600, eps 0.01, speed 130.43 f/s, time 37.2 min\n",
            "268142: done 1383 games, reward 374.720, eps 0.01, speed 130.69 f/s, time 37.2 min\n",
            "268345: done 1384 games, reward 370.520, eps 0.01, speed 130.43 f/s, time 37.2 min\n",
            "268536: done 1385 games, reward 373.880, eps 0.01, speed 118.28 f/s, time 37.3 min\n",
            "269058: done 1386 games, reward 380.960, eps 0.01, speed 111.04 f/s, time 37.4 min\n",
            "269128: done 1387 games, reward 379.800, eps 0.01, speed 127.60 f/s, time 37.4 min\n",
            "269277: done 1388 games, reward 378.680, eps 0.01, speed 129.20 f/s, time 37.4 min\n",
            "269391: done 1389 games, reward 380.840, eps 0.01, speed 124.84 f/s, time 37.4 min\n",
            "269632: done 1390 games, reward 379.080, eps 0.01, speed 129.23 f/s, time 37.4 min\n",
            "269733: done 1391 games, reward 380.120, eps 0.01, speed 130.46 f/s, time 37.4 min\n",
            "270098: done 1392 games, reward 385.280, eps 0.01, speed 123.98 f/s, time 37.5 min\n",
            "270140: done 1393 games, reward 379.160, eps 0.01, speed 95.81 f/s, time 37.5 min\n",
            "270194: done 1394 games, reward 372.400, eps 0.01, speed 93.37 f/s, time 37.5 min\n",
            "270500: done 1395 games, reward 375.520, eps 0.01, speed 109.39 f/s, time 37.6 min\n",
            "270966: done 1396 games, reward 371.720, eps 0.01, speed 130.12 f/s, time 37.6 min\n",
            "271248: done 1397 games, reward 370.840, eps 0.01, speed 130.68 f/s, time 37.6 min\n",
            "271618: done 1398 games, reward 373.280, eps 0.01, speed 130.59 f/s, time 37.7 min\n",
            "271700: done 1399 games, reward 373.400, eps 0.01, speed 103.10 f/s, time 37.7 min\n",
            "272059: done 1400 games, reward 378.240, eps 0.01, speed 105.54 f/s, time 37.8 min\n",
            "272442: done 1401 games, reward 383.160, eps 0.01, speed 130.25 f/s, time 37.8 min\n",
            "272695: done 1402 games, reward 383.200, eps 0.01, speed 129.45 f/s, time 37.8 min\n",
            "272984: done 1403 games, reward 382.360, eps 0.01, speed 130.60 f/s, time 37.9 min\n",
            "273358: done 1404 games, reward 383.560, eps 0.01, speed 115.41 f/s, time 37.9 min\n",
            "273475: done 1405 games, reward 379.840, eps 0.01, speed 94.06 f/s, time 38.0 min\n",
            "273651: done 1406 games, reward 374.560, eps 0.01, speed 116.90 f/s, time 38.0 min\n",
            "273846: done 1407 games, reward 372.600, eps 0.01, speed 130.89 f/s, time 38.0 min\n",
            "274114: done 1408 games, reward 374.360, eps 0.01, speed 130.20 f/s, time 38.0 min\n",
            "274469: done 1409 games, reward 381.520, eps 0.01, speed 130.02 f/s, time 38.1 min\n",
            "275095: done 1410 games, reward 391.080, eps 0.01, speed 110.54 f/s, time 38.2 min\n",
            "275204: done 1411 games, reward 390.840, eps 0.01, speed 127.13 f/s, time 38.2 min\n",
            "275245: done 1412 games, reward 387.320, eps 0.01, speed 126.85 f/s, time 38.2 min\n",
            "275446: done 1413 games, reward 389.920, eps 0.01, speed 129.47 f/s, time 38.2 min\n",
            "275796: done 1414 games, reward 394.240, eps 0.01, speed 130.62 f/s, time 38.3 min\n",
            "275847: done 1415 games, reward 386.880, eps 0.01, speed 124.98 f/s, time 38.3 min\n",
            "276449: done 1416 games, reward 394.440, eps 0.01, speed 125.89 f/s, time 38.4 min\n",
            "276679: done 1417 games, reward 398.040, eps 0.01, speed 95.22 f/s, time 38.4 min\n",
            "277015: done 1418 games, reward 400.880, eps 0.01, speed 129.94 f/s, time 38.4 min\n",
            "278191: done 1419 games, reward 418.440, eps 0.01, speed 123.13 f/s, time 38.6 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_418-20251201-0207-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_418-20251201-0207-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 415.280 -> 418.440\n",
            "278625: done 1420 games, reward 432.960, eps 0.01, speed 118.38 f/s, time 38.7 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_432-20251201-0207-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_432-20251201-0207-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 418.440 -> 432.960\n",
            "278666: done 1421 games, reward 432.520, eps 0.01, speed 117.05 f/s, time 38.7 min\n",
            "278770: done 1422 games, reward 432.960, eps 0.01, speed 127.78 f/s, time 38.7 min\n",
            "279033: done 1423 games, reward 434.720, eps 0.01, speed 130.52 f/s, time 38.7 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_434-20251201-0207-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_434-20251201-0207-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 432.960 -> 434.720\n",
            "279549: done 1424 games, reward 441.320, eps 0.01, speed 126.38 f/s, time 38.8 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_441-20251201-0207-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_441-20251201-0207-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 434.720 -> 441.320\n",
            "279669: done 1425 games, reward 439.120, eps 0.01, speed 91.65 f/s, time 38.8 min\n",
            "280006: done 1426 games, reward 440.000, eps 0.01, speed 110.48 f/s, time 38.9 min\n",
            "280053: done 1427 games, reward 429.320, eps 0.01, speed 127.88 f/s, time 38.9 min\n",
            "280787: done 1428 games, reward 440.160, eps 0.01, speed 129.32 f/s, time 39.0 min\n",
            "280961: done 1429 games, reward 439.400, eps 0.01, speed 131.60 f/s, time 39.0 min\n",
            "281019: done 1430 games, reward 440.440, eps 0.01, speed 125.11 f/s, time 39.0 min\n",
            "281382: done 1431 games, reward 443.080, eps 0.01, speed 102.56 f/s, time 39.0 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_443-20251201-0208-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_443-20251201-0208-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 441.320 -> 443.080\n",
            "281531: done 1432 games, reward 439.160, eps 0.01, speed 121.64 f/s, time 39.1 min\n",
            "281596: done 1433 games, reward 438.760, eps 0.01, speed 125.45 f/s, time 39.1 min\n",
            "282664: done 1434 games, reward 458.080, eps 0.01, speed 129.09 f/s, time 39.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_458-20251201-0208-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_458-20251201-0208-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 443.080 -> 458.080\n",
            "282755: done 1435 games, reward 452.280, eps 0.01, speed 90.68 f/s, time 39.2 min\n",
            "282806: done 1436 games, reward 447.080, eps 0.01, speed 91.10 f/s, time 39.2 min\n",
            "283555: done 1437 games, reward 451.640, eps 0.01, speed 120.67 f/s, time 39.3 min\n",
            "283662: done 1438 games, reward 449.960, eps 0.01, speed 130.11 f/s, time 39.4 min\n",
            "283900: done 1439 games, reward 448.200, eps 0.01, speed 130.40 f/s, time 39.4 min\n",
            "284268: done 1440 games, reward 452.880, eps 0.01, speed 126.85 f/s, time 39.4 min\n",
            "284508: done 1441 games, reward 438.280, eps 0.01, speed 95.51 f/s, time 39.5 min\n",
            "284763: done 1442 games, reward 429.720, eps 0.01, speed 123.54 f/s, time 39.5 min\n",
            "285363: done 1443 games, reward 436.400, eps 0.01, speed 130.38 f/s, time 39.6 min\n",
            "285567: done 1444 games, reward 436.760, eps 0.01, speed 129.42 f/s, time 39.6 min\n",
            "285783: done 1445 games, reward 437.360, eps 0.01, speed 131.01 f/s, time 39.6 min\n",
            "286439: done 1446 games, reward 449.240, eps 0.01, speed 111.33 f/s, time 39.7 min\n",
            "286487: done 1447 games, reward 443.120, eps 0.01, speed 130.60 f/s, time 39.7 min\n",
            "286600: done 1448 games, reward 441.680, eps 0.01, speed 129.92 f/s, time 39.8 min\n",
            "286821: done 1449 games, reward 441.760, eps 0.01, speed 128.76 f/s, time 39.8 min\n",
            "287024: done 1450 games, reward 443.120, eps 0.01, speed 131.29 f/s, time 39.8 min\n",
            "287063: done 1451 games, reward 438.280, eps 0.01, speed 123.49 f/s, time 39.8 min\n",
            "287467: done 1452 games, reward 444.000, eps 0.01, speed 124.97 f/s, time 39.9 min\n",
            "287677: done 1453 games, reward 442.240, eps 0.01, speed 96.76 f/s, time 39.9 min\n",
            "287735: done 1454 games, reward 441.800, eps 0.01, speed 106.34 f/s, time 39.9 min\n",
            "288293: done 1455 games, reward 449.520, eps 0.01, speed 129.35 f/s, time 40.0 min\n",
            "288377: done 1456 games, reward 437.640, eps 0.01, speed 131.02 f/s, time 40.0 min\n",
            "288540: done 1457 games, reward 440.520, eps 0.01, speed 131.00 f/s, time 40.0 min\n",
            "288675: done 1458 games, reward 442.680, eps 0.01, speed 131.51 f/s, time 40.0 min\n",
            "289012: done 1459 games, reward 440.040, eps 0.01, speed 129.87 f/s, time 40.1 min\n",
            "289734: done 1460 games, reward 447.720, eps 0.01, speed 113.51 f/s, time 40.2 min\n",
            "290000: done 1461 games, reward 450.760, eps 0.01, speed 129.74 f/s, time 40.2 min\n",
            "290224: done 1462 games, reward 450.760, eps 0.01, speed 130.60 f/s, time 40.3 min\n",
            "290491: done 1463 games, reward 453.760, eps 0.01, speed 129.73 f/s, time 40.3 min\n",
            "291081: done 1464 games, reward 463.320, eps 0.01, speed 110.57 f/s, time 40.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_463-20251201-0209-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_463-20251201-0209-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 458.080 -> 463.320\n",
            "291279: done 1465 games, reward 461.800, eps 0.01, speed 124.79 f/s, time 40.4 min\n",
            "291465: done 1466 games, reward 459.720, eps 0.01, speed 129.97 f/s, time 40.4 min\n",
            "291595: done 1467 games, reward 459.920, eps 0.01, speed 130.20 f/s, time 40.4 min\n",
            "291666: done 1468 games, reward 458.600, eps 0.01, speed 131.51 f/s, time 40.4 min\n",
            "291885: done 1469 games, reward 444.960, eps 0.01, speed 131.81 f/s, time 40.5 min\n",
            "292367: done 1470 games, reward 452.520, eps 0.01, speed 113.62 f/s, time 40.5 min\n",
            "292405: done 1471 games, reward 451.200, eps 0.01, speed 93.36 f/s, time 40.6 min\n",
            "292679: done 1472 games, reward 452.000, eps 0.01, speed 119.65 f/s, time 40.6 min\n",
            "292925: done 1473 games, reward 455.520, eps 0.01, speed 130.64 f/s, time 40.6 min\n",
            "293047: done 1474 games, reward 455.080, eps 0.01, speed 129.85 f/s, time 40.6 min\n",
            "293960: done 1475 games, reward 471.360, eps 0.01, speed 105.03 f/s, time 40.8 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_471-20251201-0209-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_471-20251201-0209-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 463.320 -> 471.360\n",
            "294206: done 1476 games, reward 474.440, eps 0.01, speed 124.06 f/s, time 40.8 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_474-20251201-0209-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_474-20251201-0209-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 471.360 -> 474.440\n",
            "294523: done 1477 games, reward 474.920, eps 0.01, speed 129.10 f/s, time 40.9 min\n",
            "294772: done 1478 games, reward 470.920, eps 0.01, speed 128.57 f/s, time 40.9 min\n",
            "294952: done 1479 games, reward 471.240, eps 0.01, speed 130.27 f/s, time 40.9 min\n",
            "295020: done 1480 games, reward 465.080, eps 0.01, speed 131.74 f/s, time 40.9 min\n",
            "295089: done 1481 games, reward 464.560, eps 0.01, speed 127.95 f/s, time 40.9 min\n",
            "295614: done 1482 games, reward 473.560, eps 0.01, speed 107.79 f/s, time 41.0 min\n",
            "295975: done 1483 games, reward 471.800, eps 0.01, speed 129.77 f/s, time 41.1 min\n",
            "296416: done 1484 games, reward 490.840, eps 0.01, speed 130.16 f/s, time 41.1 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_490-20251201-0210-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_490-20251201-0210-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 474.440 -> 490.840\n",
            "296843: done 1485 games, reward 493.600, eps 0.01, speed 121.44 f/s, time 41.2 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_493-20251201-0210-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_493-20251201-0210-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 490.840 -> 493.600\n",
            "297146: done 1486 games, reward 491.320, eps 0.01, speed 99.73 f/s, time 41.2 min\n",
            "297570: done 1487 games, reward 496.680, eps 0.01, speed 130.07 f/s, time 41.3 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_496-20251201-0210-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_496-20251201-0210-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 493.600 -> 496.680\n",
            "298610: done 1488 games, reward 512.760, eps 0.01, speed 117.60 f/s, time 41.4 min\n",
            "ðŸ’¾ Model saved to:\n",
            " - Google Drive: /content/drive/MyDrive/PUBLIC/Models/ALE_BeamRider-v5-best_512-20251201-0210-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            " - Local:        saved_models/ALE_BeamRider-v5-best_512-20251201-0210-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4.dat\n",
            "Best reward updated 496.680 -> 512.760\n",
            "Solved in 298610 frames!\n",
            "\n",
            ">>> Triggering final solved video recording (m_reward 512.760) at frame_idx 298610 <<<\n",
            "Recording 2 episodes for tag: solved_reward_512_f298610...\n",
            "  Episode 1 finished with reward: 660.0 (frames: 309)\n",
            "  Episode 2 finished with reward: 144.0 (frames: 129)\n",
            "Video recording for tag 'solved_reward_512_f298610' complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8cb65f2b",
        "outputId": "a03a5b9f-bcb3-4657-8cb7-0a12fa6db60a"
      },
      "source": [
        "model_comment = f\"lr{LEARNING_RATE}_gamma{GAMMA}_epsdec{EPSILON_DECAY_LAST_FRAME}_rs{REPLAY_START_SIZE}_bs{BATCH_SIZE}_sync{SYNC_TARGET_FRAMES}_fs{N_STEPS}\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "env = make_env(env_name)\n",
        "net = DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
        "tgt_net = DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
        "writer = SummaryWriter(comment=f\"-{env_name}-{model_comment}\")\n",
        "print(net)\n",
        "\n",
        "buffer = ExperienceBuffer(REPLAY_SIZE)\n",
        "agent = Agent(env, buffer)\n",
        "epsilon = EPSILON_START\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
        "total_rewards = []\n",
        "frame_idx = 0\n",
        "ts_frame = 0\n",
        "ts = time.time()\n",
        "best_m_reward = None\n",
        "\n",
        "hparams = {\n",
        "    'learning_rate': LEARNING_RATE,\n",
        "    'gamma': GAMMA,\n",
        "    'epsilon_start': EPSILON_START,\n",
        "    'epsilon_final': EPSILON_FINAL,\n",
        "    'epsilon_decay_last_frame': EPSILON_DECAY_LAST_FRAME,\n",
        "    'replay_size': REPLAY_SIZE,\n",
        "    'replay_start_size': REPLAY_START_SIZE,\n",
        "    'batch_size': BATCH_SIZE,\n",
        "    'sync_target_frames': SYNC_TARGET_FRAMES,\n",
        "    'frame_stack': N_STEPS,\n",
        "    'optimizer': 'Adam',\n",
        "    'mean_reward_bound': MEAN_REWARD_BOUND\n",
        "}\n",
        "\n",
        "# Flags to ensure video is recorded only once per trigger point\n",
        "early_video_recorded = False\n",
        "trained_video_recorded = False\n",
        "\n",
        "start_time = time.time()\n",
        "while True:\n",
        "    frame_idx += 1\n",
        "    epsilon = max(EPSILON_FINAL, EPSILON_START - frame_idx / EPSILON_DECAY_LAST_FRAME)\n",
        "\n",
        "    reward = agent.play_step(net, device, epsilon)\n",
        "    if reward is not None:\n",
        "        total_rewards.append(reward)\n",
        "        speed = (frame_idx - ts_frame) / (time.time() - ts)\n",
        "        elapsed = time.time() - start_time  # in seconds\n",
        "        ts_frame = frame_idx\n",
        "        ts = time.time()\n",
        "        m_reward = np.mean(total_rewards[-100:])\n",
        "        print(f\"{frame_idx}: done {len(total_rewards)} games, reward {m_reward:.3f}, \"\n",
        "             f\"eps {epsilon:.2f}, speed {speed:.2f} f/s, time {elapsed/60:.1f} min\")\n",
        "        writer.add_scalar(\"epsilon\", epsilon, frame_idx)\n",
        "        writer.add_scalar(\"speed\", speed, frame_idx)\n",
        "        writer.add_scalar(\"reward_100\", m_reward, frame_idx)\n",
        "        writer.add_scalar(\"reward\", reward, frame_idx)\n",
        "\n",
        "        # --- Video Recording Triggers ---\n",
        "        # 1. Early video recording\n",
        "        if not early_video_recorded and frame_idx >= EARLY_VIDEO_FRAME_THRESHOLD:\n",
        "            print(f\"\\n>>> Triggering early video recording at frame_idx {frame_idx} <<<\")\n",
        "            save_video_for_model(net, device, tag=f\"early_training_f{frame_idx}\", num_episodes=VIDEO_RECORD_EPISODES)\n",
        "            early_video_recorded = True\n",
        "\n",
        "        # 2. When the model starts performing well\n",
        "        if not trained_video_recorded and m_reward >= TRAINED_VIDEO_REWARD_THRESHOLD:\n",
        "            print(f\"\\n>>> Triggering trained video recording (m_reward {m_reward:.3f}) at frame_idx {frame_idx} <<<\")\n",
        "            save_video_for_model(net, device, tag=f\"trained_reward_{int(m_reward)}_f{frame_idx}\", num_episodes=VIDEO_RECORD_EPISODES)\n",
        "            trained_video_recorded = True\n",
        "        # --- End Video Recording Triggers ---\n",
        "\n",
        "        if best_m_reward is None or m_reward > best_m_reward + SAVE_EPSILON:\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
        "            model_filename = f\"{safe_env_name}-best_{int(m_reward)}-{timestamp}-{model_comment}.dat\"\n",
        "\n",
        "            model_path_drive = os.path.join(save_dir_drive, model_filename)\n",
        "            model_path_local = os.path.join(save_dir_local, model_filename)\n",
        "\n",
        "            torch.save(net.state_dict(), model_path_drive)\n",
        "            torch.save(net.state_dict(), model_path_local)\n",
        "\n",
        "            print(f\"\\ud83d\\udcbe Model saved to:\\n - Google Drive: {model_path_drive}\\n - Local:        {model_path_local}\")\n",
        "            if best_m_reward is not None:\n",
        "                print(f\"Best reward updated {best_m_reward:.3f} -> {m_reward:.3f}\")\n",
        "            best_m_reward = m_reward\n",
        "\n",
        "            writer.add_hparams(hparams, {'metric/mean_reward': m_reward}, global_step=frame_idx)\n",
        "\n",
        "        if m_reward >= MEAN_REWARD_BOUND:\n",
        "            print(\"Solved in %d frames!\" % frame_idx)\n",
        "            # --- Video Recording Triggers ---\n",
        "            print(f\"\\n>>> Triggering final solved video recording (m_reward {m_reward:.3f}) at frame_idx {frame_idx} <<<\")\n",
        "            save_video_for_model(net, device, tag=f\"solved_reward_{int(m_reward)}_f{frame_idx}\", num_episodes=VIDEO_RECORD_EPISODES)\n",
        "            # --- End Video Recording Triggers ---\n",
        "            break\n",
        "\n",
        "    if len(buffer) < REPLAY_START_SIZE:\n",
        "        continue\n",
        "    if frame_idx % SYNC_TARGET_FRAMES == 0:\n",
        "        tgt_net.load_state_dict(net.state_dict())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    batch = buffer.sample(BATCH_SIZE)\n",
        "    loss_t = calc_loss(batch, net, tgt_net, device)\n",
        "    loss_t.backward()\n",
        "    optimizer.step()\n",
        "env.close()\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating environment ALE/BeamRider-v5\n",
            "DQN(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (5): ReLU()\n",
            "    (6): Flatten(start_dim=1, end_dim=-1)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=3136, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n",
            "194: done 1 games, reward 308.000, eps 0.98, speed 253.25 f/s, time 0.0 min\n",
            "\n",
            ">>> Triggering trained video recording (m_reward 308.000) at frame_idx 194 <<<\n",
            "Recording 2 episodes for tag: trained_reward_308_f194...\n",
            "  Episode 1 finished with reward: 0.0 (frames: 157)\n",
            "  Episode 2 finished with reward: 0.0 (frames: 94)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 89-90: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 89-90: surrogates not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "294: done 2 games, reward 286.000, eps 0.97, speed 13.64 f/s, time 0.1 min\n",
            "485: done 3 games, reward 220.000, eps 0.95, speed 384.06 f/s, time 0.1 min\n",
            "700: done 4 games, reward 220.000, eps 0.93, speed 363.98 f/s, time 0.2 min\n",
            "802: done 5 games, reward 176.000, eps 0.92, speed 371.36 f/s, time 0.2 min\n",
            "860: done 6 games, reward 161.333, eps 0.91, speed 366.04 f/s, time 0.2 min\n",
            "1014: done 7 games, reward 163.429, eps 0.90, speed 296.07 f/s, time 0.2 min\n",
            "1092: done 8 games, reward 148.500, eps 0.89, speed 152.10 f/s, time 0.2 min\n",
            "1140: done 9 games, reward 132.000, eps 0.89, speed 150.42 f/s, time 0.2 min\n",
            "1325: done 10 games, reward 145.200, eps 0.87, speed 146.07 f/s, time 0.2 min\n",
            "1386: done 11 games, reward 140.000, eps 0.86, speed 154.35 f/s, time 0.2 min\n",
            "1495: done 12 games, reward 146.667, eps 0.85, speed 137.50 f/s, time 0.2 min\n",
            "1697: done 13 games, reward 155.692, eps 0.83, speed 106.62 f/s, time 0.3 min\n",
            "1793: done 14 games, reward 150.857, eps 0.82, speed 104.07 f/s, time 0.3 min\n",
            "1844: done 15 games, reward 143.733, eps 0.82, speed 137.38 f/s, time 0.3 min\n",
            "2017: done 16 games, reward 148.500, eps 0.80, speed 145.76 f/s, time 0.3 min\n",
            "2142: done 17 games, reward 150.118, eps 0.79, speed 146.36 f/s, time 0.3 min\n",
            "2199: done 18 games, reward 141.778, eps 0.78, speed 144.70 f/s, time 0.3 min\n",
            "2458: done 19 games, reward 145.895, eps 0.75, speed 147.05 f/s, time 0.3 min\n",
            "2508: done 20 games, reward 138.600, eps 0.75, speed 146.80 f/s, time 0.4 min\n",
            "2571: done 21 games, reward 132.000, eps 0.74, speed 141.58 f/s, time 0.4 min\n",
            "2692: done 22 games, reward 134.000, eps 0.73, speed 148.33 f/s, time 0.4 min\n",
            "2739: done 23 games, reward 128.174, eps 0.73, speed 143.88 f/s, time 0.4 min\n",
            "2816: done 24 games, reward 124.667, eps 0.72, speed 147.83 f/s, time 0.4 min\n",
            "2937: done 25 games, reward 124.960, eps 0.71, speed 147.26 f/s, time 0.4 min\n",
            "2988: done 26 games, reward 120.154, eps 0.70, speed 144.71 f/s, time 0.4 min\n",
            "3070: done 27 games, reward 120.593, eps 0.69, speed 141.01 f/s, time 0.4 min\n",
            "3218: done 28 games, reward 119.429, eps 0.68, speed 147.96 f/s, time 0.4 min\n",
            "3363: done 29 games, reward 122.897, eps 0.66, speed 111.88 f/s, time 0.5 min\n",
            "3538: done 30 games, reward 129.067, eps 0.65, speed 101.32 f/s, time 0.5 min\n",
            "3659: done 31 games, reward 129.161, eps 0.63, speed 126.37 f/s, time 0.5 min\n",
            "3713: done 32 games, reward 125.125, eps 0.63, speed 136.05 f/s, time 0.5 min\n",
            "3769: done 33 games, reward 122.667, eps 0.62, speed 147.27 f/s, time 0.5 min\n",
            "4086: done 34 games, reward 133.294, eps 0.59, speed 143.64 f/s, time 0.5 min\n",
            "4184: done 35 games, reward 133.257, eps 0.58, speed 144.38 f/s, time 0.6 min\n",
            "4292: done 36 games, reward 130.778, eps 0.57, speed 142.09 f/s, time 0.6 min\n",
            "4690: done 37 games, reward 145.081, eps 0.53, speed 141.15 f/s, time 0.6 min\n",
            "4744: done 38 games, reward 143.789, eps 0.53, speed 141.67 f/s, time 0.6 min\n",
            "4783: done 39 games, reward 140.103, eps 0.52, speed 138.35 f/s, time 0.6 min\n",
            "4931: done 40 games, reward 139.900, eps 0.51, speed 141.54 f/s, time 0.6 min\n",
            "5009: done 41 games, reward 138.634, eps 0.50, speed 122.26 f/s, time 0.7 min\n",
            "\n",
            ">>> Triggering early video recording at frame_idx 5009 <<<\n",
            "Recording 2 episodes for tag: early_training_f5009...\n",
            "  Episode 1 finished with reward: 220.0 (frames: 177)\n",
            "  Episode 2 finished with reward: 440.0 (frames: 446)\n",
            "Video recording for tag 'early_training_f5009' complete.\n",
            "5071: done 42 games, reward 136.381, eps 0.49, speed 3.68 f/s, time 0.9 min\n",
            "5192: done 43 games, reward 137.302, eps 0.48, speed 138.22 f/s, time 1.0 min\n",
            "5335: done 44 games, reward 137.182, eps 0.47, speed 140.79 f/s, time 1.0 min\n",
            "5470: done 45 games, reward 137.067, eps 0.45, speed 137.40 f/s, time 1.0 min\n",
            "5551: done 46 games, reward 137.913, eps 0.44, speed 140.75 f/s, time 1.0 min\n",
            "5652: done 47 games, reward 135.915, eps 0.43, speed 137.02 f/s, time 1.0 min\n",
            "5700: done 48 games, reward 133.083, eps 0.43, speed 140.24 f/s, time 1.0 min\n",
            "5852: done 49 games, reward 133.959, eps 0.41, speed 139.89 f/s, time 1.0 min\n",
            "5901: done 50 games, reward 132.160, eps 0.41, speed 139.03 f/s, time 1.0 min\n",
            "6006: done 51 games, reward 130.431, eps 0.40, speed 140.61 f/s, time 1.1 min\n",
            "6332: done 52 games, reward 135.538, eps 0.37, speed 136.08 f/s, time 1.1 min\n",
            "6383: done 53 games, reward 134.642, eps 0.36, speed 140.70 f/s, time 1.1 min\n",
            "6449: done 54 games, reward 133.778, eps 0.36, speed 136.47 f/s, time 1.1 min\n",
            "6560: done 55 games, reward 135.345, eps 0.34, speed 99.05 f/s, time 1.1 min\n",
            "6648: done 56 games, reward 135.286, eps 0.34, speed 100.49 f/s, time 1.1 min\n",
            "6723: done 57 games, reward 132.912, eps 0.33, speed 96.84 f/s, time 1.2 min\n",
            "6882: done 58 games, reward 134.414, eps 0.31, speed 126.98 f/s, time 1.2 min\n",
            "6944: done 59 games, reward 133.627, eps 0.31, speed 137.69 f/s, time 1.2 min\n",
            "7090: done 60 games, reward 134.333, eps 0.29, speed 135.37 f/s, time 1.2 min\n",
            "7205: done 61 games, reward 133.574, eps 0.28, speed 138.71 f/s, time 1.2 min\n",
            "7262: done 62 games, reward 131.419, eps 0.27, speed 136.36 f/s, time 1.2 min\n",
            "7327: done 63 games, reward 130.032, eps 0.27, speed 133.36 f/s, time 1.2 min\n",
            "7502: done 64 games, reward 130.750, eps 0.25, speed 134.18 f/s, time 1.2 min\n",
            "7549: done 65 games, reward 129.415, eps 0.25, speed 133.82 f/s, time 1.3 min\n",
            "7631: done 66 games, reward 128.121, eps 0.24, speed 134.33 f/s, time 1.3 min\n",
            "7735: done 67 games, reward 130.149, eps 0.23, speed 135.25 f/s, time 1.3 min\n",
            "7799: done 68 games, reward 128.882, eps 0.22, speed 133.97 f/s, time 1.3 min\n",
            "7855: done 69 games, reward 127.652, eps 0.21, speed 134.15 f/s, time 1.3 min\n",
            "8229: done 70 games, reward 135.257, eps 0.18, speed 118.64 f/s, time 1.3 min\n",
            "8277: done 71 games, reward 133.352, eps 0.17, speed 94.75 f/s, time 1.4 min\n",
            "8331: done 72 games, reward 132.167, eps 0.17, speed 100.33 f/s, time 1.4 min\n",
            "8431: done 73 games, reward 132.767, eps 0.16, speed 103.36 f/s, time 1.4 min\n",
            "8552: done 74 games, reward 133.351, eps 0.14, speed 132.63 f/s, time 1.4 min\n",
            "8620: done 75 games, reward 132.160, eps 0.14, speed 135.20 f/s, time 1.4 min\n",
            "8671: done 76 games, reward 130.421, eps 0.13, speed 126.56 f/s, time 1.4 min\n",
            "8775: done 77 games, reward 130.442, eps 0.12, speed 131.62 f/s, time 1.4 min\n",
            "8835: done 78 games, reward 129.897, eps 0.12, speed 135.71 f/s, time 1.4 min\n",
            "8894: done 79 games, reward 128.810, eps 0.11, speed 132.49 f/s, time 1.4 min\n",
            "9022: done 80 games, reward 128.850, eps 0.10, speed 130.73 f/s, time 1.5 min\n",
            "9171: done 81 games, reward 129.432, eps 0.08, speed 132.46 f/s, time 1.5 min\n",
            "9226: done 82 games, reward 127.854, eps 0.08, speed 130.93 f/s, time 1.5 min\n",
            "9378: done 83 games, reward 127.904, eps 0.06, speed 131.47 f/s, time 1.5 min\n",
            "9463: done 84 games, reward 126.905, eps 0.05, speed 125.40 f/s, time 1.5 min\n",
            "9538: done 85 games, reward 126.447, eps 0.05, speed 132.00 f/s, time 1.5 min\n",
            "9683: done 86 games, reward 128.047, eps 0.03, speed 131.56 f/s, time 1.5 min\n",
            "9731: done 87 games, reward 127.080, eps 0.03, speed 101.78 f/s, time 1.5 min\n",
            "9796: done 88 games, reward 125.636, eps 0.02, speed 98.92 f/s, time 1.6 min\n",
            "9926: done 89 games, reward 127.685, eps 0.01, speed 95.08 f/s, time 1.6 min\n",
            "9997: done 90 games, reward 127.244, eps 0.01, speed 91.34 f/s, time 1.6 min\n",
            "10095: done 91 games, reward 127.297, eps 0.01, speed 125.58 f/s, time 1.6 min\n",
            "10223: done 92 games, reward 129.739, eps 0.01, speed 129.34 f/s, time 1.6 min\n",
            "10341: done 93 games, reward 129.290, eps 0.01, speed 130.08 f/s, time 1.6 min\n",
            "10398: done 94 games, reward 128.383, eps 0.01, speed 132.40 f/s, time 1.6 min\n",
            "10443: done 95 games, reward 127.032, eps 0.01, speed 126.58 f/s, time 1.7 min\n",
            "10563: done 96 games, reward 128.458, eps 0.01, speed 128.78 f/s, time 1.7 min\n",
            "10621: done 97 games, reward 127.588, eps 0.01, speed 128.78 f/s, time 1.7 min\n",
            "10818: done 98 games, reward 129.429, eps 0.01, speed 129.57 f/s, time 1.7 min\n",
            "10915: done 99 games, reward 129.455, eps 0.01, speed 129.25 f/s, time 1.7 min\n",
            "10984: done 100 games, reward 128.600, eps 0.01, speed 128.57 f/s, time 1.7 min\n",
            "11062: done 101 games, reward 126.840, eps 0.01, speed 128.60 f/s, time 1.7 min\n",
            "11151: done 102 games, reward 125.960, eps 0.01, speed 128.53 f/s, time 1.7 min\n",
            "11215: done 103 games, reward 125.520, eps 0.01, speed 132.15 f/s, time 1.7 min\n",
            "11286: done 104 games, reward 123.760, eps 0.01, speed 121.54 f/s, time 1.8 min\n",
            "11393: done 105 games, reward 124.640, eps 0.01, speed 95.36 f/s, time 1.8 min\n",
            "11444: done 106 games, reward 123.760, eps 0.01, speed 95.66 f/s, time 1.8 min\n",
            "11576: done 107 games, reward 122.880, eps 0.01, speed 92.45 f/s, time 1.8 min\n",
            "11826: done 108 games, reward 126.840, eps 0.01, speed 129.22 f/s, time 1.8 min\n",
            "11877: done 109 games, reward 126.840, eps 0.01, speed 131.35 f/s, time 1.8 min\n",
            "11949: done 110 games, reward 125.080, eps 0.01, speed 125.44 f/s, time 1.9 min\n",
            "12104: done 111 games, reward 126.400, eps 0.01, speed 131.37 f/s, time 1.9 min\n",
            "12169: done 112 games, reward 124.640, eps 0.01, speed 132.92 f/s, time 1.9 min\n",
            "12244: done 113 games, reward 122.440, eps 0.01, speed 128.69 f/s, time 1.9 min\n",
            "12388: done 114 games, reward 122.880, eps 0.01, speed 129.08 f/s, time 1.9 min\n",
            "12445: done 115 games, reward 122.880, eps 0.01, speed 132.24 f/s, time 1.9 min\n",
            "12634: done 116 games, reward 122.440, eps 0.01, speed 130.94 f/s, time 1.9 min\n",
            "12729: done 117 games, reward 122.880, eps 0.01, speed 128.17 f/s, time 2.0 min\n",
            "12931: done 118 games, reward 126.400, eps 0.01, speed 116.18 f/s, time 2.0 min\n",
            "13022: done 119 games, reward 125.080, eps 0.01, speed 96.36 f/s, time 2.0 min\n",
            "13126: done 120 games, reward 125.520, eps 0.01, speed 95.62 f/s, time 2.0 min\n",
            "13297: done 121 games, reward 129.040, eps 0.01, speed 122.34 f/s, time 2.0 min\n",
            "13682: done 122 games, reward 131.800, eps 0.01, speed 130.01 f/s, time 2.1 min\n",
            "13724: done 123 games, reward 131.800, eps 0.01, speed 126.68 f/s, time 2.1 min\n",
            "13869: done 124 games, reward 133.560, eps 0.01, speed 131.59 f/s, time 2.1 min\n",
            "13951: done 125 games, reward 133.120, eps 0.01, speed 132.85 f/s, time 2.1 min\n",
            "14056: done 126 games, reward 134.440, eps 0.01, speed 131.33 f/s, time 2.1 min\n",
            "14174: done 127 games, reward 135.320, eps 0.01, speed 130.73 f/s, time 2.2 min\n",
            "14257: done 128 games, reward 135.320, eps 0.01, speed 129.18 f/s, time 2.2 min\n",
            "14351: done 129 games, reward 134.880, eps 0.01, speed 132.01 f/s, time 2.2 min\n",
            "14476: done 130 games, reward 133.560, eps 0.01, speed 119.59 f/s, time 2.2 min\n",
            "14595: done 131 games, reward 134.880, eps 0.01, speed 95.59 f/s, time 2.2 min\n",
            "14654: done 132 games, reward 134.880, eps 0.01, speed 95.14 f/s, time 2.2 min\n",
            "14792: done 133 games, reward 136.200, eps 0.01, speed 102.81 f/s, time 2.3 min\n",
            "14860: done 134 games, reward 132.680, eps 0.01, speed 127.44 f/s, time 2.3 min\n",
            "14912: done 135 games, reward 131.800, eps 0.01, speed 130.11 f/s, time 2.3 min\n",
            "15095: done 136 games, reward 134.440, eps 0.01, speed 128.48 f/s, time 2.3 min\n",
            "15160: done 137 games, reward 127.840, eps 0.01, speed 130.92 f/s, time 2.3 min\n",
            "15251: done 138 games, reward 127.760, eps 0.01, speed 127.33 f/s, time 2.3 min\n",
            "15416: done 139 games, reward 132.600, eps 0.01, speed 130.52 f/s, time 2.3 min\n",
            "15539: done 140 games, reward 133.040, eps 0.01, speed 130.32 f/s, time 2.3 min\n",
            "15589: done 141 games, reward 132.160, eps 0.01, speed 130.13 f/s, time 2.4 min\n",
            "15713: done 142 games, reward 133.480, eps 0.01, speed 129.16 f/s, time 2.4 min\n",
            "15795: done 143 games, reward 132.160, eps 0.01, speed 127.58 f/s, time 2.4 min\n",
            "15849: done 144 games, reward 131.280, eps 0.01, speed 129.89 f/s, time 2.4 min\n",
            "16094: done 145 games, reward 135.240, eps 0.01, speed 118.37 f/s, time 2.4 min\n",
            "16138: done 146 games, reward 133.480, eps 0.01, speed 96.80 f/s, time 2.4 min\n",
            "16203: done 147 games, reward 133.040, eps 0.01, speed 96.86 f/s, time 2.4 min\n",
            "16364: done 148 games, reward 138.320, eps 0.01, speed 100.16 f/s, time 2.5 min\n",
            "16628: done 149 games, reward 137.440, eps 0.01, speed 131.37 f/s, time 2.5 min\n",
            "16678: done 150 games, reward 137.440, eps 0.01, speed 127.39 f/s, time 2.5 min\n",
            "16820: done 151 games, reward 137.880, eps 0.01, speed 127.80 f/s, time 2.5 min\n",
            "16887: done 152 games, reward 135.240, eps 0.01, speed 128.99 f/s, time 2.5 min\n",
            "16934: done 153 games, reward 134.360, eps 0.01, speed 129.49 f/s, time 2.5 min\n",
            "17304: done 154 games, reward 140.560, eps 0.01, speed 130.27 f/s, time 2.6 min\n",
            "17386: done 155 games, reward 138.840, eps 0.01, speed 127.31 f/s, time 2.6 min\n",
            "17461: done 156 games, reward 138.480, eps 0.01, speed 128.07 f/s, time 2.6 min\n",
            "17720: done 157 games, reward 142.440, eps 0.01, speed 112.59 f/s, time 2.6 min\n",
            "17952: done 158 games, reward 142.880, eps 0.01, speed 100.21 f/s, time 2.7 min\n",
            "17992: done 159 games, reward 142.000, eps 0.01, speed 123.60 f/s, time 2.7 min\n",
            "18234: done 160 games, reward 142.880, eps 0.01, speed 130.53 f/s, time 2.7 min\n",
            "18309: done 161 games, reward 142.880, eps 0.01, speed 129.52 f/s, time 2.7 min\n",
            "18373: done 162 games, reward 143.320, eps 0.01, speed 129.93 f/s, time 2.7 min\n",
            "18588: done 163 games, reward 146.840, eps 0.01, speed 130.61 f/s, time 2.8 min\n",
            "18639: done 164 games, reward 145.080, eps 0.01, speed 131.36 f/s, time 2.8 min\n",
            "18703: done 165 games, reward 145.080, eps 0.01, speed 127.94 f/s, time 2.8 min\n",
            "18812: done 166 games, reward 146.840, eps 0.01, speed 128.34 f/s, time 2.8 min\n",
            "18867: done 167 games, reward 144.200, eps 0.01, speed 126.47 f/s, time 2.8 min\n",
            "18927: done 168 games, reward 144.640, eps 0.01, speed 126.96 f/s, time 2.8 min\n",
            "19079: done 169 games, reward 146.400, eps 0.01, speed 130.84 f/s, time 2.8 min\n",
            "19135: done 170 games, reward 140.680, eps 0.01, speed 132.41 f/s, time 2.8 min\n",
            "19183: done 171 games, reward 140.680, eps 0.01, speed 123.92 f/s, time 2.8 min\n",
            "19291: done 172 games, reward 141.080, eps 0.01, speed 94.80 f/s, time 2.9 min\n",
            "19399: done 173 games, reward 141.520, eps 0.01, speed 95.91 f/s, time 2.9 min\n",
            "19454: done 174 games, reward 140.200, eps 0.01, speed 90.58 f/s, time 2.9 min\n",
            "19558: done 175 games, reward 141.520, eps 0.01, speed 121.49 f/s, time 2.9 min\n",
            "19623: done 176 games, reward 142.400, eps 0.01, speed 133.83 f/s, time 2.9 min\n",
            "19701: done 177 games, reward 141.080, eps 0.01, speed 128.70 f/s, time 2.9 min\n",
            "19791: done 178 games, reward 141.520, eps 0.01, speed 130.38 f/s, time 2.9 min\n",
            "19869: done 179 games, reward 142.840, eps 0.01, speed 134.26 f/s, time 2.9 min\n",
            "20010: done 180 games, reward 143.280, eps 0.01, speed 131.32 f/s, time 3.0 min\n",
            "20175: done 181 games, reward 143.280, eps 0.01, speed 129.83 f/s, time 3.0 min\n",
            "20222: done 182 games, reward 144.160, eps 0.01, speed 126.15 f/s, time 3.0 min\n",
            "20333: done 183 games, reward 142.840, eps 0.01, speed 126.94 f/s, time 3.0 min\n",
            "20463: done 184 games, reward 145.040, eps 0.01, speed 129.70 f/s, time 3.0 min\n",
            "20555: done 185 games, reward 145.920, eps 0.01, speed 131.94 f/s, time 3.0 min\n",
            "20623: done 186 games, reward 144.160, eps 0.01, speed 127.77 f/s, time 3.0 min\n",
            "20760: done 187 games, reward 146.360, eps 0.01, speed 130.87 f/s, time 3.1 min\n",
            "20841: done 188 games, reward 147.680, eps 0.01, speed 96.02 f/s, time 3.1 min\n",
            "20911: done 189 games, reward 144.600, eps 0.01, speed 95.16 f/s, time 3.1 min\n",
            "21014: done 190 games, reward 146.800, eps 0.01, speed 93.19 f/s, time 3.1 min\n",
            "21102: done 191 games, reward 147.240, eps 0.01, speed 107.47 f/s, time 3.1 min\n",
            "21157: done 192 games, reward 143.720, eps 0.01, speed 127.36 f/s, time 3.1 min\n",
            "21313: done 193 games, reward 146.800, eps 0.01, speed 130.25 f/s, time 3.1 min\n",
            "21364: done 194 games, reward 146.360, eps 0.01, speed 132.03 f/s, time 3.2 min\n",
            "21416: done 195 games, reward 146.360, eps 0.01, speed 130.85 f/s, time 3.2 min\n",
            "21661: done 196 games, reward 148.560, eps 0.01, speed 130.58 f/s, time 3.2 min\n",
            "21830: done 197 games, reward 150.360, eps 0.01, speed 126.60 f/s, time 3.2 min\n",
            "21868: done 198 games, reward 147.280, eps 0.01, speed 128.02 f/s, time 3.2 min\n",
            "22013: done 199 games, reward 147.720, eps 0.01, speed 130.03 f/s, time 3.2 min\n",
            "22104: done 200 games, reward 149.480, eps 0.01, speed 130.17 f/s, time 3.2 min\n",
            "22172: done 201 games, reward 148.600, eps 0.01, speed 130.55 f/s, time 3.3 min\n",
            "22317: done 202 games, reward 150.800, eps 0.01, speed 130.41 f/s, time 3.3 min\n",
            "22522: done 203 games, reward 153.000, eps 0.01, speed 100.13 f/s, time 3.3 min\n",
            "22601: done 204 games, reward 154.000, eps 0.01, speed 93.52 f/s, time 3.3 min\n",
            "22775: done 205 games, reward 157.520, eps 0.01, speed 117.79 f/s, time 3.3 min\n",
            "22886: done 206 games, reward 158.400, eps 0.01, speed 130.16 f/s, time 3.4 min\n",
            "23051: done 207 games, reward 159.320, eps 0.01, speed 132.24 f/s, time 3.4 min\n",
            "23220: done 208 games, reward 158.440, eps 0.01, speed 130.00 f/s, time 3.4 min\n",
            "23364: done 209 games, reward 161.520, eps 0.01, speed 130.01 f/s, time 3.4 min\n",
            "23432: done 210 games, reward 162.560, eps 0.01, speed 131.41 f/s, time 3.4 min\n",
            "23599: done 211 games, reward 162.120, eps 0.01, speed 130.90 f/s, time 3.5 min\n",
            "23681: done 212 games, reward 162.560, eps 0.01, speed 130.35 f/s, time 3.5 min\n",
            "23830: done 213 games, reward 163.440, eps 0.01, speed 130.66 f/s, time 3.5 min\n",
            "23977: done 214 games, reward 164.760, eps 0.01, speed 116.32 f/s, time 3.5 min\n",
            "24101: done 215 games, reward 166.520, eps 0.01, speed 92.94 f/s, time 3.5 min\n",
            "24152: done 216 games, reward 165.200, eps 0.01, speed 97.71 f/s, time 3.5 min\n",
            "24190: done 217 games, reward 163.000, eps 0.01, speed 90.52 f/s, time 3.5 min\n",
            "24304: done 218 games, reward 160.360, eps 0.01, speed 114.03 f/s, time 3.6 min\n",
            "24403: done 219 games, reward 160.800, eps 0.01, speed 130.32 f/s, time 3.6 min\n",
            "24457: done 220 games, reward 160.800, eps 0.01, speed 129.23 f/s, time 3.6 min\n",
            "24616: done 221 games, reward 160.360, eps 0.01, speed 130.49 f/s, time 3.6 min\n",
            "24711: done 222 games, reward 157.160, eps 0.01, speed 127.42 f/s, time 3.6 min\n",
            "24880: done 223 games, reward 158.920, eps 0.01, speed 127.51 f/s, time 3.6 min\n",
            "24975: done 224 games, reward 158.480, eps 0.01, speed 95.84 f/s, time 3.6 min\n",
            "25144: done 225 games, reward 159.360, eps 0.01, speed 94.26 f/s, time 3.7 min\n",
            "25263: done 226 games, reward 158.920, eps 0.01, speed 121.34 f/s, time 3.7 min\n",
            "25373: done 227 games, reward 158.920, eps 0.01, speed 128.94 f/s, time 3.7 min\n",
            "25441: done 228 games, reward 159.360, eps 0.01, speed 103.29 f/s, time 3.7 min\n",
            "25559: done 229 games, reward 160.240, eps 0.01, speed 96.70 f/s, time 3.7 min\n",
            "25726: done 230 games, reward 161.560, eps 0.01, speed 99.50 f/s, time 3.8 min\n",
            "25791: done 231 games, reward 159.800, eps 0.01, speed 126.01 f/s, time 3.8 min\n",
            "25861: done 232 games, reward 159.800, eps 0.01, speed 130.34 f/s, time 3.8 min\n",
            "26234: done 233 games, reward 164.640, eps 0.01, speed 130.33 f/s, time 3.8 min\n",
            "26278: done 234 games, reward 163.320, eps 0.01, speed 129.07 f/s, time 3.8 min\n",
            "26319: done 235 games, reward 162.880, eps 0.01, speed 131.41 f/s, time 3.8 min\n",
            "26410: done 236 games, reward 161.560, eps 0.01, speed 129.92 f/s, time 3.9 min\n",
            "26468: done 237 games, reward 162.000, eps 0.01, speed 132.71 f/s, time 3.9 min\n",
            "26527: done 238 games, reward 162.000, eps 0.01, speed 130.05 f/s, time 3.9 min\n",
            "26715: done 239 games, reward 162.440, eps 0.01, speed 130.54 f/s, time 3.9 min\n",
            "26780: done 240 games, reward 160.680, eps 0.01, speed 132.57 f/s, time 3.9 min\n",
            "26849: done 241 games, reward 160.680, eps 0.01, speed 128.85 f/s, time 3.9 min\n",
            "26980: done 242 games, reward 161.120, eps 0.01, speed 130.72 f/s, time 3.9 min\n",
            "27038: done 243 games, reward 160.680, eps 0.01, speed 96.67 f/s, time 3.9 min\n",
            "27146: done 244 games, reward 161.120, eps 0.01, speed 96.78 f/s, time 4.0 min\n",
            "27336: done 245 games, reward 158.480, eps 0.01, speed 102.76 f/s, time 4.0 min\n",
            "27451: done 246 games, reward 160.680, eps 0.01, speed 129.11 f/s, time 4.0 min\n",
            "27505: done 247 games, reward 160.680, eps 0.01, speed 129.20 f/s, time 4.0 min\n",
            "27734: done 248 games, reward 159.360, eps 0.01, speed 130.47 f/s, time 4.0 min\n",
            "27809: done 249 games, reward 159.360, eps 0.01, speed 130.56 f/s, time 4.0 min\n",
            "27899: done 250 games, reward 160.240, eps 0.01, speed 132.39 f/s, time 4.1 min\n",
            "28032: done 251 games, reward 161.120, eps 0.01, speed 132.11 f/s, time 4.1 min\n",
            "28082: done 252 games, reward 159.800, eps 0.01, speed 129.88 f/s, time 4.1 min\n",
            "28141: done 253 games, reward 160.680, eps 0.01, speed 131.29 f/s, time 4.1 min\n",
            "28299: done 254 games, reward 157.560, eps 0.01, speed 127.14 f/s, time 4.1 min\n",
            "28383: done 255 games, reward 157.080, eps 0.01, speed 129.92 f/s, time 4.1 min\n",
            "28503: done 256 games, reward 157.440, eps 0.01, speed 130.51 f/s, time 4.1 min\n",
            "28604: done 257 games, reward 154.360, eps 0.01, speed 113.62 f/s, time 4.2 min\n",
            "28688: done 258 games, reward 152.600, eps 0.01, speed 98.13 f/s, time 4.2 min\n",
            "28740: done 259 games, reward 152.600, eps 0.01, speed 95.36 f/s, time 4.2 min\n",
            "28861: done 260 games, reward 150.840, eps 0.01, speed 95.03 f/s, time 4.2 min\n",
            "28936: done 261 games, reward 150.400, eps 0.01, speed 118.55 f/s, time 4.2 min\n",
            "28988: done 262 games, reward 149.960, eps 0.01, speed 130.06 f/s, time 4.2 min\n",
            "29110: done 263 games, reward 147.320, eps 0.01, speed 129.05 f/s, time 4.2 min\n",
            "29198: done 264 games, reward 149.080, eps 0.01, speed 128.46 f/s, time 4.2 min\n",
            "29354: done 265 games, reward 149.960, eps 0.01, speed 131.48 f/s, time 4.3 min\n",
            "29498: done 266 games, reward 149.080, eps 0.01, speed 130.52 f/s, time 4.3 min\n",
            "29546: done 267 games, reward 149.080, eps 0.01, speed 130.50 f/s, time 4.3 min\n",
            "29612: done 268 games, reward 148.640, eps 0.01, speed 126.00 f/s, time 4.3 min\n",
            "29733: done 269 games, reward 147.320, eps 0.01, speed 129.25 f/s, time 4.3 min\n",
            "29787: done 270 games, reward 146.880, eps 0.01, speed 130.98 f/s, time 4.3 min\n",
            "29838: done 271 games, reward 146.880, eps 0.01, speed 127.35 f/s, time 4.3 min\n",
            "29941: done 272 games, reward 147.320, eps 0.01, speed 131.79 f/s, time 4.3 min\n",
            "30012: done 273 games, reward 146.000, eps 0.01, speed 130.00 f/s, time 4.3 min\n",
            "30063: done 274 games, reward 145.560, eps 0.01, speed 131.20 f/s, time 4.4 min\n",
            "30224: done 275 games, reward 146.000, eps 0.01, speed 108.96 f/s, time 4.4 min\n",
            "30281: done 276 games, reward 146.000, eps 0.01, speed 95.59 f/s, time 4.4 min\n",
            "30365: done 277 games, reward 146.000, eps 0.01, speed 97.81 f/s, time 4.4 min\n",
            "30519: done 278 games, reward 147.760, eps 0.01, speed 110.72 f/s, time 4.4 min\n",
            "30590: done 279 games, reward 146.000, eps 0.01, speed 129.21 f/s, time 4.4 min\n",
            "30641: done 280 games, reward 144.680, eps 0.01, speed 131.04 f/s, time 4.4 min\n",
            "30762: done 281 games, reward 145.120, eps 0.01, speed 130.05 f/s, time 4.5 min\n",
            "30813: done 282 games, reward 144.680, eps 0.01, speed 131.40 f/s, time 4.5 min\n",
            "30898: done 283 games, reward 146.000, eps 0.01, speed 127.86 f/s, time 4.5 min\n",
            "31042: done 284 games, reward 145.120, eps 0.01, speed 130.19 f/s, time 4.5 min\n",
            "31092: done 285 games, reward 143.360, eps 0.01, speed 125.30 f/s, time 4.5 min\n",
            "31296: done 286 games, reward 146.440, eps 0.01, speed 132.55 f/s, time 4.5 min\n",
            "31403: done 287 games, reward 144.680, eps 0.01, speed 130.73 f/s, time 4.5 min\n",
            "31462: done 288 games, reward 143.800, eps 0.01, speed 132.38 f/s, time 4.5 min\n",
            "31521: done 289 games, reward 144.240, eps 0.01, speed 124.61 f/s, time 4.6 min\n",
            "31594: done 290 games, reward 142.480, eps 0.01, speed 130.47 f/s, time 4.6 min\n",
            "31721: done 291 games, reward 142.920, eps 0.01, speed 130.66 f/s, time 4.6 min\n",
            "31801: done 292 games, reward 143.800, eps 0.01, speed 97.55 f/s, time 4.6 min\n",
            "32132: done 293 games, reward 146.440, eps 0.01, speed 103.95 f/s, time 4.6 min\n",
            "32212: done 294 games, reward 146.920, eps 0.01, speed 124.83 f/s, time 4.7 min\n",
            "32252: done 295 games, reward 146.920, eps 0.01, speed 127.21 f/s, time 4.7 min\n",
            "32481: done 296 games, reward 144.280, eps 0.01, speed 129.89 f/s, time 4.7 min\n",
            "32532: done 297 games, reward 142.480, eps 0.01, speed 133.19 f/s, time 4.7 min\n",
            "32578: done 298 games, reward 142.480, eps 0.01, speed 129.85 f/s, time 4.7 min\n",
            "33017: done 299 games, reward 147.320, eps 0.01, speed 130.88 f/s, time 4.8 min\n",
            "33060: done 300 games, reward 145.120, eps 0.01, speed 131.36 f/s, time 4.8 min\n",
            "33154: done 301 games, reward 147.080, eps 0.01, speed 129.28 f/s, time 4.8 min\n",
            "33238: done 302 games, reward 143.600, eps 0.01, speed 130.11 f/s, time 4.8 min\n",
            "33352: done 303 games, reward 142.280, eps 0.01, speed 109.22 f/s, time 4.8 min\n",
            "33472: done 304 games, reward 141.720, eps 0.01, speed 96.16 f/s, time 4.8 min\n",
            "33571: done 305 games, reward 137.760, eps 0.01, speed 94.48 f/s, time 4.8 min\n",
            "33748: done 306 games, reward 140.400, eps 0.01, speed 123.04 f/s, time 4.9 min\n",
            "33818: done 307 games, reward 139.920, eps 0.01, speed 131.96 f/s, time 4.9 min\n",
            "33872: done 308 games, reward 136.400, eps 0.01, speed 125.65 f/s, time 4.9 min\n",
            "33994: done 309 games, reward 135.080, eps 0.01, speed 129.88 f/s, time 4.9 min\n",
            "34184: done 310 games, reward 137.560, eps 0.01, speed 131.69 f/s, time 4.9 min\n",
            "34335: done 311 games, reward 136.720, eps 0.01, speed 130.57 f/s, time 4.9 min\n",
            "34587: done 312 games, reward 139.360, eps 0.01, speed 131.20 f/s, time 5.0 min\n",
            "34651: done 313 games, reward 138.040, eps 0.01, speed 131.39 f/s, time 5.0 min\n",
            "34746: done 314 games, reward 136.720, eps 0.01, speed 128.03 f/s, time 5.0 min\n",
            "34982: done 315 games, reward 138.040, eps 0.01, speed 114.11 f/s, time 5.0 min\n",
            "35104: done 316 games, reward 138.920, eps 0.01, speed 94.15 f/s, time 5.0 min\n",
            "35202: done 317 games, reward 140.240, eps 0.01, speed 98.94 f/s, time 5.1 min\n",
            "35268: done 318 games, reward 140.680, eps 0.01, speed 125.93 f/s, time 5.1 min\n",
            "35327: done 319 games, reward 139.800, eps 0.01, speed 131.18 f/s, time 5.1 min\n",
            "35379: done 320 games, reward 139.360, eps 0.01, speed 127.66 f/s, time 5.1 min\n",
            "35543: done 321 games, reward 138.920, eps 0.01, speed 128.82 f/s, time 5.1 min\n",
            "35640: done 322 games, reward 138.480, eps 0.01, speed 129.29 f/s, time 5.1 min\n",
            "35944: done 323 games, reward 141.720, eps 0.01, speed 131.64 f/s, time 5.2 min\n",
            "36289: done 324 games, reward 146.560, eps 0.01, speed 130.13 f/s, time 5.2 min\n",
            "36354: done 325 games, reward 144.800, eps 0.01, speed 129.07 f/s, time 5.2 min\n",
            "36394: done 326 games, reward 143.920, eps 0.01, speed 122.06 f/s, time 5.2 min\n",
            "36521: done 327 games, reward 143.480, eps 0.01, speed 111.18 f/s, time 5.2 min\n",
            "36575: done 328 games, reward 142.600, eps 0.01, speed 97.82 f/s, time 5.2 min\n",
            "36626: done 329 games, reward 139.960, eps 0.01, speed 94.90 f/s, time 5.3 min\n",
            "36803: done 330 games, reward 139.520, eps 0.01, speed 100.83 f/s, time 5.3 min\n",
            "36887: done 331 games, reward 138.640, eps 0.01, speed 127.12 f/s, time 5.3 min\n",
            "36946: done 332 games, reward 138.640, eps 0.01, speed 129.33 f/s, time 5.3 min\n",
            "37154: done 333 games, reward 133.800, eps 0.01, speed 129.04 f/s, time 5.3 min\n",
            "37241: done 334 games, reward 134.680, eps 0.01, speed 131.82 f/s, time 5.3 min\n",
            "37385: done 335 games, reward 137.320, eps 0.01, speed 130.18 f/s, time 5.4 min\n",
            "37530: done 336 games, reward 136.440, eps 0.01, speed 131.82 f/s, time 5.4 min\n",
            "37826: done 337 games, reward 139.960, eps 0.01, speed 129.51 f/s, time 5.4 min\n",
            "37881: done 338 games, reward 139.960, eps 0.01, speed 129.27 f/s, time 5.4 min\n",
            "38140: done 339 games, reward 140.400, eps 0.01, speed 115.35 f/s, time 5.5 min\n",
            "38187: done 340 games, reward 140.400, eps 0.01, speed 89.99 f/s, time 5.5 min\n",
            "38330: done 341 games, reward 141.280, eps 0.01, speed 94.60 f/s, time 5.5 min\n",
            "38541: done 342 games, reward 139.960, eps 0.01, speed 126.75 f/s, time 5.5 min\n",
            "38702: done 343 games, reward 141.720, eps 0.01, speed 131.17 f/s, time 5.5 min\n",
            "38822: done 344 games, reward 142.600, eps 0.01, speed 105.92 f/s, time 5.6 min\n",
            "38950: done 345 games, reward 141.280, eps 0.01, speed 55.43 f/s, time 5.6 min\n",
            "39101: done 346 games, reward 142.160, eps 0.01, speed 63.45 f/s, time 5.6 min\n",
            "39326: done 347 games, reward 144.360, eps 0.01, speed 100.32 f/s, time 5.7 min\n",
            "39477: done 348 games, reward 141.720, eps 0.01, speed 94.55 f/s, time 5.7 min\n",
            "39528: done 349 games, reward 141.280, eps 0.01, speed 96.29 f/s, time 5.7 min\n",
            "39619: done 350 games, reward 141.280, eps 0.01, speed 125.23 f/s, time 5.7 min\n",
            "39800: done 351 games, reward 140.400, eps 0.01, speed 128.28 f/s, time 5.7 min\n",
            "39851: done 352 games, reward 140.400, eps 0.01, speed 129.10 f/s, time 5.8 min\n",
            "39904: done 353 games, reward 139.960, eps 0.01, speed 130.63 f/s, time 5.8 min\n",
            "40241: done 354 games, reward 139.960, eps 0.01, speed 130.19 f/s, time 5.8 min\n",
            "40352: done 355 games, reward 141.280, eps 0.01, speed 130.12 f/s, time 5.8 min\n",
            "40401: done 356 games, reward 140.400, eps 0.01, speed 131.42 f/s, time 5.8 min\n",
            "40535: done 357 games, reward 141.720, eps 0.01, speed 130.25 f/s, time 5.8 min\n",
            "40613: done 358 games, reward 141.280, eps 0.01, speed 128.51 f/s, time 5.9 min\n",
            "40819: done 359 games, reward 144.800, eps 0.01, speed 128.67 f/s, time 5.9 min\n",
            "41088: done 360 games, reward 147.440, eps 0.01, speed 94.28 f/s, time 5.9 min\n",
            "41219: done 361 games, reward 148.760, eps 0.01, speed 124.72 f/s, time 5.9 min\n",
            "41301: done 362 games, reward 150.080, eps 0.01, speed 130.34 f/s, time 6.0 min\n",
            "41479: done 363 games, reward 150.960, eps 0.01, speed 129.57 f/s, time 6.0 min\n",
            "41529: done 364 games, reward 149.200, eps 0.01, speed 130.24 f/s, time 6.0 min\n",
            "41635: done 365 games, reward 148.320, eps 0.01, speed 127.18 f/s, time 6.0 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41796: done 366 games, reward 147.880, eps 0.01, speed 123.50 f/s, time 6.0 min\n",
            "41981: done 367 games, reward 151.400, eps 0.01, speed 124.32 f/s, time 6.0 min\n",
            "42034: done 368 games, reward 150.960, eps 0.01, speed 129.08 f/s, time 6.1 min\n",
            "42128: done 369 games, reward 151.840, eps 0.01, speed 129.96 f/s, time 6.1 min\n",
            "42239: done 370 games, reward 152.280, eps 0.01, speed 126.15 f/s, time 6.1 min\n",
            "42362: done 371 games, reward 155.360, eps 0.01, speed 128.82 f/s, time 6.1 min\n",
            "42480: done 372 games, reward 155.360, eps 0.01, speed 95.71 f/s, time 6.1 min\n",
            "42567: done 373 games, reward 155.800, eps 0.01, speed 95.86 f/s, time 6.1 min\n",
            "42793: done 374 games, reward 159.320, eps 0.01, speed 107.77 f/s, time 6.2 min\n",
            "42922: done 375 games, reward 159.760, eps 0.01, speed 127.73 f/s, time 6.2 min\n",
            "43068: done 376 games, reward 160.640, eps 0.01, speed 129.35 f/s, time 6.2 min\n",
            "43134: done 377 games, reward 161.080, eps 0.01, speed 123.21 f/s, time 6.2 min\n",
            "43286: done 378 games, reward 158.880, eps 0.01, speed 129.08 f/s, time 6.2 min\n",
            "43359: done 379 games, reward 158.880, eps 0.01, speed 127.99 f/s, time 6.2 min\n",
            "43540: done 380 games, reward 160.200, eps 0.01, speed 127.70 f/s, time 6.3 min\n",
            "43814: done 381 games, reward 160.640, eps 0.01, speed 130.17 f/s, time 6.3 min\n",
            "43854: done 382 games, reward 160.200, eps 0.01, speed 122.95 f/s, time 6.3 min\n",
            "43961: done 383 games, reward 160.640, eps 0.01, speed 118.56 f/s, time 6.3 min\n",
            "44079: done 384 games, reward 160.640, eps 0.01, speed 96.78 f/s, time 6.3 min\n",
            "44143: done 385 games, reward 161.520, eps 0.01, speed 98.27 f/s, time 6.3 min\n",
            "44255: done 386 games, reward 158.440, eps 0.01, speed 96.92 f/s, time 6.4 min\n",
            "44524: done 387 games, reward 162.840, eps 0.01, speed 128.40 f/s, time 6.4 min\n",
            "44574: done 388 games, reward 162.840, eps 0.01, speed 126.67 f/s, time 6.4 min\n",
            "44644: done 389 games, reward 162.840, eps 0.01, speed 128.02 f/s, time 6.4 min\n",
            "44917: done 390 games, reward 166.360, eps 0.01, speed 129.06 f/s, time 6.5 min\n",
            "44989: done 391 games, reward 164.160, eps 0.01, speed 130.92 f/s, time 6.5 min\n",
            "45188: done 392 games, reward 165.520, eps 0.01, speed 131.14 f/s, time 6.5 min\n",
            "45318: done 393 games, reward 162.440, eps 0.01, speed 128.15 f/s, time 6.5 min\n",
            "45487: done 394 games, reward 164.600, eps 0.01, speed 129.63 f/s, time 6.5 min\n",
            "45592: done 395 games, reward 165.040, eps 0.01, speed 101.66 f/s, time 6.5 min\n",
            "45770: done 396 games, reward 164.160, eps 0.01, speed 94.04 f/s, time 6.6 min\n",
            "45851: done 397 games, reward 165.040, eps 0.01, speed 107.44 f/s, time 6.6 min\n",
            "45905: done 398 games, reward 165.480, eps 0.01, speed 79.42 f/s, time 6.6 min\n",
            "46045: done 399 games, reward 161.520, eps 0.01, speed 95.68 f/s, time 6.6 min\n",
            "46220: done 400 games, reward 164.600, eps 0.01, speed 117.84 f/s, time 6.6 min\n",
            "46267: done 401 games, reward 162.200, eps 0.01, speed 125.57 f/s, time 6.7 min\n",
            "46661: done 402 games, reward 165.240, eps 0.01, speed 129.73 f/s, time 6.7 min\n",
            "46821: done 403 games, reward 166.120, eps 0.01, speed 130.10 f/s, time 6.7 min\n",
            "46937: done 404 games, reward 165.240, eps 0.01, speed 129.00 f/s, time 6.7 min\n",
            "47128: done 405 games, reward 166.120, eps 0.01, speed 101.63 f/s, time 6.8 min\n",
            "47222: done 406 games, reward 164.360, eps 0.01, speed 96.96 f/s, time 6.8 min\n",
            "47368: done 407 games, reward 165.240, eps 0.01, speed 107.03 f/s, time 6.8 min\n",
            "47616: done 408 games, reward 166.560, eps 0.01, speed 128.89 f/s, time 6.8 min\n",
            "47838: done 409 games, reward 169.200, eps 0.01, speed 129.70 f/s, time 6.9 min\n",
            "47890: done 410 games, reward 165.240, eps 0.01, speed 128.53 f/s, time 6.9 min\n",
            "48037: done 411 games, reward 166.520, eps 0.01, speed 132.10 f/s, time 6.9 min\n",
            "48184: done 412 games, reward 163.440, eps 0.01, speed 129.87 f/s, time 6.9 min\n",
            "48244: done 413 games, reward 163.880, eps 0.01, speed 129.09 f/s, time 6.9 min\n",
            "48311: done 414 games, reward 163.440, eps 0.01, speed 128.20 f/s, time 6.9 min\n",
            "48481: done 415 games, reward 162.120, eps 0.01, speed 129.67 f/s, time 7.0 min\n",
            "48566: done 416 games, reward 161.680, eps 0.01, speed 127.91 f/s, time 7.0 min\n",
            "48722: done 417 games, reward 162.560, eps 0.01, speed 96.06 f/s, time 7.0 min\n",
            "49025: done 418 games, reward 164.320, eps 0.01, speed 109.99 f/s, time 7.0 min\n",
            "49093: done 419 games, reward 164.320, eps 0.01, speed 131.11 f/s, time 7.0 min\n",
            "49256: done 420 games, reward 166.960, eps 0.01, speed 129.94 f/s, time 7.1 min\n",
            "49424: done 421 games, reward 167.400, eps 0.01, speed 129.39 f/s, time 7.1 min\n",
            "49523: done 422 games, reward 168.720, eps 0.01, speed 130.26 f/s, time 7.1 min\n",
            "49721: done 423 games, reward 165.040, eps 0.01, speed 129.61 f/s, time 7.1 min\n",
            "49890: done 424 games, reward 160.200, eps 0.01, speed 130.59 f/s, time 7.1 min\n",
            "49940: done 425 games, reward 160.640, eps 0.01, speed 126.29 f/s, time 7.2 min\n",
            "50005: done 426 games, reward 161.080, eps 0.01, speed 130.31 f/s, time 7.2 min\n",
            "50148: done 427 games, reward 160.640, eps 0.01, speed 129.31 f/s, time 7.2 min\n",
            "50215: done 428 games, reward 160.640, eps 0.01, speed 93.18 f/s, time 7.2 min\n",
            "50397: done 429 games, reward 162.400, eps 0.01, speed 93.78 f/s, time 7.2 min\n",
            "50808: done 430 games, reward 165.480, eps 0.01, speed 122.80 f/s, time 7.3 min\n",
            "50857: done 431 games, reward 165.480, eps 0.01, speed 130.19 f/s, time 7.3 min\n",
            "50925: done 432 games, reward 166.360, eps 0.01, speed 126.04 f/s, time 7.3 min\n",
            "51077: done 433 games, reward 167.240, eps 0.01, speed 129.44 f/s, time 7.3 min\n",
            "51126: done 434 games, reward 167.240, eps 0.01, speed 128.69 f/s, time 7.3 min\n",
            "51342: done 435 games, reward 167.680, eps 0.01, speed 130.40 f/s, time 7.4 min\n",
            "51534: done 436 games, reward 168.560, eps 0.01, speed 129.36 f/s, time 7.4 min\n",
            "51698: done 437 games, reward 167.240, eps 0.01, speed 128.40 f/s, time 7.4 min\n",
            "51814: done 438 games, reward 167.680, eps 0.01, speed 99.26 f/s, time 7.4 min\n",
            "51981: done 439 games, reward 163.720, eps 0.01, speed 95.56 f/s, time 7.4 min\n",
            "52196: done 440 games, reward 165.480, eps 0.01, speed 122.57 f/s, time 7.5 min\n",
            "52263: done 441 games, reward 165.040, eps 0.01, speed 127.03 f/s, time 7.5 min\n",
            "52474: done 442 games, reward 165.920, eps 0.01, speed 128.13 f/s, time 7.5 min\n",
            "52742: done 443 games, reward 169.000, eps 0.01, speed 130.00 f/s, time 7.5 min\n",
            "52874: done 444 games, reward 168.200, eps 0.01, speed 129.41 f/s, time 7.6 min\n",
            "53014: done 445 games, reward 168.200, eps 0.01, speed 129.68 f/s, time 7.6 min\n",
            "53066: done 446 games, reward 165.560, eps 0.01, speed 128.21 f/s, time 7.6 min\n",
            "53278: done 447 games, reward 165.560, eps 0.01, speed 131.49 f/s, time 7.6 min\n",
            "53489: done 448 games, reward 165.120, eps 0.01, speed 96.17 f/s, time 7.7 min\n",
            "53571: done 449 games, reward 166.440, eps 0.01, speed 92.19 f/s, time 7.7 min\n",
            "53860: done 450 games, reward 169.080, eps 0.01, speed 128.98 f/s, time 7.7 min\n",
            "53961: done 451 games, reward 169.080, eps 0.01, speed 129.05 f/s, time 7.7 min\n",
            "54204: done 452 games, reward 172.600, eps 0.01, speed 130.06 f/s, time 7.7 min\n",
            "54416: done 453 games, reward 174.360, eps 0.01, speed 131.60 f/s, time 7.8 min\n",
            "54530: done 454 games, reward 172.160, eps 0.01, speed 128.70 f/s, time 7.8 min\n",
            "54611: done 455 games, reward 171.720, eps 0.01, speed 119.86 f/s, time 7.8 min\n",
            "54734: done 456 games, reward 172.600, eps 0.01, speed 131.87 f/s, time 7.8 min\n",
            "54912: done 457 games, reward 171.720, eps 0.01, speed 120.94 f/s, time 7.8 min\n",
            "55133: done 458 games, reward 173.480, eps 0.01, speed 95.91 f/s, time 7.9 min\n",
            "55211: done 459 games, reward 170.840, eps 0.01, speed 111.65 f/s, time 7.9 min\n",
            "55348: done 460 games, reward 168.640, eps 0.01, speed 129.15 f/s, time 7.9 min\n",
            "55399: done 461 games, reward 166.880, eps 0.01, speed 131.39 f/s, time 7.9 min\n",
            "55451: done 462 games, reward 165.560, eps 0.01, speed 125.68 f/s, time 7.9 min\n",
            "55636: done 463 games, reward 164.680, eps 0.01, speed 130.65 f/s, time 7.9 min\n",
            "55806: done 464 games, reward 166.440, eps 0.01, speed 130.04 f/s, time 8.0 min\n",
            "56016: done 465 games, reward 168.640, eps 0.01, speed 129.28 f/s, time 8.0 min\n",
            "56353: done 466 games, reward 173.040, eps 0.01, speed 130.12 f/s, time 8.0 min\n",
            "56412: done 467 games, reward 169.960, eps 0.01, speed 127.74 f/s, time 8.0 min\n",
            "56492: done 468 games, reward 170.840, eps 0.01, speed 109.52 f/s, time 8.1 min\n",
            "56683: done 469 games, reward 170.840, eps 0.01, speed 97.94 f/s, time 8.1 min\n",
            "56765: done 470 games, reward 170.400, eps 0.01, speed 97.53 f/s, time 8.1 min\n",
            "56866: done 471 games, reward 168.640, eps 0.01, speed 127.63 f/s, time 8.1 min\n",
            "57057: done 472 games, reward 169.080, eps 0.01, speed 128.08 f/s, time 8.1 min\n",
            "57244: done 473 games, reward 170.840, eps 0.01, speed 129.68 f/s, time 8.2 min\n",
            "57296: done 474 games, reward 167.320, eps 0.01, speed 128.73 f/s, time 8.2 min\n",
            "57424: done 475 games, reward 166.000, eps 0.01, speed 130.43 f/s, time 8.2 min\n",
            "57508: done 476 games, reward 164.680, eps 0.01, speed 130.73 f/s, time 8.2 min\n",
            "57658: done 477 games, reward 166.880, eps 0.01, speed 127.80 f/s, time 8.2 min\n",
            "57812: done 478 games, reward 167.320, eps 0.01, speed 129.30 f/s, time 8.2 min\n",
            "57941: done 479 games, reward 169.960, eps 0.01, speed 130.61 f/s, time 8.3 min\n",
            "58043: done 480 games, reward 169.520, eps 0.01, speed 122.63 f/s, time 8.3 min\n",
            "58231: done 481 games, reward 169.520, eps 0.01, speed 88.28 f/s, time 8.3 min\n",
            "58534: done 482 games, reward 173.480, eps 0.01, speed 86.88 f/s, time 8.4 min\n",
            "58601: done 483 games, reward 171.720, eps 0.01, speed 124.81 f/s, time 8.4 min\n",
            "58903: done 484 games, reward 173.040, eps 0.01, speed 128.69 f/s, time 8.4 min\n",
            "58972: done 485 games, reward 173.040, eps 0.01, speed 129.01 f/s, time 8.4 min\n",
            "59080: done 486 games, reward 173.920, eps 0.01, speed 128.58 f/s, time 8.4 min\n",
            "59265: done 487 games, reward 169.520, eps 0.01, speed 130.66 f/s, time 8.5 min\n",
            "59316: done 488 games, reward 169.520, eps 0.01, speed 128.23 f/s, time 8.5 min\n",
            "59516: done 489 games, reward 171.720, eps 0.01, speed 129.06 f/s, time 8.5 min\n",
            "59745: done 490 games, reward 167.760, eps 0.01, speed 114.32 f/s, time 8.5 min\n",
            "59795: done 491 games, reward 168.200, eps 0.01, speed 90.78 f/s, time 8.5 min\n",
            "60242: done 492 games, reward 171.240, eps 0.01, speed 114.51 f/s, time 8.6 min\n",
            "60706: done 493 games, reward 173.440, eps 0.01, speed 128.98 f/s, time 8.7 min\n",
            "60787: done 494 games, reward 171.680, eps 0.01, speed 130.51 f/s, time 8.7 min\n",
            "60897: done 495 games, reward 172.680, eps 0.01, speed 129.95 f/s, time 8.7 min\n",
            "61079: done 496 games, reward 174.000, eps 0.01, speed 130.03 f/s, time 8.7 min\n",
            "61212: done 497 games, reward 173.560, eps 0.01, speed 130.80 f/s, time 8.7 min\n",
            "61315: done 498 games, reward 174.880, eps 0.01, speed 99.82 f/s, time 8.7 min\n",
            "61538: done 499 games, reward 173.560, eps 0.01, speed 96.77 f/s, time 8.8 min\n",
            "61589: done 500 games, reward 170.480, eps 0.01, speed 129.21 f/s, time 8.8 min\n",
            "61828: done 501 games, reward 173.560, eps 0.01, speed 127.52 f/s, time 8.8 min\n",
            "62208: done 502 games, reward 174.440, eps 0.01, speed 130.07 f/s, time 8.9 min\n",
            "62259: done 503 games, reward 172.240, eps 0.01, speed 130.25 f/s, time 8.9 min\n",
            "62367: done 504 games, reward 173.560, eps 0.01, speed 129.76 f/s, time 8.9 min\n",
            "62566: done 505 games, reward 174.440, eps 0.01, speed 132.21 f/s, time 8.9 min\n",
            "62830: done 506 games, reward 177.080, eps 0.01, speed 128.40 f/s, time 8.9 min\n",
            "62919: done 507 games, reward 175.840, eps 0.01, speed 97.85 f/s, time 9.0 min\n",
            "63100: done 508 games, reward 176.720, eps 0.01, speed 94.53 f/s, time 9.0 min\n",
            "63153: done 509 games, reward 172.760, eps 0.01, speed 121.25 f/s, time 9.0 min\n",
            "63298: done 510 games, reward 174.960, eps 0.01, speed 130.75 f/s, time 9.0 min\n",
            "63548: done 511 games, reward 174.080, eps 0.01, speed 129.33 f/s, time 9.0 min\n",
            "63912: done 512 games, reward 178.480, eps 0.01, speed 130.36 f/s, time 9.1 min\n",
            "63963: done 513 games, reward 178.040, eps 0.01, speed 126.54 f/s, time 9.1 min\n",
            "64100: done 514 games, reward 178.040, eps 0.01, speed 129.38 f/s, time 9.1 min\n",
            "64194: done 515 games, reward 177.600, eps 0.01, speed 126.34 f/s, time 9.1 min\n",
            "64233: done 516 games, reward 176.720, eps 0.01, speed 124.50 f/s, time 9.1 min\n",
            "64441: done 517 games, reward 175.840, eps 0.01, speed 121.26 f/s, time 9.2 min\n",
            "64627: done 518 games, reward 175.400, eps 0.01, speed 95.76 f/s, time 9.2 min\n",
            "64679: done 519 games, reward 175.400, eps 0.01, speed 88.80 f/s, time 9.2 min\n",
            "64823: done 520 games, reward 174.520, eps 0.01, speed 127.73 f/s, time 9.2 min\n",
            "65153: done 521 games, reward 176.280, eps 0.01, speed 130.50 f/s, time 9.3 min\n",
            "65340: done 522 games, reward 175.040, eps 0.01, speed 127.77 f/s, time 9.3 min\n",
            "65575: done 523 games, reward 174.600, eps 0.01, speed 129.62 f/s, time 9.3 min\n",
            "65708: done 524 games, reward 175.040, eps 0.01, speed 129.96 f/s, time 9.3 min\n",
            "65964: done 525 games, reward 178.120, eps 0.01, speed 130.15 f/s, time 9.4 min\n",
            "66332: done 526 games, reward 180.760, eps 0.01, speed 100.19 f/s, time 9.4 min\n",
            "66382: done 527 games, reward 179.440, eps 0.01, speed 130.23 f/s, time 9.4 min\n",
            "66530: done 528 games, reward 180.760, eps 0.01, speed 129.95 f/s, time 9.5 min\n",
            "66907: done 529 games, reward 182.520, eps 0.01, speed 129.47 f/s, time 9.5 min\n",
            "67131: done 530 games, reward 179.880, eps 0.01, speed 129.71 f/s, time 9.5 min\n",
            "67242: done 531 games, reward 181.320, eps 0.01, speed 128.26 f/s, time 9.6 min\n",
            "67399: done 532 games, reward 182.200, eps 0.01, speed 130.27 f/s, time 9.6 min\n",
            "67530: done 533 games, reward 181.320, eps 0.01, speed 125.10 f/s, time 9.6 min\n",
            "67770: done 534 games, reward 183.520, eps 0.01, speed 95.67 f/s, time 9.6 min\n",
            "68139: done 535 games, reward 184.400, eps 0.01, speed 119.94 f/s, time 9.7 min\n",
            "68221: done 536 games, reward 183.080, eps 0.01, speed 128.18 f/s, time 9.7 min\n",
            "68442: done 537 games, reward 182.640, eps 0.01, speed 130.65 f/s, time 9.7 min\n",
            "68797: done 538 games, reward 183.960, eps 0.01, speed 129.73 f/s, time 9.8 min\n",
            "68923: done 539 games, reward 183.520, eps 0.01, speed 130.33 f/s, time 9.8 min\n",
            "69153: done 540 games, reward 184.400, eps 0.01, speed 121.25 f/s, time 9.8 min\n",
            "69436: done 541 games, reward 189.240, eps 0.01, speed 98.20 f/s, time 9.9 min\n",
            "69484: done 542 games, reward 187.920, eps 0.01, speed 124.65 f/s, time 9.9 min\n",
            "69874: done 543 games, reward 183.520, eps 0.01, speed 132.49 f/s, time 9.9 min\n",
            "70234: done 544 games, reward 186.080, eps 0.01, speed 130.51 f/s, time 10.0 min\n",
            "70284: done 545 games, reward 185.200, eps 0.01, speed 127.27 f/s, time 10.0 min\n",
            "70593: done 546 games, reward 187.400, eps 0.01, speed 130.93 f/s, time 10.0 min\n",
            "70790: done 547 games, reward 186.520, eps 0.01, speed 114.22 f/s, time 10.0 min\n",
            "70948: done 548 games, reward 186.960, eps 0.01, speed 96.41 f/s, time 10.1 min\n",
            "71034: done 549 games, reward 186.080, eps 0.01, speed 101.34 f/s, time 10.1 min\n",
            "71282: done 550 games, reward 183.880, eps 0.01, speed 130.36 f/s, time 10.1 min\n",
            "71411: done 551 games, reward 185.200, eps 0.01, speed 129.79 f/s, time 10.1 min\n",
            "71487: done 552 games, reward 181.680, eps 0.01, speed 125.75 f/s, time 10.1 min\n",
            "71581: done 553 games, reward 180.800, eps 0.01, speed 128.66 f/s, time 10.2 min\n",
            "71766: done 554 games, reward 179.920, eps 0.01, speed 129.44 f/s, time 10.2 min\n",
            "72029: done 555 games, reward 181.680, eps 0.01, speed 130.05 f/s, time 10.2 min\n",
            "72639: done 556 games, reward 186.960, eps 0.01, speed 110.53 f/s, time 10.3 min\n",
            "72807: done 557 games, reward 187.080, eps 0.01, speed 127.83 f/s, time 10.3 min\n",
            "72950: done 558 games, reward 186.800, eps 0.01, speed 128.21 f/s, time 10.3 min\n",
            "73189: done 559 games, reward 187.680, eps 0.01, speed 127.00 f/s, time 10.4 min\n",
            "73351: done 560 games, reward 188.120, eps 0.01, speed 130.21 f/s, time 10.4 min\n",
            "73813: done 561 games, reward 191.200, eps 0.01, speed 131.89 f/s, time 10.5 min\n",
            "74146: done 562 games, reward 195.160, eps 0.01, speed 98.18 f/s, time 10.5 min\n",
            "74197: done 563 games, reward 194.280, eps 0.01, speed 119.67 f/s, time 10.5 min\n",
            "74298: done 564 games, reward 193.840, eps 0.01, speed 125.92 f/s, time 10.5 min\n",
            "74476: done 565 games, reward 192.960, eps 0.01, speed 130.71 f/s, time 10.6 min\n",
            "74713: done 566 games, reward 192.520, eps 0.01, speed 129.38 f/s, time 10.6 min\n",
            "74831: done 567 games, reward 192.080, eps 0.01, speed 128.16 f/s, time 10.6 min\n",
            "75102: done 568 games, reward 192.080, eps 0.01, speed 129.05 f/s, time 10.6 min\n",
            "75314: done 569 games, reward 192.520, eps 0.01, speed 129.36 f/s, time 10.7 min\n",
            "75352: done 570 games, reward 192.080, eps 0.01, speed 124.76 f/s, time 10.7 min\n",
            "75734: done 571 games, reward 194.280, eps 0.01, speed 100.26 f/s, time 10.7 min\n",
            "75808: done 572 games, reward 192.960, eps 0.01, speed 123.60 f/s, time 10.7 min\n",
            "76025: done 573 games, reward 192.520, eps 0.01, speed 130.01 f/s, time 10.8 min\n",
            "76416: done 574 games, reward 195.160, eps 0.01, speed 130.30 f/s, time 10.8 min\n",
            "76569: done 575 games, reward 195.600, eps 0.01, speed 129.55 f/s, time 10.8 min\n",
            "76728: done 576 games, reward 197.360, eps 0.01, speed 128.07 f/s, time 10.9 min\n",
            "76923: done 577 games, reward 196.040, eps 0.01, speed 130.04 f/s, time 10.9 min\n",
            "77085: done 578 games, reward 197.360, eps 0.01, speed 112.14 f/s, time 10.9 min\n",
            "77156: done 579 games, reward 196.040, eps 0.01, speed 94.95 f/s, time 10.9 min\n",
            "77567: done 580 games, reward 197.800, eps 0.01, speed 113.74 f/s, time 11.0 min\n",
            "77652: done 581 games, reward 195.600, eps 0.01, speed 129.23 f/s, time 11.0 min\n",
            "77857: done 582 games, reward 194.280, eps 0.01, speed 128.40 f/s, time 11.0 min\n",
            "78176: done 583 games, reward 199.120, eps 0.01, speed 129.51 f/s, time 11.1 min\n",
            "78240: done 584 games, reward 196.480, eps 0.01, speed 127.96 f/s, time 11.1 min\n",
            "78361: done 585 games, reward 196.480, eps 0.01, speed 129.89 f/s, time 11.1 min\n",
            "78735: done 586 games, reward 201.320, eps 0.01, speed 113.72 f/s, time 11.1 min\n",
            "78819: done 587 games, reward 201.400, eps 0.01, speed 97.34 f/s, time 11.2 min\n",
            "78919: done 588 games, reward 202.880, eps 0.01, speed 99.24 f/s, time 11.2 min\n",
            "79057: done 589 games, reward 201.560, eps 0.01, speed 127.24 f/s, time 11.2 min\n",
            "79108: done 590 games, reward 200.680, eps 0.01, speed 124.60 f/s, time 11.2 min\n",
            "79213: done 591 games, reward 202.000, eps 0.01, speed 126.28 f/s, time 11.2 min\n",
            "79380: done 592 games, reward 198.480, eps 0.01, speed 126.00 f/s, time 11.2 min\n",
            "79542: done 593 games, reward 196.280, eps 0.01, speed 126.14 f/s, time 11.2 min\n",
            "79716: done 594 games, reward 196.720, eps 0.01, speed 127.85 f/s, time 11.3 min\n",
            "79847: done 595 games, reward 197.040, eps 0.01, speed 126.27 f/s, time 11.3 min\n",
            "79902: done 596 games, reward 195.280, eps 0.01, speed 128.30 f/s, time 11.3 min\n",
            "79954: done 597 games, reward 194.840, eps 0.01, speed 126.42 f/s, time 11.3 min\n",
            "80243: done 598 games, reward 197.040, eps 0.01, speed 113.02 f/s, time 11.3 min\n",
            "80306: done 599 games, reward 197.040, eps 0.01, speed 93.13 f/s, time 11.4 min\n",
            "80371: done 600 games, reward 198.360, eps 0.01, speed 93.48 f/s, time 11.4 min\n",
            "80489: done 601 games, reward 197.480, eps 0.01, speed 101.30 f/s, time 11.4 min\n",
            "80548: done 602 games, reward 193.520, eps 0.01, speed 122.10 f/s, time 11.4 min\n",
            "80604: done 603 games, reward 193.520, eps 0.01, speed 126.68 f/s, time 11.4 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80883: done 604 games, reward 195.280, eps 0.01, speed 121.58 f/s, time 11.4 min\n",
            "80950: done 605 games, reward 193.520, eps 0.01, speed 127.74 f/s, time 11.5 min\n",
            "81007: done 606 games, reward 189.560, eps 0.01, speed 128.90 f/s, time 11.5 min\n",
            "81069: done 607 games, reward 189.480, eps 0.01, speed 127.05 f/s, time 11.5 min\n",
            "81204: done 608 games, reward 189.040, eps 0.01, speed 128.82 f/s, time 11.5 min\n",
            "81258: done 609 games, reward 188.600, eps 0.01, speed 129.29 f/s, time 11.5 min\n",
            "81317: done 610 games, reward 186.400, eps 0.01, speed 126.32 f/s, time 11.5 min\n",
            "81499: done 611 games, reward 188.160, eps 0.01, speed 128.75 f/s, time 11.5 min\n",
            "81654: done 612 games, reward 185.960, eps 0.01, speed 128.40 f/s, time 11.5 min\n",
            "81809: done 613 games, reward 186.840, eps 0.01, speed 101.25 f/s, time 11.6 min\n",
            "82010: done 614 games, reward 188.160, eps 0.01, speed 97.34 f/s, time 11.6 min\n",
            "82188: done 615 games, reward 188.600, eps 0.01, speed 127.25 f/s, time 11.6 min\n",
            "82328: done 616 games, reward 190.360, eps 0.01, speed 126.61 f/s, time 11.6 min\n",
            "82749: done 617 games, reward 195.200, eps 0.01, speed 131.00 f/s, time 11.7 min\n",
            "82981: done 618 games, reward 193.000, eps 0.01, speed 130.91 f/s, time 11.7 min\n",
            "83024: done 619 games, reward 192.560, eps 0.01, speed 129.62 f/s, time 11.7 min\n",
            "83340: done 620 games, reward 196.520, eps 0.01, speed 120.04 f/s, time 11.8 min\n",
            "83631: done 621 games, reward 192.560, eps 0.01, speed 98.63 f/s, time 11.8 min\n",
            "83674: done 622 games, reward 191.600, eps 0.01, speed 124.15 f/s, time 11.8 min\n",
            "84085: done 623 games, reward 195.560, eps 0.01, speed 129.91 f/s, time 11.9 min\n",
            "84191: done 624 games, reward 194.680, eps 0.01, speed 130.34 f/s, time 11.9 min\n",
            "84517: done 625 games, reward 191.160, eps 0.01, speed 129.34 f/s, time 11.9 min\n",
            "84740: done 626 games, reward 189.840, eps 0.01, speed 130.11 f/s, time 12.0 min\n",
            "84844: done 627 games, reward 190.720, eps 0.01, speed 130.62 f/s, time 12.0 min\n",
            "85292: done 628 games, reward 193.400, eps 0.01, speed 104.47 f/s, time 12.1 min\n",
            "85443: done 629 games, reward 191.200, eps 0.01, speed 128.69 f/s, time 12.1 min\n",
            "85516: done 630 games, reward 188.560, eps 0.01, speed 128.48 f/s, time 12.1 min\n",
            "85595: done 631 games, reward 188.440, eps 0.01, speed 128.76 f/s, time 12.1 min\n",
            "86107: done 632 games, reward 193.760, eps 0.01, speed 130.36 f/s, time 12.2 min\n",
            "86187: done 633 games, reward 193.440, eps 0.01, speed 127.44 f/s, time 12.2 min\n",
            "86285: done 634 games, reward 190.840, eps 0.01, speed 130.18 f/s, time 12.2 min\n",
            "86605: done 635 games, reward 193.480, eps 0.01, speed 109.79 f/s, time 12.2 min\n",
            "86655: done 636 games, reward 193.040, eps 0.01, speed 95.82 f/s, time 12.2 min\n",
            "86699: done 637 games, reward 190.840, eps 0.01, speed 91.51 f/s, time 12.2 min\n",
            "87073: done 638 games, reward 191.720, eps 0.01, speed 120.37 f/s, time 12.3 min\n",
            "87207: done 639 games, reward 192.160, eps 0.01, speed 128.81 f/s, time 12.3 min\n",
            "87308: done 640 games, reward 190.840, eps 0.01, speed 128.63 f/s, time 12.3 min\n",
            "87503: done 641 games, reward 186.880, eps 0.01, speed 127.83 f/s, time 12.4 min\n",
            "87742: done 642 games, reward 190.400, eps 0.01, speed 129.77 f/s, time 12.4 min\n",
            "87972: done 643 games, reward 190.840, eps 0.01, speed 131.36 f/s, time 12.4 min\n",
            "88640: done 644 games, reward 193.480, eps 0.01, speed 111.25 f/s, time 12.5 min\n",
            "88759: done 645 games, reward 193.480, eps 0.01, speed 130.27 f/s, time 12.5 min\n",
            "88912: done 646 games, reward 190.840, eps 0.01, speed 130.56 f/s, time 12.5 min\n",
            "89111: done 647 games, reward 192.160, eps 0.01, speed 130.30 f/s, time 12.6 min\n",
            "89276: done 648 games, reward 193.480, eps 0.01, speed 128.35 f/s, time 12.6 min\n",
            "89673: done 649 games, reward 195.360, eps 0.01, speed 119.89 f/s, time 12.7 min\n",
            "90354: done 650 games, reward 200.200, eps 0.01, speed 116.17 f/s, time 12.7 min\n",
            "90555: done 651 games, reward 198.960, eps 0.01, speed 129.85 f/s, time 12.8 min\n",
            "90668: done 652 games, reward 200.400, eps 0.01, speed 129.27 f/s, time 12.8 min\n",
            "91231: done 653 games, reward 206.160, eps 0.01, speed 125.32 f/s, time 12.9 min\n",
            "91357: done 654 games, reward 208.160, eps 0.01, speed 94.86 f/s, time 12.9 min\n",
            "91449: done 655 games, reward 206.480, eps 0.01, speed 91.33 f/s, time 12.9 min\n",
            "91619: done 656 games, reward 202.520, eps 0.01, speed 121.96 f/s, time 12.9 min\n",
            "91722: done 657 games, reward 201.520, eps 0.01, speed 130.88 f/s, time 12.9 min\n",
            "92145: done 658 games, reward 204.560, eps 0.01, speed 130.51 f/s, time 13.0 min\n",
            "92339: done 659 games, reward 205.880, eps 0.01, speed 130.30 f/s, time 13.0 min\n",
            "92750: done 660 games, reward 207.200, eps 0.01, speed 130.64 f/s, time 13.1 min\n",
            "92937: done 661 games, reward 206.000, eps 0.01, speed 74.98 f/s, time 13.1 min\n",
            "93253: done 662 games, reward 207.320, eps 0.01, speed 89.76 f/s, time 13.2 min\n",
            "93395: done 663 games, reward 208.200, eps 0.01, speed 128.64 f/s, time 13.2 min\n",
            "93554: done 664 games, reward 208.800, eps 0.01, speed 130.35 f/s, time 13.2 min\n",
            "94027: done 665 games, reward 213.640, eps 0.01, speed 130.28 f/s, time 13.3 min\n",
            "94066: done 666 games, reward 208.800, eps 0.01, speed 125.34 f/s, time 13.3 min\n",
            "94155: done 667 games, reward 209.280, eps 0.01, speed 130.93 f/s, time 13.3 min\n",
            "94578: done 668 games, reward 212.360, eps 0.01, speed 117.09 f/s, time 13.3 min\n",
            "94670: done 669 games, reward 211.040, eps 0.01, speed 95.31 f/s, time 13.4 min\n",
            "94719: done 670 games, reward 211.480, eps 0.01, speed 91.40 f/s, time 13.4 min\n",
            "95056: done 671 games, reward 212.360, eps 0.01, speed 125.48 f/s, time 13.4 min\n",
            "95208: done 672 games, reward 214.120, eps 0.01, speed 129.83 f/s, time 13.4 min\n",
            "95396: done 673 games, reward 215.320, eps 0.01, speed 129.03 f/s, time 13.5 min\n",
            "95512: done 674 games, reward 214.000, eps 0.01, speed 130.04 f/s, time 13.5 min\n",
            "95870: done 675 games, reward 217.520, eps 0.01, speed 130.31 f/s, time 13.5 min\n",
            "96024: done 676 games, reward 215.800, eps 0.01, speed 128.86 f/s, time 13.5 min\n",
            "96170: done 677 games, reward 215.800, eps 0.01, speed 98.02 f/s, time 13.6 min\n",
            "96223: done 678 games, reward 213.160, eps 0.01, speed 95.45 f/s, time 13.6 min\n",
            "96320: done 679 games, reward 213.160, eps 0.01, speed 91.94 f/s, time 13.6 min\n",
            "96623: done 680 games, reward 215.800, eps 0.01, speed 127.93 f/s, time 13.6 min\n",
            "97017: done 681 games, reward 216.240, eps 0.01, speed 129.10 f/s, time 13.7 min\n",
            "97096: done 682 games, reward 214.080, eps 0.01, speed 126.68 f/s, time 13.7 min\n",
            "97261: done 683 games, reward 211.440, eps 0.01, speed 130.47 f/s, time 13.7 min\n",
            "97442: done 684 games, reward 213.200, eps 0.01, speed 129.84 f/s, time 13.7 min\n",
            "97499: done 685 games, reward 212.320, eps 0.01, speed 125.41 f/s, time 13.7 min\n",
            "97640: done 686 games, reward 207.480, eps 0.01, speed 117.01 f/s, time 13.8 min\n",
            "97690: done 687 games, reward 207.400, eps 0.01, speed 96.71 f/s, time 13.8 min\n",
            "97801: done 688 games, reward 207.240, eps 0.01, speed 94.36 f/s, time 13.8 min\n",
            "97955: done 689 games, reward 208.560, eps 0.01, speed 101.52 f/s, time 13.8 min\n",
            "98008: done 690 games, reward 209.000, eps 0.01, speed 129.64 f/s, time 13.8 min\n",
            "98151: done 691 games, reward 209.440, eps 0.01, speed 129.65 f/s, time 13.8 min\n",
            "98373: done 692 games, reward 209.000, eps 0.01, speed 129.37 f/s, time 13.9 min\n",
            "98586: done 693 games, reward 209.440, eps 0.01, speed 130.12 f/s, time 13.9 min\n",
            "99118: done 694 games, reward 214.720, eps 0.01, speed 130.59 f/s, time 14.0 min\n",
            "99226: done 695 games, reward 214.720, eps 0.01, speed 108.24 f/s, time 14.0 min\n",
            "99286: done 696 games, reward 213.840, eps 0.01, speed 96.11 f/s, time 14.0 min\n",
            "99416: done 697 games, reward 216.040, eps 0.01, speed 94.66 f/s, time 14.0 min\n",
            "99524: done 698 games, reward 213.400, eps 0.01, speed 106.20 f/s, time 14.0 min\n",
            "99635: done 699 games, reward 213.400, eps 0.01, speed 130.49 f/s, time 14.0 min\n",
            "99810: done 700 games, reward 213.400, eps 0.01, speed 131.43 f/s, time 14.1 min\n",
            "99884: done 701 games, reward 212.520, eps 0.01, speed 128.55 f/s, time 14.1 min\n",
            "100145: done 702 games, reward 215.160, eps 0.01, speed 130.35 f/s, time 14.1 min\n",
            "100478: done 703 games, reward 216.920, eps 0.01, speed 129.84 f/s, time 14.2 min\n",
            "100656: done 704 games, reward 216.200, eps 0.01, speed 129.88 f/s, time 14.2 min\n",
            "101236: done 705 games, reward 225.240, eps 0.01, speed 108.73 f/s, time 14.3 min\n",
            "101416: done 706 games, reward 227.200, eps 0.01, speed 129.31 f/s, time 14.3 min\n",
            "101482: done 707 games, reward 227.280, eps 0.01, speed 128.66 f/s, time 14.3 min\n",
            "101903: done 708 games, reward 231.240, eps 0.01, speed 127.96 f/s, time 14.4 min\n",
            "101979: done 709 games, reward 231.680, eps 0.01, speed 130.13 f/s, time 14.4 min\n",
            "102270: done 710 games, reward 233.600, eps 0.01, speed 129.27 f/s, time 14.4 min\n",
            "102462: done 711 games, reward 232.720, eps 0.01, speed 103.53 f/s, time 14.4 min\n",
            "102969: done 712 games, reward 236.880, eps 0.01, speed 115.08 f/s, time 14.5 min\n",
            "103021: done 713 games, reward 236.000, eps 0.01, speed 126.44 f/s, time 14.5 min\n",
            "103166: done 714 games, reward 235.560, eps 0.01, speed 129.74 f/s, time 14.5 min\n",
            "103658: done 715 games, reward 238.200, eps 0.01, speed 130.20 f/s, time 14.6 min\n",
            "103895: done 716 games, reward 238.840, eps 0.01, speed 127.74 f/s, time 14.6 min\n",
            "104249: done 717 games, reward 238.840, eps 0.01, speed 97.64 f/s, time 14.7 min\n",
            "104399: done 718 games, reward 239.320, eps 0.01, speed 129.27 f/s, time 14.7 min\n",
            "104477: done 719 games, reward 239.320, eps 0.01, speed 129.44 f/s, time 14.7 min\n",
            "104609: done 720 games, reward 234.920, eps 0.01, speed 129.27 f/s, time 14.7 min\n",
            "104723: done 721 games, reward 235.360, eps 0.01, speed 128.92 f/s, time 14.7 min\n",
            "105289: done 722 games, reward 238.880, eps 0.01, speed 130.16 f/s, time 14.8 min\n",
            "105744: done 723 games, reward 238.880, eps 0.01, speed 107.52 f/s, time 14.9 min\n",
            "106049: done 724 games, reward 239.320, eps 0.01, speed 124.25 f/s, time 14.9 min\n",
            "106114: done 725 games, reward 239.800, eps 0.01, speed 126.05 f/s, time 14.9 min\n",
            "106601: done 726 games, reward 244.640, eps 0.01, speed 130.05 f/s, time 15.0 min\n",
            "106673: done 727 games, reward 243.760, eps 0.01, speed 131.11 f/s, time 15.0 min\n",
            "106970: done 728 games, reward 244.600, eps 0.01, speed 129.31 f/s, time 15.0 min\n",
            "107608: done 729 games, reward 250.840, eps 0.01, speed 111.01 f/s, time 15.1 min\n",
            "107674: done 730 games, reward 251.360, eps 0.01, speed 118.01 f/s, time 15.2 min\n",
            "107787: done 731 games, reward 250.520, eps 0.01, speed 130.52 f/s, time 15.2 min\n",
            "107922: done 732 games, reward 246.080, eps 0.01, speed 130.43 f/s, time 15.2 min\n",
            "108231: done 733 games, reward 248.600, eps 0.01, speed 128.95 f/s, time 15.2 min\n",
            "108496: done 734 games, reward 251.000, eps 0.01, speed 128.23 f/s, time 15.3 min\n",
            "108597: done 735 games, reward 245.720, eps 0.01, speed 130.09 f/s, time 15.3 min\n",
            "108951: done 736 games, reward 251.000, eps 0.01, speed 99.29 f/s, time 15.3 min\n",
            "109119: done 737 games, reward 254.360, eps 0.01, speed 127.57 f/s, time 15.4 min\n",
            "109267: done 738 games, reward 253.480, eps 0.01, speed 129.96 f/s, time 15.4 min\n",
            "109807: done 739 games, reward 257.120, eps 0.01, speed 131.19 f/s, time 15.4 min\n",
            "109888: done 740 games, reward 256.760, eps 0.01, speed 129.11 f/s, time 15.5 min\n",
            "110026: done 741 games, reward 256.760, eps 0.01, speed 128.01 f/s, time 15.5 min\n",
            "110167: done 742 games, reward 254.120, eps 0.01, speed 130.18 f/s, time 15.5 min\n",
            "110416: done 743 games, reward 257.200, eps 0.01, speed 103.14 f/s, time 15.5 min\n",
            "110576: done 744 games, reward 252.800, eps 0.01, speed 103.08 f/s, time 15.6 min\n",
            "111134: done 745 games, reward 259.120, eps 0.01, speed 130.25 f/s, time 15.6 min\n",
            "111232: done 746 games, reward 260.560, eps 0.01, speed 125.49 f/s, time 15.6 min\n",
            "111638: done 747 games, reward 264.520, eps 0.01, speed 129.75 f/s, time 15.7 min\n",
            "111748: done 748 games, reward 262.360, eps 0.01, speed 131.86 f/s, time 15.7 min\n",
            "111791: done 749 games, reward 259.600, eps 0.01, speed 125.76 f/s, time 15.7 min\n",
            "111909: done 750 games, reward 255.640, eps 0.01, speed 97.39 f/s, time 15.7 min\n",
            "112345: done 751 games, reward 260.080, eps 0.01, speed 112.61 f/s, time 15.8 min\n",
            "112478: done 752 games, reward 260.080, eps 0.01, speed 129.06 f/s, time 15.8 min\n",
            "112946: done 753 games, reward 259.600, eps 0.01, speed 130.73 f/s, time 15.9 min\n",
            "113093: done 754 games, reward 258.160, eps 0.01, speed 129.20 f/s, time 15.9 min\n",
            "113438: done 755 games, reward 262.000, eps 0.01, speed 122.48 f/s, time 15.9 min\n",
            "113973: done 756 games, reward 265.520, eps 0.01, speed 112.42 f/s, time 16.0 min\n",
            "114325: done 757 games, reward 267.440, eps 0.01, speed 129.50 f/s, time 16.1 min\n",
            "114399: done 758 games, reward 262.960, eps 0.01, speed 126.26 f/s, time 16.1 min\n",
            "114782: done 759 games, reward 266.480, eps 0.01, speed 130.97 f/s, time 16.1 min\n",
            "115353: done 760 games, reward 270.600, eps 0.01, speed 108.29 f/s, time 16.2 min\n",
            "115622: done 761 games, reward 273.920, eps 0.01, speed 126.83 f/s, time 16.2 min\n",
            "116098: done 762 games, reward 274.800, eps 0.01, speed 130.11 f/s, time 16.3 min\n",
            "116191: done 763 games, reward 273.920, eps 0.01, speed 130.75 f/s, time 16.3 min\n",
            "116587: done 764 games, reward 277.280, eps 0.01, speed 122.36 f/s, time 16.4 min\n",
            "117037: done 765 games, reward 275.960, eps 0.01, speed 107.30 f/s, time 16.4 min\n",
            "117128: done 766 games, reward 277.280, eps 0.01, speed 131.52 f/s, time 16.5 min\n",
            "117414: done 767 games, reward 279.680, eps 0.01, speed 128.31 f/s, time 16.5 min\n",
            "117908: done 768 games, reward 283.280, eps 0.01, speed 126.97 f/s, time 16.6 min\n",
            "118045: done 769 games, reward 284.320, eps 0.01, speed 128.36 f/s, time 16.6 min\n",
            "118109: done 770 games, reward 283.880, eps 0.01, speed 120.68 f/s, time 16.6 min\n",
            "118276: done 771 games, reward 282.120, eps 0.01, speed 94.92 f/s, time 16.6 min\n",
            "118734: done 772 games, reward 284.360, eps 0.01, speed 116.40 f/s, time 16.7 min\n",
            "119035: done 773 games, reward 284.360, eps 0.01, speed 127.71 f/s, time 16.7 min\n",
            "119473: done 774 games, reward 289.200, eps 0.01, speed 130.23 f/s, time 16.8 min\n",
            "119564: done 775 games, reward 284.360, eps 0.01, speed 131.63 f/s, time 16.8 min\n",
            "119676: done 776 games, reward 284.840, eps 0.01, speed 124.11 f/s, time 16.8 min\n",
            "120183: done 777 games, reward 289.680, eps 0.01, speed 107.62 f/s, time 16.9 min\n",
            "120321: done 778 games, reward 291.080, eps 0.01, speed 131.02 f/s, time 16.9 min\n",
            "120383: done 779 games, reward 290.240, eps 0.01, speed 129.85 f/s, time 16.9 min\n",
            "121080: done 780 games, reward 291.120, eps 0.01, speed 130.61 f/s, time 17.0 min\n",
            "121235: done 781 games, reward 291.680, eps 0.01, speed 128.30 f/s, time 17.0 min\n",
            "121348: done 782 games, reward 291.680, eps 0.01, speed 101.54 f/s, time 17.0 min\n",
            "121708: done 783 games, reward 295.640, eps 0.01, speed 106.50 f/s, time 17.1 min\n",
            "122074: done 784 games, reward 295.800, eps 0.01, speed 130.05 f/s, time 17.1 min\n",
            "122259: done 785 games, reward 299.160, eps 0.01, speed 129.67 f/s, time 17.2 min\n",
            "122441: done 786 games, reward 300.040, eps 0.01, speed 127.07 f/s, time 17.2 min\n",
            "122627: done 787 games, reward 302.240, eps 0.01, speed 128.75 f/s, time 17.2 min\n",
            "122696: done 788 games, reward 300.920, eps 0.01, speed 127.98 f/s, time 17.2 min\n",
            "123056: done 789 games, reward 302.240, eps 0.01, speed 106.30 f/s, time 17.3 min\n",
            "123107: done 790 games, reward 302.240, eps 0.01, speed 86.80 f/s, time 17.3 min\n",
            "123363: done 791 games, reward 302.240, eps 0.01, speed 125.87 f/s, time 17.3 min\n",
            "123625: done 792 games, reward 305.760, eps 0.01, speed 129.23 f/s, time 17.3 min\n",
            "124023: done 793 games, reward 303.560, eps 0.01, speed 129.90 f/s, time 17.4 min\n",
            "124081: done 794 games, reward 296.960, eps 0.01, speed 130.16 f/s, time 17.4 min\n",
            "124215: done 795 games, reward 298.280, eps 0.01, speed 130.54 f/s, time 17.4 min\n",
            "124511: done 796 games, reward 301.360, eps 0.01, speed 116.10 f/s, time 17.5 min\n",
            "124583: done 797 games, reward 299.160, eps 0.01, speed 94.69 f/s, time 17.5 min\n",
            "124967: done 798 games, reward 302.240, eps 0.01, speed 114.65 f/s, time 17.5 min\n",
            "125049: done 799 games, reward 301.360, eps 0.01, speed 131.29 f/s, time 17.5 min\n",
            "125413: done 800 games, reward 303.240, eps 0.01, speed 129.55 f/s, time 17.6 min\n",
            "125542: done 801 games, reward 305.000, eps 0.01, speed 130.17 f/s, time 17.6 min\n",
            "125627: done 802 games, reward 301.920, eps 0.01, speed 129.51 f/s, time 17.6 min\n",
            "126584: done 803 games, reward 307.520, eps 0.01, speed 117.24 f/s, time 17.8 min\n",
            "126807: done 804 games, reward 307.800, eps 0.01, speed 110.01 f/s, time 17.8 min\n",
            "127171: done 805 games, reward 303.720, eps 0.01, speed 106.69 f/s, time 17.8 min\n",
            "127251: done 806 games, reward 302.760, eps 0.01, speed 128.81 f/s, time 17.9 min\n",
            "127581: done 807 games, reward 305.320, eps 0.01, speed 113.86 f/s, time 17.9 min\n",
            "127931: done 808 games, reward 305.080, eps 0.01, speed 111.55 f/s, time 18.0 min\n",
            "128074: done 809 games, reward 306.080, eps 0.01, speed 128.87 f/s, time 18.0 min\n",
            "128410: done 810 games, reward 306.360, eps 0.01, speed 129.04 f/s, time 18.0 min\n",
            "128580: done 811 games, reward 305.920, eps 0.01, speed 129.32 f/s, time 18.0 min\n",
            "128633: done 812 games, reward 299.560, eps 0.01, speed 130.36 f/s, time 18.0 min\n",
            "129145: done 813 games, reward 306.640, eps 0.01, speed 120.67 f/s, time 18.1 min\n",
            "129283: done 814 games, reward 306.320, eps 0.01, speed 94.30 f/s, time 18.1 min\n",
            "129414: done 815 games, reward 302.920, eps 0.01, speed 113.75 f/s, time 18.2 min\n",
            "129718: done 816 games, reward 302.280, eps 0.01, speed 129.39 f/s, time 18.2 min\n",
            "130246: done 817 games, reward 304.800, eps 0.01, speed 129.57 f/s, time 18.3 min\n",
            "130354: done 818 games, reward 306.280, eps 0.01, speed 128.31 f/s, time 18.3 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "131975: done 823 games, reward 317.120, eps 0.01, speed 128.05 f/s, time 18.5 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "133425: done 826 games, reward 330.760, eps 0.01, speed 125.36 f/s, time 18.7 min\n",
            "133689: done 827 games, reward 331.720, eps 0.01, speed 127.45 f/s, time 18.7 min\n",
            "134202: done 828 games, reward 332.160, eps 0.01, speed 105.25 f/s, time 18.8 min\n",
            "134444: done 829 games, reward 326.440, eps 0.01, speed 131.33 f/s, time 18.9 min\n",
            "134501: done 830 games, reward 325.480, eps 0.01, speed 129.86 f/s, time 18.9 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "135499: done 832 games, reward 333.280, eps 0.01, speed 89.57 f/s, time 19.0 min\n",
            "135734: done 833 games, reward 332.200, eps 0.01, speed 112.20 f/s, time 19.0 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "136834: done 836 games, reward 337.040, eps 0.01, speed 116.23 f/s, time 19.2 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "137560: done 838 games, reward 341.480, eps 0.01, speed 120.64 f/s, time 19.3 min\n",
            "137647: done 839 games, reward 337.520, eps 0.01, speed 126.48 f/s, time 19.3 min\n",
            "138139: done 840 games, reward 343.160, eps 0.01, speed 129.45 f/s, time 19.4 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 110-111: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 110-111: surrogates not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "138834: done 843 games, reward 345.080, eps 0.01, speed 120.51 f/s, time 19.5 min\n",
            "138958: done 844 games, reward 345.080, eps 0.01, speed 128.65 f/s, time 19.5 min\n",
            "139239: done 845 games, reward 340.960, eps 0.01, speed 128.80 f/s, time 19.5 min\n",
            "139327: done 846 games, reward 341.720, eps 0.01, speed 129.09 f/s, time 19.5 min\n",
            "139705: done 847 games, reward 340.960, eps 0.01, speed 128.44 f/s, time 19.6 min\n",
            "139986: done 848 games, reward 344.800, eps 0.01, speed 126.29 f/s, time 19.6 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "140734: done 850 games, reward 352.600, eps 0.01, speed 126.05 f/s, time 19.7 min\n",
            "140823: done 851 games, reward 348.160, eps 0.01, speed 126.67 f/s, time 19.7 min\n",
            "140964: done 852 games, reward 350.240, eps 0.01, speed 130.62 f/s, time 19.8 min\n",
            "141122: done 853 games, reward 345.840, eps 0.01, speed 131.68 f/s, time 19.8 min\n",
            "141257: done 854 games, reward 345.280, eps 0.01, speed 127.55 f/s, time 19.8 min\n",
            "141418: done 855 games, reward 343.120, eps 0.01, speed 130.15 f/s, time 19.8 min\n",
            "141934: done 856 games, reward 342.840, eps 0.01, speed 106.87 f/s, time 19.9 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "143638: done 859 games, reward 359.640, eps 0.01, speed 115.03 f/s, time 20.1 min\n",
            "143694: done 860 games, reward 352.920, eps 0.01, speed 117.35 f/s, time 20.1 min\n",
            "143895: done 861 games, reward 352.120, eps 0.01, speed 130.08 f/s, time 20.2 min\n",
            "144087: done 862 games, reward 348.160, eps 0.01, speed 125.22 f/s, time 20.2 min\n",
            "144159: done 863 games, reward 347.720, eps 0.01, speed 129.42 f/s, time 20.2 min\n",
            "144253: done 864 games, reward 344.200, eps 0.01, speed 129.64 f/s, time 20.2 min\n",
            "144372: done 865 games, reward 340.240, eps 0.01, speed 130.13 f/s, time 20.2 min\n",
            "144944: done 866 games, reward 349.160, eps 0.01, speed 111.57 f/s, time 20.3 min\n",
            "145595: done 867 games, reward 353.360, eps 0.01, speed 127.16 f/s, time 20.4 min\n",
            "145863: done 868 games, reward 350.120, eps 0.01, speed 129.49 f/s, time 20.4 min\n",
            "145932: done 869 games, reward 349.160, eps 0.01, speed 128.04 f/s, time 20.4 min\n",
            "146648: done 870 games, reward 356.720, eps 0.01, speed 112.95 f/s, time 20.6 min\n",
            "146837: done 871 games, reward 357.440, eps 0.01, speed 128.01 f/s, time 20.6 min\n",
            "146933: done 872 games, reward 353.960, eps 0.01, speed 127.97 f/s, time 20.6 min\n",
            "147689: done 873 games, reward 359.120, eps 0.01, speed 129.63 f/s, time 20.7 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "149289: done 877 games, reward 368.360, eps 0.01, speed 126.07 f/s, time 20.9 min\n",
            "149366: done 878 games, reward 367.440, eps 0.01, speed 126.88 f/s, time 20.9 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 110-111: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 110-111: surrogates not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "149879: done 880 games, reward 366.960, eps 0.01, speed 124.90 f/s, time 21.0 min\n",
            "150178: done 881 games, reward 372.720, eps 0.01, speed 128.76 f/s, time 21.0 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150915: done 883 games, reward 372.240, eps 0.01, speed 127.01 f/s, time 21.1 min\n",
            "151005: done 884 games, reward 370.320, eps 0.01, speed 109.92 f/s, time 21.1 min\n",
            "151426: done 885 games, reward 370.920, eps 0.01, speed 106.28 f/s, time 21.2 min\n",
            "151643: done 886 games, reward 370.920, eps 0.01, speed 128.73 f/s, time 21.2 min\n",
            "152165: done 887 games, reward 377.120, eps 0.01, speed 128.48 f/s, time 21.3 min\n",
            "152374: done 888 games, reward 378.440, eps 0.01, speed 130.61 f/s, time 21.3 min\n",
            "152744: done 889 games, reward 378.000, eps 0.01, speed 109.50 f/s, time 21.4 min\n",
            "152800: done 890 games, reward 378.440, eps 0.01, speed 89.49 f/s, time 21.4 min\n",
            "152920: done 891 games, reward 377.560, eps 0.01, speed 113.86 f/s, time 21.4 min\n",
            "153213: done 892 games, reward 377.120, eps 0.01, speed 129.98 f/s, time 21.5 min\n",
            "153304: done 893 games, reward 376.240, eps 0.01, speed 132.86 f/s, time 21.5 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153715: done 895 games, reward 378.000, eps 0.01, speed 123.04 f/s, time 21.5 min\n",
            "154017: done 896 games, reward 376.680, eps 0.01, speed 130.00 f/s, time 21.6 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "154806: done 898 games, reward 381.320, eps 0.01, speed 117.48 f/s, time 21.7 min\n",
            "154947: done 899 games, reward 382.800, eps 0.01, speed 122.84 f/s, time 21.7 min\n",
            "155061: done 900 games, reward 380.920, eps 0.01, speed 127.94 f/s, time 21.7 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 110-111: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 110-111: surrogates not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "156141: done 903 games, reward 383.480, eps 0.01, speed 107.01 f/s, time 21.9 min\n",
            "156287: done 904 games, reward 381.720, eps 0.01, speed 128.34 f/s, time 21.9 min\n",
            "156399: done 905 games, reward 377.200, eps 0.01, speed 132.04 f/s, time 21.9 min\n",
            "156651: done 906 games, reward 379.280, eps 0.01, speed 130.51 f/s, time 21.9 min\n",
            "156762: done 907 games, reward 376.640, eps 0.01, speed 129.02 f/s, time 21.9 min\n",
            "156887: done 908 games, reward 372.920, eps 0.01, speed 123.89 f/s, time 22.0 min\n",
            "157039: done 909 games, reward 374.560, eps 0.01, speed 129.45 f/s, time 22.0 min\n",
            "157384: done 910 games, reward 375.440, eps 0.01, speed 113.07 f/s, time 22.0 min\n",
            "157515: done 911 games, reward 373.680, eps 0.01, speed 93.52 f/s, time 22.1 min\n",
            "157847: done 912 games, reward 377.640, eps 0.01, speed 127.09 f/s, time 22.1 min\n",
            "157960: done 913 games, reward 371.880, eps 0.01, speed 129.44 f/s, time 22.1 min\n",
            "158032: done 914 games, reward 371.320, eps 0.01, speed 129.68 f/s, time 22.1 min\n",
            "158731: done 915 games, reward 381.760, eps 0.01, speed 129.79 f/s, time 22.2 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "159255: done 917 games, reward 379.480, eps 0.01, speed 116.43 f/s, time 22.3 min\n",
            "159382: done 918 games, reward 378.840, eps 0.01, speed 128.27 f/s, time 22.3 min\n",
            "160058: done 919 games, reward 377.560, eps 0.01, speed 130.79 f/s, time 22.4 min\n",
            "160223: done 920 games, reward 376.120, eps 0.01, speed 129.49 f/s, time 22.4 min\n",
            "160770: done 921 games, reward 383.680, eps 0.01, speed 107.44 f/s, time 22.5 min\n",
            "160909: done 922 games, reward 380.320, eps 0.01, speed 127.47 f/s, time 22.5 min\n",
            "160955: done 923 games, reward 376.600, eps 0.01, speed 124.26 f/s, time 22.5 min\n",
            "161278: done 924 games, reward 370.760, eps 0.01, speed 130.10 f/s, time 22.6 min\n",
            "161728: done 925 games, reward 366.960, eps 0.01, speed 129.60 f/s, time 22.6 min\n",
            "162291: done 926 games, reward 368.960, eps 0.01, speed 94.85 f/s, time 22.7 min\n",
            "162949: done 927 games, reward 377.000, eps 0.01, speed 121.99 f/s, time 22.8 min\n",
            "163680: done 928 games, reward 383.880, eps 0.01, speed 129.57 f/s, time 22.9 min\n",
            "163774: done 929 games, reward 383.160, eps 0.01, speed 97.24 f/s, time 22.9 min\n",
            "163948: done 930 games, reward 386.240, eps 0.01, speed 95.01 f/s, time 23.0 min\n",
            "164396: done 931 games, reward 381.240, eps 0.01, speed 128.41 f/s, time 23.0 min\n",
            "164574: done 932 games, reward 384.600, eps 0.01, speed 130.69 f/s, time 23.0 min\n",
            "164745: done 933 games, reward 383.480, eps 0.01, speed 131.55 f/s, time 23.1 min\n",
            "165185: done 934 games, reward 376.920, eps 0.01, speed 130.92 f/s, time 23.1 min\n",
            "165375: done 935 games, reward 376.920, eps 0.01, speed 107.02 f/s, time 23.1 min\n",
            "166031: done 936 games, reward 386.360, eps 0.01, speed 117.97 f/s, time 23.2 min\n",
            "166098: done 937 games, reward 377.360, eps 0.01, speed 123.77 f/s, time 23.2 min\n",
            "166318: done 938 games, reward 378.800, eps 0.01, speed 129.46 f/s, time 23.3 min\n",
            "166865: done 939 games, reward 384.440, eps 0.01, speed 127.95 f/s, time 23.3 min\n",
            "167040: done 940 games, reward 379.760, eps 0.01, speed 96.44 f/s, time 23.4 min\n",
            "167171: done 941 games, reward 380.240, eps 0.01, speed 99.11 f/s, time 23.4 min\n",
            "167732: done 942 games, reward 382.040, eps 0.01, speed 129.24 f/s, time 23.5 min\n",
            "168098: done 943 games, reward 386.960, eps 0.01, speed 129.06 f/s, time 23.5 min\n",
            "168271: done 944 games, reward 387.720, eps 0.01, speed 129.77 f/s, time 23.5 min\n",
            "168416: done 945 games, reward 386.400, eps 0.01, speed 126.64 f/s, time 23.6 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "169049: done 947 games, reward 387.960, eps 0.01, speed 124.92 f/s, time 23.7 min\n",
            "169206: done 948 games, reward 386.280, eps 0.01, speed 128.63 f/s, time 23.7 min\n",
            "169315: done 949 games, reward 380.000, eps 0.01, speed 129.53 f/s, time 23.7 min\n",
            "169554: done 950 games, reward 379.800, eps 0.01, speed 129.64 f/s, time 23.7 min\n",
            "169930: done 951 games, reward 389.280, eps 0.01, speed 129.73 f/s, time 23.8 min\n",
            "170074: done 952 games, reward 388.160, eps 0.01, speed 104.88 f/s, time 23.8 min\n",
            "170255: done 953 games, reward 389.000, eps 0.01, speed 93.39 f/s, time 23.8 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "170643: done 955 games, reward 392.080, eps 0.01, speed 124.87 f/s, time 23.9 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "171191: done 957 games, reward 381.120, eps 0.01, speed 124.29 f/s, time 23.9 min\n",
            "171430: done 958 games, reward 378.040, eps 0.01, speed 130.38 f/s, time 24.0 min\n",
            "171814: done 959 games, reward 380.480, eps 0.01, speed 103.31 f/s, time 24.0 min\n",
            "171995: done 960 games, reward 383.080, eps 0.01, speed 121.32 f/s, time 24.1 min\n",
            "172277: done 961 games, reward 382.200, eps 0.01, speed 131.52 f/s, time 24.1 min\n",
            "172749: done 962 games, reward 386.720, eps 0.01, speed 131.23 f/s, time 24.2 min\n",
            "173092: done 963 games, reward 392.440, eps 0.01, speed 128.77 f/s, time 24.2 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 110-111: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 110-111: surrogates not allowed\n",
            "ERROR:tornado.application:Exception in callback functools.partial(<bound method OutStream._flush of <ipykernel.iostream.OutStream object at 0x7f2b55fa0f70>>)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 104, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
            "    ret = callback()\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 518, in _flush\n",
            "    self.session.send(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 848, in send\n",
            "    to_send = self.serialize(msg, ident)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 718, in serialize\n",
            "    content = self.pack(content)\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py\", line 112, in json_packer\n",
            "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 111-112: surrogates not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "173700: done 966 games, reward 389.800, eps 0.01, speed 125.77 f/s, time 24.3 min\n",
            "173791: done 967 games, reward 384.040, eps 0.01, speed 129.13 f/s, time 24.3 min\n",
            "173897: done 968 games, reward 380.600, eps 0.01, speed 129.63 f/s, time 24.3 min\n",
            "174078: done 969 games, reward 384.480, eps 0.01, speed 129.83 f/s, time 24.3 min\n",
            "174245: done 970 games, reward 378.680, eps 0.01, speed 130.81 f/s, time 24.4 min\n",
            "174459: done 971 games, reward 378.680, eps 0.01, speed 129.72 f/s, time 24.4 min\n",
            "175133: done 972 games, reward 390.560, eps 0.01, speed 111.24 f/s, time 24.5 min\n",
            "175270: done 973 games, reward 382.040, eps 0.01, speed 128.75 f/s, time 24.5 min\n",
            "175339: done 974 games, reward 372.040, eps 0.01, speed 129.08 f/s, time 24.5 min\n",
            "175497: done 975 games, reward 374.440, eps 0.01, speed 130.22 f/s, time 24.5 min\n",
            "175636: done 976 games, reward 367.800, eps 0.01, speed 129.27 f/s, time 24.6 min\n",
            "175741: done 977 games, reward 365.680, eps 0.01, speed 131.84 f/s, time 24.6 min\n",
            "176046: done 978 games, reward 370.480, eps 0.01, speed 129.92 f/s, time 24.6 min\n",
            "176245: done 979 games, reward 367.520, eps 0.01, speed 130.67 f/s, time 24.6 min\n",
            "176287: done 980 games, reward 366.640, eps 0.01, speed 125.58 f/s, time 24.6 min\n",
            "176614: done 981 games, reward 365.600, eps 0.01, speed 98.09 f/s, time 24.7 min\n",
            "176670: done 982 games, reward 360.320, eps 0.01, speed 126.44 f/s, time 24.7 min\n",
            "176897: done 983 games, reward 363.720, eps 0.01, speed 129.89 f/s, time 24.7 min\n",
            "177221: done 984 games, reward 368.120, eps 0.01, speed 129.82 f/s, time 24.8 min\n",
            "177345: done 985 games, reward 365.920, eps 0.01, speed 130.25 f/s, time 24.8 min\n",
            "177631: done 986 games, reward 367.600, eps 0.01, speed 128.99 f/s, time 24.8 min\n",
            "177748: done 987 games, reward 360.960, eps 0.01, speed 127.88 f/s, time 24.8 min\n",
            "177824: done 988 games, reward 359.640, eps 0.01, speed 127.68 f/s, time 24.9 min\n",
            "178156: done 989 games, reward 359.640, eps 0.01, speed 99.64 f/s, time 24.9 min\n",
            "178292: done 990 games, reward 360.960, eps 0.01, speed 127.94 f/s, time 24.9 min\n",
            "178403: done 991 games, reward 360.960, eps 0.01, speed 129.22 f/s, time 24.9 min\n",
            "178642: done 992 games, reward 359.640, eps 0.01, speed 131.84 f/s, time 25.0 min\n",
            "179056: done 993 games, reward 364.920, eps 0.01, speed 130.88 f/s, time 25.0 min\n",
            "179128: done 994 games, reward 361.840, eps 0.01, speed 129.92 f/s, time 25.0 min\n",
            "179310: done 995 games, reward 361.000, eps 0.01, speed 130.49 f/s, time 25.1 min\n",
            "179832: done 996 games, reward 366.800, eps 0.01, speed 108.45 f/s, time 25.1 min\n",
            "180059: done 997 games, reward 362.600, eps 0.01, speed 129.87 f/s, time 25.2 min\n",
            "180111: done 998 games, reward 360.680, eps 0.01, speed 125.50 f/s, time 25.2 min\n",
            "180495: done 999 games, reward 364.920, eps 0.01, speed 129.11 f/s, time 25.2 min\n",
            "180677: done 1000 games, reward 366.440, eps 0.01, speed 129.72 f/s, time 25.2 min\n",
            "180758: done 1001 games, reward 360.680, eps 0.01, speed 129.13 f/s, time 25.3 min\n",
            "181094: done 1002 games, reward 366.320, eps 0.01, speed 122.58 f/s, time 25.3 min\n",
            "181205: done 1003 games, reward 363.400, eps 0.01, speed 95.79 f/s, time 25.3 min\n",
            "181403: done 1004 games, reward 365.400, eps 0.01, speed 104.07 f/s, time 25.4 min\n",
            "181765: done 1005 games, reward 371.120, eps 0.01, speed 130.31 f/s, time 25.4 min\n",
            "182296: done 1006 games, reward 374.320, eps 0.01, speed 129.49 f/s, time 25.5 min\n",
            "182352: done 1007 games, reward 373.920, eps 0.01, speed 129.57 f/s, time 25.5 min\n",
            "182476: done 1008 games, reward 374.360, eps 0.01, speed 127.56 f/s, time 25.5 min\n",
            "182839: done 1009 games, reward 375.680, eps 0.01, speed 104.73 f/s, time 25.6 min\n",
            "182892: done 1010 games, reward 372.160, eps 0.01, speed 90.45 f/s, time 25.6 min\n",
            "183315: done 1011 games, reward 381.640, eps 0.01, speed 129.44 f/s, time 25.6 min\n",
            "183424: done 1012 games, reward 378.200, eps 0.01, speed 128.83 f/s, time 25.6 min\n",
            "183547: done 1013 games, reward 378.320, eps 0.01, speed 128.94 f/s, time 25.6 min\n",
            "183688: done 1014 games, reward 380.080, eps 0.01, speed 130.18 f/s, time 25.7 min\n",
            "183744: done 1015 games, reward 369.080, eps 0.01, speed 123.73 f/s, time 25.7 min\n",
            "184331: done 1016 games, reward 370.720, eps 0.01, speed 118.91 f/s, time 25.8 min\n",
            "185011: done 1017 games, reward 384.520, eps 0.01, speed 119.52 f/s, time 25.8 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "185067: done 1018 games, reward 383.280, eps 0.01, speed 117.52 f/s, time 25.9 min\n",
            "185223: done 1019 games, reward 381.080, eps 0.01, speed 114.31 f/s, time 25.9 min\n",
            "185638: done 1020 games, reward 385.280, eps 0.01, speed 131.05 f/s, time 25.9 min\n",
            "185894: done 1021 games, reward 380.120, eps 0.01, speed 106.94 f/s, time 26.0 min\n",
            "186403: done 1022 games, reward 386.320, eps 0.01, speed 116.55 f/s, time 26.0 min\n",
            "187029: done 1023 games, reward 396.760, eps 0.01, speed 129.48 f/s, time 26.1 min\n",
            "187131: done 1024 games, reward 392.480, eps 0.01, speed 131.19 f/s, time 26.1 min\n",
            "187477: done 1025 games, reward 393.680, eps 0.01, speed 111.75 f/s, time 26.2 min\n",
            "187972: done 1026 games, reward 395.400, eps 0.01, speed 116.79 f/s, time 26.3 min\n",
            "188063: done 1027 games, reward 387.360, eps 0.01, speed 129.22 f/s, time 26.3 min\n",
            "188225: done 1028 games, reward 378.120, eps 0.01, speed 130.27 f/s, time 26.3 min\n",
            "188409: done 1029 games, reward 379.640, eps 0.01, speed 129.67 f/s, time 26.3 min\n",
            "189087: done 1030 games, reward 386.280, eps 0.01, speed 119.41 f/s, time 26.4 min\n",
            "189351: done 1031 games, reward 388.040, eps 0.01, speed 111.27 f/s, time 26.5 min\n",
            "189694: done 1032 games, reward 389.520, eps 0.01, speed 129.32 f/s, time 26.5 min\n",
            "189842: done 1033 games, reward 389.520, eps 0.01, speed 128.89 f/s, time 26.5 min\n",
            "190150: done 1034 games, reward 390.440, eps 0.01, speed 128.80 f/s, time 26.6 min\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1169041952.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mloss_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0mloss_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1902363388.py\u001b[0m in \u001b[0;36mcalc_loss\u001b[0;34m(batch, net, tgt_net, device)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     state_action_values = net(states_t).gather(\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     ).squeeze(-1)\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74ceda0e"
      },
      "source": [
        "model_comment = f\"lr{LEARNING_RATE}_gamma{GAMMA}_epsdec{EPSILON_DECAY_LAST_FRAME}_rs{REPLAY_START_SIZE}_bs{BATCH_SIZE}_sync{SYNC_TARGET_FRAMES}_fs{N_STEPS}\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "env = make_env(env_name)\n",
        "net = DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
        "tgt_net = DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
        "writer = SummaryWriter(comment=f\"-{env_name}-{model_comment}\")\n",
        "print(net)\n",
        "\n",
        "buffer = ExperienceBuffer(REPLAY_SIZE)\n",
        "agent = Agent(env, buffer)\n",
        "epsilon = EPSILON_START\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
        "total_rewards = []\n",
        "frame_idx = 0\n",
        "ts_frame = 0\n",
        "ts = time.time()\n",
        "best_m_reward = None\n",
        "\n",
        "hparams = {\n",
        "    'learning_rate': LEARNING_RATE,\n",
        "    'gamma': GAMMA,\n",
        "    'epsilon_start': EPSILON_START,\n",
        "    'epsilon_final': EPSILON_FINAL,\n",
        "    'epsilon_decay_last_frame': EPSILON_DECAY_LAST_FRAME,\n",
        "    'replay_size': REPLAY_SIZE,\n",
        "    'replay_start_size': REPLAY_START_SIZE,\n",
        "    'batch_size': BATCH_SIZE,\n",
        "    'sync_target_frames': SYNC_TARGET_FRAMES,\n",
        "    'frame_stack': N_STEPS,\n",
        "    'optimizer': 'Adam',\n",
        "    'mean_reward_bound': MEAN_REWARD_BOUND\n",
        "}\n",
        "\n",
        "# Flags to ensure video is recorded only once per trigger point\n",
        "early_video_recorded = False\n",
        "trained_video_recorded = False\n",
        "\n",
        "start_time = time.time()\n",
        "while True:\n",
        "    frame_idx += 1\n",
        "    epsilon = max(EPSILON_FINAL, EPSILON_START - frame_idx / EPSILON_DECAY_LAST_FRAME)\n",
        "\n",
        "    reward = agent.play_step(net, device, epsilon)\n",
        "    if reward is not None:\n",
        "        total_rewards.append(reward)\n",
        "        speed = (frame_idx - ts_frame) / (time.time() - ts)\n",
        "        elapsed = time.time() - start_time  # in seconds\n",
        "        ts_frame = frame_idx\n",
        "        ts = time.time()\n",
        "        m_reward = np.mean(total_rewards[-100:])\n",
        "        print(f\"{frame_idx}: done {len(total_rewards)} games, reward {m_reward:.3f}, \"\n",
        "             f\"eps {epsilon:.2f}, speed {speed:.2f} f/s, time {elapsed/60:.1f} min\")\n",
        "        writer.add_scalar(\"epsilon\", epsilon, frame_idx)\n",
        "        writer.add_scalar(\"speed\", speed, frame_idx)\n",
        "        writer.add_scalar(\"reward_100\", m_reward, frame_idx)\n",
        "        writer.add_scalar(\"reward\", reward, frame_idx)\n",
        "\n",
        "        # --- Video Recording Triggers ---\n",
        "        # 1. Early video recording\n",
        "        if not early_video_recorded and frame_idx >= EARLY_VIDEO_FRAME_THRESHOLD:\n",
        "            print(f\"\\n>>> Triggering early video recording at frame_idx {frame_idx} <<<\")\n",
        "            save_video_for_model(net, device, tag=f\"early_training_f{frame_idx}\", num_episodes=VIDEO_RECORD_EPISODES)\n",
        "            early_video_recorded = True\n",
        "\n",
        "        # 2. When the model starts performing well\n",
        "        if not trained_video_recorded and m_reward >= TRAINED_VIDEO_REWARD_THRESHOLD:\n",
        "            print(f\"\\n>>> Triggering trained video recording (m_reward {m_reward:.3f}) at frame_idx {frame_idx} <<<\")\n",
        "            save_video_for_model(net, device, tag=f\"trained_reward_{int(m_reward)}_f{frame_idx}\", num_episodes=VIDEO_RECORD_EPISODES)\n",
        "            trained_video_recorded = True\n",
        "        # --- End Video Recording Triggers ---\n",
        "\n",
        "        if best_m_reward is None or m_reward > best_m_reward + SAVE_EPSILON:\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
        "            model_filename = f\"{safe_env_name}-best_{int(m_reward)}-{timestamp}-{model_comment}.dat\"\n",
        "\n",
        "            model_path_drive = os.path.join(save_dir_drive, model_filename)\n",
        "            model_path_local = os.path.join(save_dir_local, model_filename)\n",
        "\n",
        "            torch.save(net.state_dict(), model_path_drive)\n",
        "            torch.save(net.state_dict(), model_path_local)\n",
        "\n",
        "            print(f\"Model saved to:\\n - Google Drive: {model_path_drive}\\n - Local:        {model_path_local}\") # Removed emoji\n",
        "            if best_m_reward is not None:\n",
        "                print(f\"Best reward updated {best_m_reward:.3f} -> {m_reward:.3f}\")\n",
        "            best_m_reward = m_reward\n",
        "\n",
        "            writer.add_hparams(hparams, {'metric/mean_reward': m_reward}, global_step=frame_idx)\n",
        "\n",
        "        if m_reward >= MEAN_REWARD_BOUND:\n",
        "            print(\"Solved in %d frames!\" % frame_idx)\n",
        "            # --- Video Recording Triggers ---\n",
        "            print(f\"\\n>>> Triggering final solved video recording (m_reward {m_reward:.3f}) at frame_idx {frame_idx} <<<\")\n",
        "            save_video_for_model(net, device, tag=f\"solved_reward_{int(m_reward)}_f{frame_idx}\", num_episodes=VIDEO_RECORD_EPISODES)\n",
        "            # --- End Video Recording Triggers ---\n",
        "            break\n",
        "\n",
        "    if len(buffer) < REPLAY_START_SIZE:\n",
        "        continue\n",
        "    if frame_idx % SYNC_TARGET_FRAMES == 0:\n",
        "        tgt_net.load_state_dict(net.state_dict())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    batch = buffer.sample(BATCH_SIZE)\n",
        "    loss_t = calc_loss(batch, net, tgt_net, device)\n",
        "    loss_t.backward()\n",
        "    optimizer.step()\n",
        "env.close()\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e51ea47d",
        "outputId": "131feff7-c52f-4d5d-874d-5169859b1217"
      },
      "source": [
        "!pip install tensorboard\n",
        "print(\"TensorBoard installed/upgraded successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.10)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.48.2->tensorboard) (4.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n",
            "TensorBoard installed/upgraded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "384fde46",
        "outputId": "53ba2fe8-0307-498a-db0a-0a520ddc1bbf"
      },
      "source": [
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "print(\"TensorBoard's EventAccumulator imported successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorBoard's EventAccumulator imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8902b53f",
        "outputId": "3d73261f-3eaf-4b4a-f428-0dc6b4f2ec94"
      },
      "source": [
        "import os\n",
        "\n",
        "log_dir = \"runs\"\n",
        "if not os.path.exists(log_dir):\n",
        "    print(f\"Error: The log directory '{log_dir}' does not exist. Please ensure TensorBoard logs are generated.\")\n",
        "else:\n",
        "    print(f\"Contents of '{log_dir}' directory:\")\n",
        "    for root, dirs, files in os.walk(log_dir):\n",
        "        for name in files:\n",
        "            if \"events.out.tfevents\" in name:\n",
        "                print(os.path.join(root, name))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of 'runs' directory:\n",
            "runs/Dec01_00-53-20_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/events.out.tfevents.1764550400.88e75354e526.827.4\n",
            "runs/Dec01_00-53-20_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764550401.304702/events.out.tfevents.1764550401.88e75354e526.827.5\n",
            "runs/Dec01_00-35-11_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/events.out.tfevents.1764549311.88e75354e526.827.0\n",
            "runs/Dec01_00-35-11_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764549318.6933749/events.out.tfevents.1764549318.88e75354e526.827.1\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/events.out.tfevents.1764552549.88e75354e526.827.136\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554259.8986726/events.out.tfevents.1764554259.88e75354e526.827.249\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552558.9466374/events.out.tfevents.1764552558.88e75354e526.827.138\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553822.8130143/events.out.tfevents.1764553822.88e75354e526.827.207\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552786.1476288/events.out.tfevents.1764552786.88e75354e526.827.159\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554902.226477/events.out.tfevents.1764554902.88e75354e526.827.256\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554093.8689773/events.out.tfevents.1764554093.88e75354e526.827.226\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764555016.4600034/events.out.tfevents.1764555016.88e75354e526.827.260\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552969.6839516/events.out.tfevents.1764552969.88e75354e526.827.167\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554223.9076803/events.out.tfevents.1764554223.88e75354e526.827.243\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553861.1713636/events.out.tfevents.1764553861.88e75354e526.827.210\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554998.588647/events.out.tfevents.1764554998.88e75354e526.827.259\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554192.5700207/events.out.tfevents.1764554192.88e75354e526.827.238\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553929.5155225/events.out.tfevents.1764553929.88e75354e526.827.214\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554206.8623993/events.out.tfevents.1764554206.88e75354e526.827.240\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553118.0665557/events.out.tfevents.1764553118.88e75354e526.827.170\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552700.3174117/events.out.tfevents.1764552700.88e75354e526.827.143\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553960.3203347/events.out.tfevents.1764553960.88e75354e526.827.220\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554996.6057818/events.out.tfevents.1764554996.88e75354e526.827.258\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552736.979383/events.out.tfevents.1764552736.88e75354e526.827.152\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554291.0202014/events.out.tfevents.1764554291.88e75354e526.827.250\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553363.8291914/events.out.tfevents.1764553363.88e75354e526.827.177\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552771.0243359/events.out.tfevents.1764552771.88e75354e526.827.156\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554183.2247994/events.out.tfevents.1764554183.88e75354e526.827.236\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554869.2048438/events.out.tfevents.1764554869.88e75354e526.827.252\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553946.1080647/events.out.tfevents.1764553946.88e75354e526.827.218\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552740.3218179/events.out.tfevents.1764552740.88e75354e526.827.154\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552801.6174586/events.out.tfevents.1764552801.88e75354e526.827.163\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553793.606199/events.out.tfevents.1764553793.88e75354e526.827.204\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553680.1460955/events.out.tfevents.1764553680.88e75354e526.827.197\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554007.2404728/events.out.tfevents.1764554007.88e75354e526.827.223\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553976.6179252/events.out.tfevents.1764553976.88e75354e526.827.222\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554156.1619248/events.out.tfevents.1764554156.88e75354e526.827.235\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552959.562804/events.out.tfevents.1764552959.88e75354e526.827.166\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553808.0164216/events.out.tfevents.1764553808.88e75354e526.827.205\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553351.2900636/events.out.tfevents.1764553351.88e75354e526.827.175\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554106.2510996/events.out.tfevents.1764554106.88e75354e526.827.230\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553787.687501/events.out.tfevents.1764553787.88e75354e526.827.203\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553470.7426214/events.out.tfevents.1764553470.88e75354e526.827.187\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554141.9233959/events.out.tfevents.1764554141.88e75354e526.827.234\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553843.870871/events.out.tfevents.1764553843.88e75354e526.827.208\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552697.5833063/events.out.tfevents.1764552697.88e75354e526.827.142\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553956.9201238/events.out.tfevents.1764553956.88e75354e526.827.219\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553963.702086/events.out.tfevents.1764553963.88e75354e526.827.221\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553670.8680449/events.out.tfevents.1764553670.88e75354e526.827.196\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552686.4269352/events.out.tfevents.1764552686.88e75354e526.827.141\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552788.201686/events.out.tfevents.1764552788.88e75354e526.827.161\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552739.3310418/events.out.tfevents.1764552739.88e75354e526.827.153\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553869.525965/events.out.tfevents.1764553869.88e75354e526.827.211\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553593.852631/events.out.tfevents.1764553593.88e75354e526.827.190\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552977.9002817/events.out.tfevents.1764552977.88e75354e526.827.168\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553401.1292775/events.out.tfevents.1764553401.88e75354e526.827.180\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554971.9358559/events.out.tfevents.1764554971.88e75354e526.827.257\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554095.4242125/events.out.tfevents.1764554095.88e75354e526.827.227\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552777.4050891/events.out.tfevents.1764552777.88e75354e526.827.157\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554101.510149/events.out.tfevents.1764554101.88e75354e526.827.228\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554090.1320453/events.out.tfevents.1764554090.88e75354e526.827.225\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553614.147483/events.out.tfevents.1764553614.88e75354e526.827.192\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553754.8170946/events.out.tfevents.1764553754.88e75354e526.827.199\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554088.971552/events.out.tfevents.1764554088.88e75354e526.827.224\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552957.012716/events.out.tfevents.1764552957.88e75354e526.827.165\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552735.2163315/events.out.tfevents.1764552735.88e75354e526.827.151\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553945.1363592/events.out.tfevents.1764553945.88e75354e526.827.217\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552727.8339832/events.out.tfevents.1764552727.88e75354e526.827.148\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552731.4303107/events.out.tfevents.1764552731.88e75354e526.827.149\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552683.7343934/events.out.tfevents.1764552683.88e75354e526.827.140\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552756.9182606/events.out.tfevents.1764552756.88e75354e526.827.155\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553329.343147/events.out.tfevents.1764553329.88e75354e526.827.172\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553354.3553462/events.out.tfevents.1764553354.88e75354e526.827.176\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553658.7058098/events.out.tfevents.1764553658.88e75354e526.827.195\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552798.0278397/events.out.tfevents.1764552798.88e75354e526.827.162\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554187.2251983/events.out.tfevents.1764554187.88e75354e526.827.237\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554103.858337/events.out.tfevents.1764554103.88e75354e526.827.229\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553937.5185442/events.out.tfevents.1764553937.88e75354e526.827.216\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553403.382813/events.out.tfevents.1764553403.88e75354e526.827.181\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553059.981802/events.out.tfevents.1764553059.88e75354e526.827.169\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552701.9690537/events.out.tfevents.1764552701.88e75354e526.827.144\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553916.7972698/events.out.tfevents.1764553916.88e75354e526.827.213\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553591.1662188/events.out.tfevents.1764553591.88e75354e526.827.189\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552784.9209442/events.out.tfevents.1764552784.88e75354e526.827.158\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553934.0940962/events.out.tfevents.1764553934.88e75354e526.827.215\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554248.9619813/events.out.tfevents.1764554248.88e75354e526.827.247\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553332.47385/events.out.tfevents.1764553332.88e75354e526.827.173\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553412.382356/events.out.tfevents.1764553412.88e75354e526.827.184\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554212.823061/events.out.tfevents.1764554212.88e75354e526.827.241\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552723.140437/events.out.tfevents.1764552723.88e75354e526.827.147\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764555019.981636/events.out.tfevents.1764555019.88e75354e526.827.261\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553608.4480958/events.out.tfevents.1764553608.88e75354e526.827.191\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553129.140231/events.out.tfevents.1764553129.88e75354e526.827.171\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764555026.2735364/events.out.tfevents.1764555026.88e75354e526.827.262\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552717.4395854/events.out.tfevents.1764552717.88e75354e526.827.146\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554230.283175/events.out.tfevents.1764554230.88e75354e526.827.245\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554865.5479977/events.out.tfevents.1764554865.88e75354e526.827.251\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553763.7061718/events.out.tfevents.1764553763.88e75354e526.827.200\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553407.8668964/events.out.tfevents.1764553407.88e75354e526.827.182\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764555035.1221008/events.out.tfevents.1764555035.88e75354e526.827.263\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552953.5473075/events.out.tfevents.1764552953.88e75354e526.827.164\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553783.6034389/events.out.tfevents.1764553783.88e75354e526.827.202\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553779.6086347/events.out.tfevents.1764553779.88e75354e526.827.201\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554135.1294143/events.out.tfevents.1764554135.88e75354e526.827.233\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553687.0153315/events.out.tfevents.1764553687.88e75354e526.827.198\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554123.951587/events.out.tfevents.1764554123.88e75354e526.827.232\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553872.70234/events.out.tfevents.1764553872.88e75354e526.827.212\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554242.188287/events.out.tfevents.1764554242.88e75354e526.827.246\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554892.2069042/events.out.tfevents.1764554892.88e75354e526.827.255\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553451.8113682/events.out.tfevents.1764553451.88e75354e526.827.185\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553388.1376326/events.out.tfevents.1764553388.88e75354e526.827.178\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553637.2946868/events.out.tfevents.1764553637.88e75354e526.827.193\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552672.7456524/events.out.tfevents.1764552672.88e75354e526.827.139\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553818.505896/events.out.tfevents.1764553818.88e75354e526.827.206\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553453.484083/events.out.tfevents.1764553453.88e75354e526.827.186\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553398.4753582/events.out.tfevents.1764553398.88e75354e526.827.179\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553584.6301785/events.out.tfevents.1764553584.88e75354e526.827.188\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553409.45966/events.out.tfevents.1764553409.88e75354e526.827.183\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554251.000208/events.out.tfevents.1764554251.88e75354e526.827.248\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554872.3877776/events.out.tfevents.1764554872.88e75354e526.827.253\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552549.809719/events.out.tfevents.1764552549.88e75354e526.827.137\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554226.7576988/events.out.tfevents.1764554226.88e75354e526.827.244\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554112.8427186/events.out.tfevents.1764554112.88e75354e526.827.231\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552733.2057915/events.out.tfevents.1764552733.88e75354e526.827.150\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554217.619826/events.out.tfevents.1764554217.88e75354e526.827.242\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553350.1617165/events.out.tfevents.1764553350.88e75354e526.827.174\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552787.1755512/events.out.tfevents.1764552787.88e75354e526.827.160\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553850.7338095/events.out.tfevents.1764553850.88e75354e526.827.209\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552713.0523608/events.out.tfevents.1764552713.88e75354e526.827.145\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554876.4858437/events.out.tfevents.1764554876.88e75354e526.827.254\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764553651.108568/events.out.tfevents.1764553651.88e75354e526.827.194\n",
            "runs/Dec01_01-29-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764554200.3830276/events.out.tfevents.1764554200.88e75354e526.827.239\n",
            "runs/Dec01_00-53-49_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/events.out.tfevents.1764550429.88e75354e526.827.6\n",
            "runs/Dec01_00-53-49_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764550435.7211473/events.out.tfevents.1764550435.88e75354e526.827.7\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/events.out.tfevents.1764555045.88e75354e526.827.264\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556227.632535/events.out.tfevents.1764556227.88e75354e526.827.278\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556344.837186/events.out.tfevents.1764556344.88e75354e526.827.287\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556481.1040914/events.out.tfevents.1764556481.88e75354e526.827.293\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556303.859588/events.out.tfevents.1764556303.88e75354e526.827.284\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556246.5311265/events.out.tfevents.1764556246.88e75354e526.827.279\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556311.8307285/events.out.tfevents.1764556311.88e75354e526.827.285\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556150.7674942/events.out.tfevents.1764556150.88e75354e526.827.268\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556501.753639/events.out.tfevents.1764556501.88e75354e526.827.295\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556335.360699/events.out.tfevents.1764556335.88e75354e526.827.286\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556463.447185/events.out.tfevents.1764556463.88e75354e526.827.291\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556250.733904/events.out.tfevents.1764556250.88e75354e526.827.280\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556149.2046704/events.out.tfevents.1764556149.88e75354e526.827.267\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556291.6838317/events.out.tfevents.1764556291.88e75354e526.827.281\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556201.781703/events.out.tfevents.1764556201.88e75354e526.827.275\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556146.4972425/events.out.tfevents.1764556146.88e75354e526.827.266\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556500.3706784/events.out.tfevents.1764556500.88e75354e526.827.294\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556476.5437844/events.out.tfevents.1764556476.88e75354e526.827.292\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556165.6765428/events.out.tfevents.1764556165.88e75354e526.827.271\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556352.2490692/events.out.tfevents.1764556352.88e75354e526.827.288\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556162.1743367/events.out.tfevents.1764556162.88e75354e526.827.270\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556152.5131538/events.out.tfevents.1764556152.88e75354e526.827.269\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556212.367092/events.out.tfevents.1764556212.88e75354e526.827.277\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556292.8803434/events.out.tfevents.1764556292.88e75354e526.827.282\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556195.1812758/events.out.tfevents.1764556195.88e75354e526.827.274\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556353.3259637/events.out.tfevents.1764556353.88e75354e526.827.289\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556209.076795/events.out.tfevents.1764556209.88e75354e526.827.276\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764555052.9762747/events.out.tfevents.1764555052.88e75354e526.827.265\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556193.303527/events.out.tfevents.1764556193.88e75354e526.827.273\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556297.9329236/events.out.tfevents.1764556297.88e75354e526.827.283\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556184.7966/events.out.tfevents.1764556184.88e75354e526.827.272\n",
            "runs/Dec01_02-10-45_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764556382.622913/events.out.tfevents.1764556382.88e75354e526.827.290\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/events.out.tfevents.1764550727.88e75354e526.827.8\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552491.6681898/events.out.tfevents.1764552491.88e75354e526.827.129\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551617.4558694/events.out.tfevents.1764551617.88e75354e526.827.74\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551341.4077144/events.out.tfevents.1764551341.88e75354e526.827.52\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552423.9787648/events.out.tfevents.1764552423.88e75354e526.827.121\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764550843.7744987/events.out.tfevents.1764550843.88e75354e526.827.12\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551890.1053832/events.out.tfevents.1764551890.88e75354e526.827.93\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551779.919771/events.out.tfevents.1764551779.88e75354e526.827.80\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551112.9876008/events.out.tfevents.1764551112.88e75354e526.827.37\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551106.1554577/events.out.tfevents.1764551106.88e75354e526.827.35\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551852.9568317/events.out.tfevents.1764551852.88e75354e526.827.89\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552122.0443828/events.out.tfevents.1764552122.88e75354e526.827.102\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551116.9794095/events.out.tfevents.1764551116.88e75354e526.827.38\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552051.3767593/events.out.tfevents.1764552051.88e75354e526.827.100\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551809.825235/events.out.tfevents.1764551809.88e75354e526.827.82\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551832.2168593/events.out.tfevents.1764551832.88e75354e526.827.87\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551779.2761705/events.out.tfevents.1764551779.88e75354e526.827.79\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551106.6383073/events.out.tfevents.1764551106.88e75354e526.827.36\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552497.1847188/events.out.tfevents.1764552497.88e75354e526.827.130\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552345.8975163/events.out.tfevents.1764552345.88e75354e526.827.113\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764550880.3337924/events.out.tfevents.1764550880.88e75354e526.827.23\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552416.5636122/events.out.tfevents.1764552416.88e75354e526.827.119\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551991.4547684/events.out.tfevents.1764551991.88e75354e526.827.95\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552307.9994297/events.out.tfevents.1764552307.88e75354e526.827.109\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551312.6502776/events.out.tfevents.1764551312.88e75354e526.827.43\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551320.177064/events.out.tfevents.1764551320.88e75354e526.827.45\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552283.8086655/events.out.tfevents.1764552283.88e75354e526.827.105\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551152.555515/events.out.tfevents.1764551152.88e75354e526.827.41\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551999.659918/events.out.tfevents.1764551999.88e75354e526.827.98\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551605.7218862/events.out.tfevents.1764551605.88e75354e526.827.73\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551530.2655928/events.out.tfevents.1764551530.88e75354e526.827.62\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552087.3919103/events.out.tfevents.1764552087.88e75354e526.827.101\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551544.3292081/events.out.tfevents.1764551544.88e75354e526.827.66\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551759.101159/events.out.tfevents.1764551759.88e75354e526.827.77\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552344.711424/events.out.tfevents.1764552344.88e75354e526.827.112\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551124.9763482/events.out.tfevents.1764551124.88e75354e526.827.39\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551810.9706328/events.out.tfevents.1764551810.88e75354e526.827.83\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551824.7620966/events.out.tfevents.1764551824.88e75354e526.827.85\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551992.992408/events.out.tfevents.1764551992.88e75354e526.827.96\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552500.886767/events.out.tfevents.1764552500.88e75354e526.827.131\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551948.5028467/events.out.tfevents.1764551948.88e75354e526.827.94\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551840.0797772/events.out.tfevents.1764551840.88e75354e526.827.88\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551597.9888124/events.out.tfevents.1764551597.88e75354e526.827.72\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551591.835618/events.out.tfevents.1764551591.88e75354e526.827.71\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551085.3147964/events.out.tfevents.1764551085.88e75354e526.827.31\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551550.478645/events.out.tfevents.1764551550.88e75354e526.827.68\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764550845.9985008/events.out.tfevents.1764550845.88e75354e526.827.14\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552542.3303552/events.out.tfevents.1764552542.88e75354e526.827.133\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551514.843876/events.out.tfevents.1764551514.88e75354e526.827.59\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552432.1655378/events.out.tfevents.1764552432.88e75354e526.827.123\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551059.8708196/events.out.tfevents.1764551059.88e75354e526.827.27\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552144.3559227/events.out.tfevents.1764552144.88e75354e526.827.104\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551760.5285923/events.out.tfevents.1764551760.88e75354e526.827.78\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764550834.1682022/events.out.tfevents.1764550834.88e75354e526.827.10\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764550834.9459655/events.out.tfevents.1764550834.88e75354e526.827.11\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552367.6987333/events.out.tfevents.1764552367.88e75354e526.827.117\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551856.675612/events.out.tfevents.1764551856.88e75354e526.827.91\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552298.3676503/events.out.tfevents.1764552298.88e75354e526.827.107\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552533.1309297/events.out.tfevents.1764552533.88e75354e526.827.132\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551077.3291004/events.out.tfevents.1764551077.88e75354e526.827.29\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552439.909536/events.out.tfevents.1764552439.88e75354e526.827.125\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551062.9253628/events.out.tfevents.1764551062.88e75354e526.827.28\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552293.162077/events.out.tfevents.1764552293.88e75354e526.827.106\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764550872.7810524/events.out.tfevents.1764550872.88e75354e526.827.20\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551541.8959396/events.out.tfevents.1764551541.88e75354e526.827.65\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551358.6707242/events.out.tfevents.1764551358.88e75354e526.827.55\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552361.578807/events.out.tfevents.1764552361.88e75354e526.827.116\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764550881.759157/events.out.tfevents.1764550881.88e75354e526.827.24\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552348.7427282/events.out.tfevents.1764552348.88e75354e526.827.114\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552355.581881/events.out.tfevents.1764552355.88e75354e526.827.115\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552448.2957203/events.out.tfevents.1764552448.88e75354e526.827.128\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551814.1875925/events.out.tfevents.1764551814.88e75354e526.827.84\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552445.871416/events.out.tfevents.1764552445.88e75354e526.827.126\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551885.3181286/events.out.tfevents.1764551885.88e75354e526.827.92\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552048.659264/events.out.tfevents.1764552048.88e75354e526.827.99\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551619.3117874/events.out.tfevents.1764551619.88e75354e526.827.75\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552329.3933153/events.out.tfevents.1764552329.88e75354e526.827.111\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551316.028056/events.out.tfevents.1764551316.88e75354e526.827.44\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551349.3163223/events.out.tfevents.1764551349.88e75354e526.827.53\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764550874.0174437/events.out.tfevents.1764550874.88e75354e526.827.21\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551333.0557537/events.out.tfevents.1764551333.88e75354e526.827.49\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552415.5217202/events.out.tfevents.1764552415.88e75354e526.827.118\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764550904.303459/events.out.tfevents.1764550904.88e75354e526.827.25\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551539.1545863/events.out.tfevents.1764551539.88e75354e526.827.63\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551088.5645578/events.out.tfevents.1764551088.88e75354e526.827.32\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764550905.698153/events.out.tfevents.1764550905.88e75354e526.827.26\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551264.7275863/events.out.tfevents.1764551264.88e75354e526.827.42\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551327.5627027/events.out.tfevents.1764551327.88e75354e526.827.47\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551539.7655556/events.out.tfevents.1764551539.88e75354e526.827.64\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551569.8618207/events.out.tfevents.1764551569.88e75354e526.827.69\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552420.2782178/events.out.tfevents.1764552420.88e75354e526.827.120\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764550878.1276186/events.out.tfevents.1764550878.88e75354e526.827.22\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551798.4472637/events.out.tfevents.1764551798.88e75354e526.827.81\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551095.5723448/events.out.tfevents.1764551095.88e75354e526.827.34\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764550871.3215914/events.out.tfevents.1764550871.88e75354e526.827.19\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764550862.3607836/events.out.tfevents.1764550862.88e75354e526.827.17\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551090.671948/events.out.tfevents.1764551090.88e75354e526.827.33\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551546.266354/events.out.tfevents.1764551546.88e75354e526.827.67\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551855.5946836/events.out.tfevents.1764551855.88e75354e526.827.90\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551525.6338737/events.out.tfevents.1764551525.88e75354e526.827.61\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551361.5183172/events.out.tfevents.1764551361.88e75354e526.827.56\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551826.4406254/events.out.tfevents.1764551826.88e75354e526.827.86\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551582.8389068/events.out.tfevents.1764551582.88e75354e526.827.70\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551143.0167792/events.out.tfevents.1764551143.88e75354e526.827.40\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552546.946902/events.out.tfevents.1764552546.88e75354e526.827.134\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551997.5346599/events.out.tfevents.1764551997.88e75354e526.827.97\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764550728.3689754/events.out.tfevents.1764550728.88e75354e526.827.9\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551352.4639673/events.out.tfevents.1764551352.88e75354e526.827.54\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551633.4882247/events.out.tfevents.1764551633.88e75354e526.827.76\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552304.9634411/events.out.tfevents.1764552304.88e75354e526.827.108\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552316.4079316/events.out.tfevents.1764552316.88e75354e526.827.110\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764550844.75503/events.out.tfevents.1764550844.88e75354e526.827.13\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551329.881514/events.out.tfevents.1764551329.88e75354e526.827.48\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551519.2884765/events.out.tfevents.1764551519.88e75354e526.827.60\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551081.5264323/events.out.tfevents.1764551081.88e75354e526.827.30\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551339.1603866/events.out.tfevents.1764551339.88e75354e526.827.51\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552430.026369/events.out.tfevents.1764552430.88e75354e526.827.122\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551323.6375232/events.out.tfevents.1764551323.88e75354e526.827.46\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764550859.8952312/events.out.tfevents.1764550859.88e75354e526.827.16\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552140.5293722/events.out.tfevents.1764552140.88e75354e526.827.103\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551376.8968291/events.out.tfevents.1764551376.88e75354e526.827.58\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551334.6419466/events.out.tfevents.1764551334.88e75354e526.827.50\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764550848.8306124/events.out.tfevents.1764550848.88e75354e526.827.15\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764551368.1212864/events.out.tfevents.1764551368.88e75354e526.827.57\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552435.0442934/events.out.tfevents.1764552435.88e75354e526.827.124\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552549.1986387/events.out.tfevents.1764552549.88e75354e526.827.135\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764550864.6162004/events.out.tfevents.1764550864.88e75354e526.827.18\n",
            "runs/Dec01_00-58-47_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764552446.4615965/events.out.tfevents.1764552446.88e75354e526.827.127\n",
            "runs/Dec01_00-52-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/events.out.tfevents.1764550329.88e75354e526.827.2\n",
            "runs/Dec01_00-52-09_88e75354e526-ALE/BeamRider-v5-lr0.0001_gamma0.99_epsdec10000_rs1000_bs32_sync500_fs4/1764550343.1492002/events.out.tfevents.1764550343.88e75354e526.827.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "9e5bcf49",
        "outputId": "6b2d9663-7e24-47f8-af78-dfbd128745aa"
      },
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_latest_event_file(log_dir):\n",
        "    list_of_files = glob(os.path.join(log_dir, '**', 'events.out.tfevents.*'), recursive=True)\n",
        "    if not list_of_files:\n",
        "        return None\n",
        "    latest_file = max(list_of_files, key=os.path.getmtime)\n",
        "    return latest_file\n",
        "\n",
        "latest_event_file = get_latest_event_file(log_dir)\n",
        "\n",
        "if latest_event_file:\n",
        "    event_acc = EventAccumulator(latest_event_file)\n",
        "    event_acc.Reload()\n",
        "\n",
        "    # Extract scalar data\n",
        "    rewards = []\n",
        "    losses = []\n",
        "    frames = []\n",
        "    loss_frames = []\n",
        "\n",
        "    if 'reward_100' in event_acc.Tags()['scalars']:\n",
        "        for s in event_acc.Scalars('reward_100'):\n",
        "            rewards.append(s.value)\n",
        "            frames.append(s.step)\n",
        "    else:\n",
        "        print(\"Warning: 'reward_100' not found in scalars. Available tags:\", event_acc.Tags()['scalars'])\n",
        "\n",
        "    if 'loss_t' in event_acc.Tags()['scalars']:\n",
        "        for s in event_acc.Scalars('loss_t'):\n",
        "            losses.append(s.value)\n",
        "            loss_frames.append(s.step)\n",
        "    else:\n",
        "        print(\"Warning: 'loss_t' not found in scalars. Available tags:\", event_acc.Tags()['scalars'])\n",
        "\n",
        "    # Create DataFrames for easier plotting\n",
        "    df_rewards = pd.DataFrame({'frame_idx': frames, 'mean_reward': rewards})\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(15, 6))\n",
        "\n",
        "    if not df_rewards.empty:\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(df_rewards['frame_idx'], df_rewards['mean_reward'], label='Mean Reward (last 100 episodes)', color='blue')\n",
        "        plt.xlabel('Frames')\n",
        "        plt.ylabel('Mean Reward')\n",
        "        plt.title('Mean Reward over Training Frames')\n",
        "        plt.grid(True)\n",
        "        plt.legend()\n",
        "    else:\n",
        "        print(\"No reward data to plot.\")\n",
        "\n",
        "    if losses:\n",
        "        df_losses = pd.DataFrame({'frame_idx': loss_frames, 'loss': losses})\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(df_losses['frame_idx'], df_losses['loss'], label='Loss', color='red')\n",
        "        plt.xlabel('Frames')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Loss over Training Frames')\n",
        "        plt.grid(True)\n",
        "        plt.legend()\n",
        "    else:\n",
        "        print(\"No loss data to plot.\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Learning curves for mean reward and loss plotted successfully.\")\n",
        "else:\n",
        "    print(\"No TensorBoard event files found in the 'runs' directory.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: 'loss_t' not found in scalars. Available tags: ['epsilon', 'speed', 'reward_100', 'reward']\n",
            "No loss data to plot.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning curves for mean reward and loss plotted successfully.\n"
          ]
        }
      ]
    }
  ]
}
